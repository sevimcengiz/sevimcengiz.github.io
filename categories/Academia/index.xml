<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Academia on Sevim Cengiz</title><link>https://sevimcengiz.github.io/categories/Academia/</link><description>Recent content in Academia on Sevim Cengiz</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 06 Jan 2017 00:00:00 +0000</lastBuildDate><atom:link href="https://sevimcengiz.github.io/categories/Academia/index.xml" rel="self" type="application/rss+xml"/><item><title>Do you have to publish papers to obtain a PhD?</title><link>https://sevimcengiz.github.io/blog/2017/01/06/do-you-have-to-publish-papers-for-a-phd/</link><pubDate>Fri, 06 Jan 2017 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2017/01/06/do-you-have-to-publish-papers-for-a-phd/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>It is common for friction to arise between graduate students and their supervisors (PIs) over how many and what kind of papers the students need to publish before graduating. While on occasion the students’ complaint is that their PI keeps them from publishing,&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> the much more common scenario is one where the PI wants the student to complete &lt;em>x&lt;/em> papers in &lt;em>y&lt;/em> journals while the student just wants to graduate and move on. When these conflicts come to a head, students usually start to inquire what the minimum requirements are before graduation.&lt;/p>
&lt;p>Of course there is only one correct answer to this question:&lt;/p>
&lt;blockquote class="twitter-tweet" data-lang="en">
&lt;p lang="en" dir="ltr">
A PhD thesis/dissertation does not in any way require papers be published from the work. &lt;a href="https://t.co/AIGnIcDyY7">https://t.co/AIGnIcDyY7&lt;/a>
&lt;/p>
— Drug Monkey (&lt;span class="citation">@drugmonkeyblog&lt;/span>) &lt;a href="https://twitter.com/drugmonkeyblog/status/817351541275230209">January 6, 2017&lt;/a>
&lt;/blockquote>
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>As much as PIs may want to impose a publication requirement, because it benefits them,&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> they cannot require the students to do something that is entirely outside of the control of both student and PI. A PhD is defined as an independent body of research, performed by the student and assessed by the PhD committee. If the student has done the research proposed during the proposal defense and has written up the resulting work in the form of a thesis, then the committee needs to evaluate that work and, if it is of sufficient quality, grant the degree.&lt;/p>
&lt;p>There are multiple reasons why requiring published papers as a condition of graduation is wrong. First, as all working scientists know, the peer review process can drag out months or even years, and it may take multiple submissions to multiple different journals before a paper is accepted. Much of this process is out of the hands of the author. Even a perfectly well executed and written paper can be held up forever, for all sorts of reasons that have nothing to do with the quality of the work. Thus, it is entirely unreasonable to ask a graduate student to wait until this process is over before being allowed to graduate.&lt;/p>
&lt;p>Second, sometimes a reasonable effort at investigating a question simply doesn’t lead to important new insight. A student may have very carefully studied a system for many years, only to conclusively prove that the interesting results they saw in their first month in the lab were caused by temperature fluctuations in the incubator room. Such work would be appropriate for a PhD thesis but it would likely not be suitable for publication in a major research journal.&lt;/p>
&lt;p>Third, by requiring a published article, the PhD committee is skirting its responsibility to evaluate the student’s work. The committee is saying, in effect, that they cannot judge whether the work is PhD-worthy unless an external body (the editors and reviewers of a scientific journal) has judged the work to be worthy of publication.&lt;/p>
&lt;p>Now, having said all this, I am of course very much in favor of graduate students publishing their work. None of my past graduate students have graduated without at least one first-author paper, and I want all my graduate students to submit a paper as soon as possible, ideally in year one or two of their graduate career. Also, I generally expect a PhD thesis to consist of at least three distinct projects, which should have been developed to the point where they could be submitted as a journal article. But to the question of whether a publication is strictly required, the answer has to be “no.”&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>There’s an inherent conflict of interest between students and PIs, in that minor, pedestrian papers will be of very little value to an established PI but can be of exceptional value to a graduate student who hasn’t published much and wants to apply for a fellowship or postdoc position. There’s a lesson here for prospective students or postdocs: If a lab publishes a steady stream of minor papers, it likely does so out of the PI’s sense of duty towards their mentees. A lab that only publishes in Nature, Science, and Cell will likely not be good for a significant chunk of its trainees, no matter how great it is for those that manage to be first author on one of the celebrated papers.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>What PIs will say is that any papers that haven’t been published by the time the student graduates will likely never be published. This statement is indeed true, in my experience. However, it also demonstrates that the paper is more important to the PI than to the student. In my opinion, any PI who cares so much about a given paper should just complete it themselves.&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>How to reject a rejection</title><link>https://sevimcengiz.github.io/blog/2017/01/02/how-to-reject-a-rejection/</link><pubDate>Mon, 02 Jan 2017 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2017/01/02/how-to-reject-a-rejection/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>For a junior scientist, it can be a major blow when their manuscript is rejected. They have poured many months to years of their time into this project, have submitted the paper where they think it belongs, and the editor puts an end to their aspirations by rejecting the submission. However, more experienced scientists, in particular those with editorial roles at major journals, know very well that many a rejection is not final. Often, a rejection is only the first step in an ongoing negotiation with the journal, one that frequently ends with the eventual publication of the article. To level the playing field between the junior and the more senior scientists, here I’ll reveal this secret to the world: How to reject a rejection.&lt;/p>
&lt;p>There are basically two strategies that you can pursue, appeal to the editor or resubmit anyways. In the following, I’ll briefly discuss the mechanics of each option and then give my opinion of which option should be used when.&lt;/p>
&lt;div id="appeal-to-the-editor" class="section level2">
&lt;h2>Appeal to the editor&lt;/h2>
&lt;p>An appeal is a request to the editor to overturn the decision. Typically, a successful appeal will change the decision from “reject” to “major revision”, i.e., it will buy you the right to revise and resubmit. Some journals have complex and formal appeals processes while others handle appeals more informally. In all cases, you will initiate the appeal by contacting the editor and explaining why you believe the reviewer criticisms were either unwarranted or can be fully addressed in a revision. The initial contact to the editor could consist of just a brief email explaining the main issues, or it could be accompanied by a detailed point-by-point response to the reviewer comments.&lt;/p>
&lt;p>How a journal handles an appeal depends on the journal’s policies and procedures as well as the specific appeal request you are making. The journal may send out your original manuscript to another reviewer, they may send your point-by-point response to the original reviewers, or they may involve one or more editors who didn’t handle the original submission. They may also ask you for more information, such as a detailed point-by-point response to the reviewer comments (if you haven’t sent one yet) or a revised manuscript draft.&lt;/p>
&lt;p>An appeal can be a long, drawn-out procedure, in particular if you initiate it with just an email to the editor. The editor may take a week or two to respond to your original email, asking you for a detailed point-by-point response. Once you submit that, the editor may have it reviewed by multiple people (the original reviewers, new reviewers, or other editors), and this process may take as long as a typical review would take. After all this time has passed, the editor may then tell you that they need to see a revised manuscript before they can make any sort of decision. The revised manuscript will then again have to be re-reviewed, of course, and this review process will likely prompt further requests for revision, even in the best-case scenario that the appeal is ultimately successful.&lt;/p>
&lt;/div>
&lt;div id="resubmit-anyways" class="section level2">
&lt;h2>Resubmit anyways&lt;/h2>
&lt;p>As an alternative to filing a formal appeal, you can also just go ahead, revise your manuscript, and resubmit. This will have to be under the guise that you have sufficiently revised the manuscript to the point where it can now be considered a new submission. The unethical way of doing this would be to change the title, change the abstract, and hope the editor won’t notice. I do not recommend this approach. The ethical way to proceed is to submit as a new submission but state clearly in the cover letter that an earlier version of this paper was previously reviewed and rejected. You should also submit a detailed response to the reviewer comments. The journal submission system may not have a special option to do so, since it thinks you’re submitting a new article, but you can always just upload your response as a supplemental file and point to it in the cover letter.&lt;/p>
&lt;/div>
&lt;div id="which-option-is-preferable" class="section level2">
&lt;h2>Which option is preferable?&lt;/h2>
&lt;p>Given the two options of either appealing or resubmitting anyways, most people would intuitively choose to appeal. Resubmitting without prior approval feels wrong and somewhat sneaky; most people need to know that they are welcome to resubmit before they feel comfortable doing it. Further, the act of appealing feels right: The reviewers were stupid, the editors didn’t get it, and I want to protest!&lt;/p>
&lt;p>However, if you consider the two options from the perspective of the editor, you’ll see that filing an appeal is almost always the worse option. The appeal, by its very nature, creates an adversarial relationship with the editor. You’re telling the editor they were wrong and need to change their decision. This adversarial relationship can make the editor negatively predisposed towards you. An appeal only makes sense, in my opinion, when the reviews were truly biased or otherwise off (e.g., contained unprofessional ad-hominem attacks), so that there is no way you can revise the manuscript to address the reviewer comments.&lt;/p>
&lt;p>If you’re going the “submit as new manuscript” route, you’re putting the editor in a position where they are more likely to be positively predisposed towards you, even though it may not seem that way. First, note that you’re in effect asking the editor for a favor, namely the favor of connecting this new submission to the history of the previous submission and to use (some of) the previous reviewers. And asking somebody to do you a favor is a great way to get them to like you.&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> Second, you’re providing the editor with a submission that is easy to handle. The editor already knows which reviewers to invite, which issues to look out for, and so on. So, as long as you appear to have made serious efforts to address the prior criticisms, the editor will likely be willing to go along and at least send the paper back out to review.&lt;/p>
&lt;/div>
&lt;div id="how-well-does-this-work" class="section level2">
&lt;h2>How well does this work?&lt;/h2>
&lt;p>What are the chances of success? After having read this post, will you now be able to publish all your work in Science and Nature? No, of course not. Appeals and uninvited resubmissions frequently are unsuccessful. However, they succeed often enough that you should at least consider going this route from time to time. If you never resubmit a rejected article you’re leaving money on the table. You can be certain that any PI who routinely publishes in high-profile journals does a lot of appealing and resubmitting of rejected articles.&lt;/p>
&lt;p>But won’t the editors just get annoyed and put you on their blacklist? I think that’s unlikely, unless you become really obnoxious, e.g. by appealing a failed appeal or by not putting an honest effort into revising your manuscript. Remember that editors fundamentally want to work with you and want to give you a positive decision. They’re not editors because they enjoy handing out rejections all day. They are doing this thankless, poorly remunerated job primarily because they want to advance their field and their community.&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> Thus, they’d much rather handle a good paper they can accept than a bad paper they have to reject.&lt;/p>
&lt;p>Finally, you should know that many editors reject papers that they expect to be resubmitted. My own rule is that if the reviewers have pointed out a potential major flaw in the work, one that may require a substantial rethinking of the entire paper, then I’d rather reject than ask for major revisions. I do this because to me calling for major revisions creates the expectation that the paper will be accepted after the revisions have been made. And I don’t want to string authors along, make them revise, and then reject at the very end of this long process.&lt;a href="#fn3" class="footnote-ref" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>This is called the &lt;a href="https://en.wikipedia.org/wiki/Ben_Franklin_effect">Ben Franklin effect,&lt;/a> after Ben Franklin, who asked a rival legislator to lend him a rare book.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>Yes, this statement applies even to paid, professional editors.&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>This doesn’t mean I never reject revised manuscripts. It just means I try to make my initial editorial decisions such that rejections after revision are rare.&lt;a href="#fnref3" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Hiding journal names from your publication list stinks</title><link>https://sevimcengiz.github.io/blog/2015/12/08/hiding-journal-names-from-your-publication-list-stinks/</link><pubDate>Tue, 08 Dec 2015 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2015/12/08/hiding-journal-names-from-your-publication-list-stinks/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>Michael Eisen recently announced his new website, which features a new publication list that doesn’t mention journal names anywhere:&lt;/p>
&lt;blockquote class="twitter-tweet" lang="en">
&lt;p lang="en" dir="ltr">
made a new lab website - completely scrubbed any mention of journal titles - &lt;a href="https://t.co/iTwYvWDwqX">https://t.co/iTwYvWDwqX&lt;/a>
&lt;/p>
— Michⓐel Eisen (&lt;span class="citation">@mbeisen&lt;/span>) &lt;a href="https://twitter.com/mbeisen/status/673419464633749504">December 6, 2015&lt;/a>
&lt;/blockquote>
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>This idea was quickly picked up by others, e.g.:&lt;/p>
&lt;blockquote class="twitter-tweet" lang="en">
&lt;p lang="en" dir="ltr">
Following &lt;a href="https://twitter.com/mbeisen">&lt;span class="citation">@mbeisen&lt;/span>&lt;/a>, removed journal names from website. But also links to cites, almetrics, &amp;amp; preprints. &lt;a href="https://t.co/bPqZgrr2iA">https://t.co/bPqZgrr2iA&lt;/a>
&lt;/p>
— Jeffrey Ross-Ibarra (&lt;span class="citation">@jrossibarra&lt;/span>) &lt;a href="https://twitter.com/jrossibarra/status/673680344982274048">December 7, 2015&lt;/a>
&lt;/blockquote>
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>I spoke out against this idea, since I immediately had the gut-feeling response that something was wrong with it:&lt;/p>
&lt;blockquote class="twitter-tweet" data-conversation="none" lang="en">
&lt;p lang="en" dir="ltr">
&lt;a href="https://twitter.com/yanivbrandvain">&lt;span class="citation">@yanivbrandvain&lt;/span>&lt;/a> Yeah, I'm not on board with hiding journal names. That's &lt;a href="https://twitter.com/mbeisen">&lt;span class="citation">@mbeisen&lt;/span>&lt;/a>'s thing, and now also &lt;a href="https://twitter.com/jrossibarra">&lt;span class="citation">@jrossibarra&lt;/span>&lt;/a>, I guess. &lt;a href="https://twitter.com/jaimedash">&lt;span class="citation">@jaimedash&lt;/span>&lt;/a>
&lt;/p>
— Claus Wilke (&lt;span class="citation">@ClausWilke&lt;/span>) &lt;a href="https://twitter.com/ClausWilke/status/673723100379283456">December 7, 2015&lt;/a>
&lt;/blockquote>
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>However, at the time, I couldn’t quite formulate what I thought the key issue was. I have now given this more thought, and I’ve found various reasons why I think it’s a bad idea to hide journal names. However, I’ve also realized that most of these arguments don’t even matter. As I’ll argue here, hiding journal names from the publication list is directly at odds with the principles of openness and egalitarianism that people like Michael Eisen so strongly promote. Therefore, to put it bluntly, I think this practice stinks.&lt;/p>
&lt;p>We need to realize that in the current world of scientific publishing, removing journal names from the publication list has cause and effect reversed. If we had reached a point where nobody cared about journal names,&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> then removing them from the publication list and listing papers simply by author, title, and DOI would be the logical next step. But since, as of today, there are plenty of people in this world who do care about journal names, hiding them is counterproductive. We can state all we want that “people shouldn’t care about journal names,” but hiding these names from publication lists won’t make it so.&lt;/p>
&lt;p>Think about it this way: If you want to move towards a world where people care more about article content than journal name, who do you need to convince? Those who already agree with you, or those who disagree? Obviously the latter. What would be a meaningful action towards that goal? In my mind, the most important action is to demonstrate that the publication venue doesn’t matter that much, by publishing your best work in journals such as PLOS ONE, PeerJ, or F1000Research, or even by just posting studies on bioRxiv without submitting them to any journal at all. These actions would demonstrate to the world that you’re putting your money where your mouth is and that you don’t care about perceived journal impact. How would the world notice that you’re doing this? They might go to your website and see that you, the esteemed scholar and noted expert in your field, publish in “low-impact” journals and on preprint servers, validating these publication venues in the process.&lt;/p>
&lt;p>By contrast, if you’re hiding the journal names from your website, this important message is not conveyed. At best, people will not notice where you publish. At worst, they may wonder what you’re hiding. And that’s where things are really getting counter-productive. Because, if you are an outspoken proponent of open access, of preprints, of post-publication peer review, of publishing in non-selective journals, then any paper you publish that violates these principles will weaken your message. And if you’re not even stating on your website where you’re publishing, you may be perceived as being dishonest. For example, on &lt;a href="http://www.eisenlab.org//publications.html">Michael Eisen’s publication list&lt;/a>, over the last 3 years, I count one pay-walled Elsevier paper (!), two papers in the highly selective journal eLife, and several papers in the fairly selective journals Genome Research, PLOS Genetics, and PLOS Computational Biology. (These papers are easier to find on his &lt;a href="https://scholar.google.com/citations?hl=en&amp;amp;user=z2foFg4AAAAJ&amp;amp;view_op=list_works&amp;amp;sortby=pubdate">Google Scholar page,&lt;/a> since it lists journal names, but they’re all on his web site as well, I checked.) So clearly the Eisen lab does not publish everything they do as post-pub review on F1000Research or as eternal preprint on bioRxiv.&lt;/p>
&lt;p>To be clear: I have no problems with publishing at venues such as eLife, Genome Research, PLOS Computational Biology, or even Science or Nature. I think that the NIH Open Access mandate solves the majority of the access issues.&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> What I have a problem with is publishing in such journals and hiding that fact from your website while blogging about the evils of peer review. As long as you participate in the traditional peer-review system, as author, reviewer, or editor, you should be honest and transparent about where you publish.&lt;/p>
&lt;p>There are other reasons why I think hiding journal names is a bad idea, and I may go into them in a future blog post. For now, I’ll just present to you, without further comment, &lt;a href="https://scholar.google.com/citations?hl=en&amp;amp;user=GIjz5dMAAAAJ&amp;amp;view_op=list_works&amp;amp;sortby=pubdate">this Google Scholar profile.&lt;/a> In summary, hide journal names once everybody agrees that they don’t matter, but not one day earlier.&lt;/p>
&lt;p>&lt;strong>Update 12/11/2015:&lt;/strong> This discussion was featured in a &lt;a href="http://www.nature.com/news/what-s-in-a-journal-name-1.18987">Nature News article.&lt;/a>&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>I doubt that time will ever come, but let’s assume it will.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>To the extent possible, I make sure that my own papers get submitted to PubMed Central. The most recent papers &lt;a href="http://wilkelab.org/publications/">on my publication list&lt;/a> may not have PMC numbers yet, because it always takes a while until papers make their way into PubMed Central. Also, for papers for which I’m not the corresponding author, I cannot always ensure that they get submitted there.&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>The Google Scholar preprint bug redux</title><link>https://sevimcengiz.github.io/blog/2015/10/08/google-scholar-bug-redux/</link><pubDate>Thu, 08 Oct 2015 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2015/10/08/google-scholar-bug-redux/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>Regular readers of my blog will know that I regularly complain about Google Scholar’s handling of preprints, see e.g. &lt;a href="https://sevimcengiz.github.io/blog/2014/11/1/the-google-scholar-preprint-bug">here&lt;/a> or &lt;a href="https://sevimcengiz.github.io/blog/2014/12/2/how-google-scholar-discourages-young-scientists-from-posting-preprints">here.&lt;/a> Well, this week, I had the opportunity to &lt;a href="http://scholarlykitchen.sspnet.org/2015/10/05/guest-post-highwires-john-sack-on-online-indexing-of-scholarly-publications-part-1-what-we-all-have-accomplished/#comment-155912">raise my concerns&lt;/a> to Anurag Acharya, the co-founder of Google Scholar. &lt;a href="http://scholarlykitchen.sspnet.org/2015/10/05/guest-post-highwires-john-sack-on-online-indexing-of-scholarly-publications-part-1-what-we-all-have-accomplished/#comment-155918">His initial response&lt;/a> and the subsequent discussion have clarified several things. We now know:&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>The bug exists&lt;/li>
&lt;li>The Scholar team is aware of it&lt;/li>
&lt;li>They don’t know how to fix it&lt;/li>
&lt;li>They don’t think it’s a particularly pressing problem&lt;/li>
&lt;li>For any given paper, the problem will go away eventually, after several months or more&lt;/li>
&lt;/ol>
&lt;div id="so-what-is-this-bug-youre-talking-about" class="section level2">
&lt;h2>So what is this bug you’re talking about?&lt;/h2>
&lt;p>In a nutshell, for papers with a preprint, the bug will prevent the final, official journal publication to appear in the Scholar database, often for many months. If you search for the article by title, only the preprint version will show. If you search by DOI, nothing will show. Importantly, other articles from the same issue of the journal will all be properly indexed in Scholar, but the one article that happened to have a preprint will be missing.&lt;/p>
&lt;/div>
&lt;div id="why-should-i-care-if-the-problem-will-fix-itself-eventually" class="section level2">
&lt;h2>Why should I care if the problem will fix itself eventually?&lt;/h2>
&lt;p>Anybody who would like to encourage more scientists to post preprints should care. And any junior scientist should care twice. This bug can have a very real effect on the career of junior scientists, by limiting their visibility or making them appear much less successful or competent than they actually are. Here are a few very real scenarios the bug can cause:&lt;/p>
&lt;ul>
&lt;li>&lt;p>You know that John Smith posted an interesting preprint 2 years ago, and you wonder if that work was ever published. You search Google Scholar and only find the preprint. So you conclude the paper never saw the light of day or maybe is embattled in review. In truth, the paper came out 8 months ago in PNAS, but Google Scholar will hide that version from you.&lt;/p>&lt;/li>
&lt;li>&lt;p>You consider hiring a promising young scientist as a postdoc or maybe even a faculty member. However, as you pull up their Google Scholar profile, you notice that over the last two years they seem to have published only preprints. And several of the articles they list on their cv don’t show up in the Scholar database at all. You conclude the scientist is dishonest and you decline the application.&lt;/p>&lt;/li>
&lt;li>&lt;p>You post a preprint that contains an error. Thankfully, the error gets noticed in review and you fix it for the final publication (and/or post a new version of the preprint). However, Google Scholar keeps showing the old, erroneous version of the preprint, many months after the fix has been made. People keep reading the erroneous version and keep giving you grief over it.&lt;/p>&lt;/li>
&lt;li>&lt;p>An important paper in your field is published, and you would like to know about it. However, since the paper had a preprint, the official article is hidden from Scholar, and Scholar won’t notify you that it came out.&lt;/p>&lt;/li>
&lt;/ul>
&lt;/div>
&lt;div id="but-it-happens-only-very-rarely-right" class="section level2">
&lt;h2>But it happens only very rarely, right?&lt;/h2>
&lt;p>That’s the stance of the Scholar team. It doesn’t mesh with my experience, though. Everybody I know who regularly posts preprints has been bitten by the bug. I cross my fingers every time I post one. And whenever I bring up this issue, some random person mentions that they have experienced the same. Also, my colleague Chris Adami just posted the following:&lt;/p>
&lt;blockquote class="twitter-tweet" data-conversation="none" lang="en">
&lt;p lang="en" dir="ltr">
. &lt;a href="https://twitter.com/ClausWilke">&lt;span class="citation">@ClausWilke&lt;/span>&lt;/a> A cursory look at just the first page of my Google Scholar shows that about half of my articles are affected by this bug.
&lt;/p>
— Christoph Adami (&lt;span class="citation">@ChristophAdami&lt;/span>) &lt;a href="https://twitter.com/ChristophAdami/status/652126221254397952">October 8, 2015&lt;/a>
&lt;/blockquote>
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>While this bug may be rare in some sense of the word “rare,” it happens frequently enough to be a real issue for real scientists and every-day users of Google Scholar.&lt;/p>
&lt;/div>
&lt;div id="is-there-a-workaround" class="section level2">
&lt;h2>Is there a workaround?&lt;/h2>
&lt;p>Not really. You can add papers manually to your Google Scholar profile, but that won’t make them show up in the search results. And they will also not be linked to the actual journal publications, a major drawback in my opinion. If you know of a preprint and are wondering whether it has been published or not, don’t check with Scholar. Check with some other data base, such as PubMed. Or just do a regular Google search. The preprint bug does not affect regular Google, which will find the papers that Google Scholar doesn’t know about.&lt;/p>
&lt;p>I hope that the Google Scholar team will eventually realize that this is an important issue to get right. In the mean time, if you have been bitten by the bug, please let me know, so we can build a record of cases and demonstrate this is an important issue. And, if you’re looking for the official publications of long-standing preprints, look for them using regular Google, not Google Scholar.&lt;/p>
&lt;/div></description></item><item><title>Safety projects</title><link>https://sevimcengiz.github.io/blog/2015/07/01/safety-projects/</link><pubDate>Wed, 01 Jul 2015 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2015/07/01/safety-projects/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>If you’ve been in science long enough, eventually you’ll have reached a point where you needed a safety project, either for yourself or for a student. A safety project is a project whose success is all but guaranteed, that doesn’t require much in terms of critical thinking or properly aligned stars. All that is required to complete a safety project is proper execution of the work.&lt;/p>
&lt;p>The most common example I see is the graduate student in year four or five who doesn’t have a single completed project but needs to graduate in a year. Alternatively, maybe tenure is looming and your cv looks thin, you need some papers on a given topic before you can submit a grant on that topic, or you’re a postdoc looking for a job and you don’t have that many papers yet. In all these cases, it’s a good idea to pursue a safety project. More generally, it’s a good idea to have a portfolio of different projects where some are high-risk, high-reward and some are low-risk safety projects that you know will give you some sort of publication at the end. So let’s take a look at a couple of generic types of safety projects that can be pursued in almost any research field you may be working in.&lt;/p>
&lt;div id="repeat-previous-study-with-larger-sample-size-or-expanded-conditions" class="section level2">
&lt;h2>Repeat previous study with larger sample size or expanded conditions&lt;/h2>
&lt;p>It is always possible to just redo an earlier study but to increase the scope somewhat. Choose a larger sample size, add experimental conditions, or use more recent raw data (if you’re doing bioinformatics). As long as your lab has the technical capability to carry out the study in the first place, there is really nothing that can go wrong here.&lt;/p>
&lt;/div>
&lt;div id="benchmark-or-compare-competing-methods" class="section level2">
&lt;h2>Benchmark or compare competing methods&lt;/h2>
&lt;p>For virtually any problem one might want to investigate, there are competing approaches to carry out the analysis. And it is rarely the case that we completely understand which approach is better, and under which conditions. So compare a couple of competing approaches in your area. Test them under a couple of different, carefully controlled conditions, and see how they perform.&lt;/p>
&lt;/div>
&lt;div id="write-a-methods-or-software-paper" class="section level2">
&lt;h2>Write a methods or software paper&lt;/h2>
&lt;p>If you have been working on some research topic for a while, chances are you have found some new ways of doing certain experiments, or you have written some software to do certain analyses. Thus, even if the actual experiments you have done don’t tell an interesting story, you may be able to just flesh out the methods or software you have developed and publish those.&lt;/p>
&lt;/div>
&lt;div id="review-the-literature-on-a-topic" class="section level2">
&lt;h2>Review the literature on a topic&lt;/h2>
&lt;p>Literature reviews are often overlooked as serious scholarly contributions, in particular by graduate students and postdocs. And while scientists who only ever write reviews will likely develop the reputation of never having an original thought, there’s nothing wrong with writing the occasional review to bolster your resume, in particular early in your career. If you’re a graduate student or postdoc and your original research hasn’t been that successful lately, you can at least write a review on the area you’re working on. Publishing a review demonstrates both your understanding of the field and your ability to complete a project. I’d rather hire a scientist who has published one original research article and one review than one who has published only one original research article.&lt;/p>
&lt;p>Can you think of other types of projects that are generally safe and rely only on careful execution? If so, please let me know in the comments.&lt;/p>
&lt;/div></description></item><item><title>PLOS ONE publishes analysis of grant writing costs and benefits</title><link>https://sevimcengiz.github.io/blog/2015/03/24/plos-one-publishes-analysis-of-grant-writing-costs-and-benefitssafety-projects/</link><pubDate>Tue, 24 Mar 2015 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2015/03/24/plos-one-publishes-analysis-of-grant-writing-costs-and-benefitssafety-projects/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>PLOS ONE just published an article providing a cost-benefit analysis of grant writing:&lt;/p>
&lt;blockquote>
&lt;p>von Hippel T, von Hippel C (2015) &lt;a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0118494">To Apply or Not to Apply: A Survey Analysis of Grant Writing Costs and Benefits.&lt;/a> PLoS ONE 10(3): e0118494.&lt;/p>
&lt;/blockquote>
&lt;p>One of the main take-home messages: If you write more grants you will get more funding. Also, at current funding rates, unless you’re writing 2-3 proposals a year, you have a reasonable chance of going unfunded over a three-year period. The authors suggest that investigators should avoid programs with funding rates at 20% or less unless they are willing to write multiple proposals a year and/or have a particularly compelling research program. However, in biology practically all funding rates are 20% or less these days, so that advice isn’t very helpful. Instead, we just need to keep writing proposals. If you’re after NIH funding, you should probably write at least one proposal per cycle, unless you’ve been recently funded. If you’re primarily after NSF funding, with yearly cycles, you’ll have to diversify and find at least two programs to which you can send your proposals.&lt;/p></description></item><item><title>Teaching a new introductory class in computational biology and bioinformatics</title><link>https://sevimcengiz.github.io/blog/2015/02/04/teaching-a-new-introductory-class-in-computational-biology-and-bioinformatics/</link><pubDate>Wed, 04 Feb 2015 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2015/02/04/teaching-a-new-introductory-class-in-computational-biology-and-bioinformatics/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>This semester, I’m teaching a new introductory class in computational biology and bioinformatics. The class is primarily targeted at undergraduates, and it is split approximately 50:50 between R and python. The R component emphasizes effective data analysis and visualization, using packages such as ggplot2 and dplyr. The python component will introduce students to basic programming concepts, and it will also cover some typical bioinformatics applications.&lt;/p>
&lt;p>Developing a new class is a lot of work, so I’ll probably have much less time for posting here on my blog. However, on the flip side, the entire course content will be posted online, and you can &lt;a href="https://wilkelab.org/classes/SDS348_spring_2015.html">follow along here.&lt;/a> The core of each lecture is an in-class exercise worksheet, and I’m posting the worksheets and the solutions online. Many lectures also have a brief traditional lecture component with slides as well as additional reading materials. I’m developing the course as I go, so there will be new material posted twice a week throughout the spring.&lt;/p></description></item><item><title>What constitutes a citable scientific work?</title><link>https://sevimcengiz.github.io/blog/2015/01/02/what-constitutes-a-citable-scientific-work/</link><pubDate>Fri, 02 Jan 2015 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2015/01/02/what-constitutes-a-citable-scientific-work/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>There was a lively discussion on Twitter the other day regarding what constitutes a citable piece of scientific work. In particular, Matthew Hahn was concerned about where to draw the line, and he felt that unless something is traditionally published there’s &lt;a href="https://twitter.com/3rdreviewer/status/549365313331290112">no need to cite it.&lt;/a> When reading this dicussion, I felt it was muddled by the lack of clear criteria separating citable works from other forms of scientific communication. In my mind, there is a clear distinction between preprints, which I consider to be citable works, and presentation slides or tweets, which are not. To formalize this distinction, I would like to propose four conditions that need to be satisfied for a document to be considered a citable piece of scientific work. The document needs to be: (i) uniquely and unambiguously citable; (ii) available in perpetuity, in unchanged form; (iii) accessible to the public; (iv) self-contained and complete.&lt;/p>
&lt;div id="uniquely-and-unambiguously-citable" class="section level2">
&lt;h2>1. Uniquely and unambiguously citable&lt;/h2>
&lt;p>It must be possible to uniquely and unambiguously refer to the particular work in question. This condition may seem trivial, but that’s not necessarily the case. For example, during the aforementioned Twitter conversation, Matthew Hahn brought up the case where somebody might &lt;a href="https://twitter.com/3rdreviewer/status/549381166722469888">tweet an entire paper or talk.&lt;/a> Such a series of tweets would not be unambigously citable: One can cite an individual tweet but not a collection of tweets. While one could cite the first tweet in a series, assuming subsequent tweets were posted as replies, it would still remain ambiguous which specific tweets should be considered to comprise the entirety of the work. What if other users replied to the first tweet as well? And what if the original author then responded to them? The very nature of Twitter is such that the unique, citable unit is a single tweet, 140 characters or less, and that is not sufficient to convey a self-contained and complete scientific work. (Note that tweets also fail condition 2, since they can be deleted.)&lt;/p>
&lt;/div>
&lt;div id="available-in-perpetuity-in-unchanged-form" class="section level2">
&lt;h2>2. Available in perpetuity, in unchanged form&lt;/h2>
&lt;p>There needs to be some guarantee that the referenced document will not change and will be available in perpetuity. While nothing is truly forever, and works tend to get lost over time, documents hosted according to industry standards by large and established non-profit or for-profit publishing operations are not likely to disappear any time soon. This certainly includes documents posted on the preprint server &lt;a href="https://arxiv.org/">arxiv.org,&lt;/a> and probably also on the &lt;a href="https://biorxiv.org/">biorxiv&lt;/a> server. Moreover, professional publishing operations generally do not allow changes to once-published documents, though they may allow for the publication of updates or revised article versions.&lt;/p>
&lt;p>Importantly, most privately hosted web sites and blogs do not satisfy this requirement.&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> If I stop paying my web-hosting bill, this blog will disappear rather quickly. Similarly, any day I could decide that I didn’t like a particular post and rewrite or delete it, or I could delete the entire blog. And the same is true for institutionally hosted pages or lab web pages. Only those publishing platforms that are built with the express purpose of allowing perpetual access provide some amount of certainty that documents won’t just disappear or change.&lt;/p>
&lt;/div>
&lt;div id="accessible-to-the-public" class="section level2">
&lt;h2>3. Accessible to the public&lt;/h2>
&lt;p>The document needs to be accessible to the public. This condition doesn’t necessarily require that access be free (though I personally would prefer it to be this way), since we have traditionally accepted that certain scientific works are only available after payment of a fee. However, anybody willing to pay the fee must be able to access the work, without any other conditions imposed. Also, libraries must be allowed to carry the work, and any library patrons must be able to peruse the work for free.&lt;/p>
&lt;p>The point of this condition is to exclude internal technical documents of companies or other organizations, in particular, documents that might require signing a non-disclosure agreement. Such documents may be useful but they do not belong into the scientific record.&lt;/p>
&lt;/div>
&lt;div id="self-contained-and-complete" class="section level2">
&lt;h2>4. Self-contained and complete&lt;/h2>
&lt;p>The document needs to be self-contained and complete. In other words, whatever the novel contribution is of a given piece of work, that contribution needs to be fully and clearly explained within the document. Many forms of scientific communication violate this condition. Consider for example the slides of a scientific presentation. They are meant merely as support to the oral presentation, and usually they cannot be fully understood without the accompanying talk. Now, if one wanted to, one could certainly write slides that are self-contained and complete. However, those slides would make for a poor talk and also would be nothing more than an awkwardly formatted preprint.&lt;/p>
&lt;p>Even if a recording of the talk is provided alongside the slides, the completeness condition will usually remain violated. For example, methodological details are frequently glossed over in presentations, as are parts of mathematical derivations in theoretical talks. However, this doesn’t mean that only written works can be scientific documents. For example, the &lt;a href="http://www.jove.com/">Journal of Visualized Experiments (JoVE)&lt;/a> publishes self-contained and complete video articles.&lt;/p>
&lt;/div>
&lt;div id="but-if-it-hasnt-been-reviewed" class="section level2">
&lt;h2>But if it hasn’t been reviewed?&lt;/h2>
&lt;p>I am a strong proponent of pre-publication review. &lt;a href="https://sevimcengiz.github.io/blog/2013/12/21/the-value-of-pre-publication-peer-review">I have said so before.&lt;/a> At the same time, I am wary of what I’d like to call “the review fetish,” the attitude that scientific works can’t be trusted until they have been reviewed, at which point they become valid contributions to the scientific literature. Whether something has been reviewed has no bearing on its validity. A work is valid or it is not, period. We all know that flawed works pass peer review and valid works get rejected. In fact, the most influential and highly cited articles often get rejected initially.&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> As working scientists, we need to personally judge the validity of each and every article we read, regardless of the article’s origin or review status.&lt;/p>
&lt;p>Also, the only logical reason to require citable works to be peer reviewed would be as a means of quality control, so that bad science doesn’t get cited. However, it then immediately follows that we would have to assess the quality of peer review at each journal. What if some journals carry out sub-standard review and basically print everything? Should they be put on a blacklist of journals we can’t cite? What about contributed papers to PNAS, many of which likely haven’t received the same kind of scrutiny as articles that get edited by independent third parties? What about journals that employ professional editors, who may make decisions that aren’t always entirely driven by scientific considerations? Should we put those journals on the blacklist? In my mind, insisting on peer review for quality control reasons opens a can of worms that simply can’t be dealt with in any reasonable manner.&lt;/p>
&lt;p>Further, while the current scientific culture expects that we submit all our articles to journals for review, I think scientists should be allowed to choose not to be subjected to this process. If some scientists prefer to skip peer review and simply post their work on a preprint server, it should be their prerogative to do so. And we should take their work seriously as long as it is worthwhile and of high quality. Clearly mathematicians do so. Consider the case of &lt;a href="http://en.wikipedia.org/wiki/Grigori_Perelman">Grigori Perelman,&lt;/a> who was awarded a Fields Medal, the highest honor bestowed upon mathematicians, for work he had posted on a preprint server but never formally published.&lt;/p>
&lt;p>Finally, I would like to point out that there are document types that have traditionally been considered part of the scholarly literature, such as monographs or dissertations, that are not necessarily reviewed. &lt;a href="http://haldanessieve.org/2013/08/26/thoughts-on-mbes-preprint-citation-policy/">Journals that forbid citations to preprints&lt;/a> do not usually impose similar restrictions on the citation of books or theses.&lt;/p>
&lt;/div>
&lt;div id="concluding-thoughts" class="section level2">
&lt;h2>Concluding thoughts&lt;/h2>
&lt;p>With the four conditions I have outlined, we can easily test whether specific documents or works should be considered to be citable resources or not. Strings of tweets clearly fail the test, as do slides, recordings of talks, posters, tweets of photos of posters, or blog posts. Documents that pass the test are articles in traditional print journals, articles in most professionally operated online journals, books, book chapters, dissertations, and preprints deposited on professionally operated preprint servers. Interestingly, websites hosting scientific software will usually fail at least conditions 2 and 3, and thus would not be citable by my criteria. In fact, it is my opinion that scientific software should always be accompanied by an article introducing and explaining the software, and what we should cite is the article, not the website where the software is housed.&lt;/p>
&lt;p>Importantly, I can think of no principled test that would cleanly separate preprints from the rest of the scientific literature. The only such test I can think of is “has it been posted on a preprint server,” but it would be difficult to provide a logical reason for why this test should be applied to determine the citability of a document,&lt;a href="#fn3" class="footnote-ref" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a> other than personal preference. I might just as well not cite articles published in journals that don’t use at least 3 reviewers, or in journals where editorial decisions are made by professional editors and not by working scientists, or in journals that typeset their articles in a sans-serif font.&lt;/p>
&lt;p>&lt;strong>Update 01/02/2015:&lt;/strong> Rafael Najmanovich &lt;a href="https://twitter.com/RNajmanovich/status/551155998350901248">suggested an additional condition:&lt;/a> Attributable authorship. It should be clear who has written a specific document. While I agree with this condition in principle, I’m not sure yet whether I would go so far as arguing that anonymous documents should never be cited. If a document is anonymous but otherwise a valid contribution to science, should we ignore it? Probably not.&lt;/p>
&lt;/div>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>Klein et al. (2014) Scholarly context not found: One in five articles suffers from reference rot. PLoS ONE 9: e115253. &lt;a href="https://doi.org/10.1371/journal.pone.0115253">doi:10.1371/journal.pone.0115253&lt;/a>&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>Siler et al. (2014) Measuring the effectiveness of scientific gatekeeping. PNAS, in press. &lt;a href="https://doi.org/10.1073/pnas.1418218112">doi:10.1073/pnas.1418218112&lt;/a>&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>Keep in mind that this entire post is about the conditions that make a document a &lt;em>citable&lt;/em> contribution to the scientific literature. This is different from the question of whether a document is a preprint or a formally published article. The main services that journals provide are (i) quality control, in the form of editorial and peer review, (ii) prestige, in proportion to how selective they are, and (iii) professional typesetting, though the quality of this service has declined in recent years. In return, journals demand exclusivity. Thus, it is natural for a journal to determine whether a document has been previously published by asking whether the document has previously undergone editorial and peer review and has been professionally typeset. Importantly, when journals make this assessment, they are not concerned with the quality of peer review. Any document that has been reviewed and accepted for publication elsewhere, no matter how low the standards, would violate the exclusivity clause and hence is going to be considered published.&lt;a href="#fnref3" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>How to prepare an article for resubmission, Part II</title><link>https://sevimcengiz.github.io/blog/2014/12/18/how-to-prepare-an-article-for-resubmission-part-ii/</link><pubDate>Thu, 18 Dec 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/12/18/how-to-prepare-an-article-for-resubmission-part-ii/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>In my previous post on &lt;a href="https://sevimcengiz.github.io/blog/2014/11/16/how-to-prepare-an-article-for-resubmission">how to prepare an article for resubmission,&lt;/a> I failed to mention one important point: In your response to the reviewers, quote the &lt;em>entire&lt;/em> referee report, even the introductory sentences. Don’t just quote the specific comments to which you are replying. This may seem unnecessary but it is in fact crucial, in particular if the introductory sentences were largely positive. (If they were highly critical, you may want to omit them, even though in this case you probably should provide a response.)&lt;/p>
&lt;p>Keep in mind that when the revised manuscript goes back to the editor and the previous reviewers, neither will remember the exact thoughts they had when they previously looked at your manuscript. In addition, the reviewers may never actually have seen the comments of the other reviewers. And finally, most editors and reviewers will look at your response to the reviewer comments before they look at anything else related to your manuscript. Thus, this is your opportunity to remind the editor and the reviewers that your manuscript overall was judged to be interesting and valuable, even if there were some issues to be addressed. By not quoting these comments, you only highlight the critical aspects of the previous reviews. For the same reasons, it is often a good idea to start the response with a brief summary of the overall reviewer sentiments, such as: “Reviewers 1 and 2 thought the manuscript addressed an important topic and had only minor comments. Reviewer 3 was more critical but also acknowledged the timeliness of our work.”&lt;/p></description></item><item><title>Relationship between h index and total citations count</title><link>https://sevimcengiz.github.io/blog/2014/12/08/relationship-between-h-index-and-total-citations-count/</link><pubDate>Mon, 08 Dec 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/12/08/relationship-between-h-index-and-total-citations-count/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>I came across an interesting paper&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> that derives a mathematical relationship between the total number of citations a scientist has received, &lt;span class="math inline">\(N_\text{tot}\)&lt;/span>, and the scientist’s &lt;span class="math inline">\(h\)&lt;/span> index.&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> The paper, written by Alexander Yong, argues that for typical scientists, &lt;span class="math inline">\(h\)&lt;/span> is given simply as 0.54 times the square-root of &lt;span class="math inline">\(N_\text{tot}\)&lt;/span>. The paper also derives confidence bounds on this estimate, and it shows that scientists who have written only a few highly-cited works will generally fall below this estimate. While the paper is set up as a critique of the &lt;span class="math inline">\(h\)&lt;/span> index, I think it shows that the &lt;span class="math inline">\(h\)&lt;/span> index works largely as intended. It measures the total amount of citations a researcher has received, but it adequately down-weighs the effect of a few extremely highly cited works in a researcher’s publication list.&lt;/p>
&lt;p>The argument of the paper goes as follows: Let’s consider all the possible ways in which a researcher’s &lt;span class="math inline">\(N_\text{tot}\)&lt;/span> citations may be distributed over a number of publications. On one extreme, the researcher could have written a single article, which has been cited &lt;span class="math inline">\(N_\text{tot}\)&lt;/span> times. On the other extreme, the researcher could have written &lt;span class="math inline">\(N_\text{tot}\)&lt;/span> articles, which all have been cited exactly once. And of course, there are many possibilities between those extremes, where some articles receive more citations and others fewer. The paper then assumes that all these different ways in which &lt;span class="math inline">\(N_\text{tot}\)&lt;/span> citations can be distributed over one or more articles are equally likely, and calculates the expected &lt;span class="math inline">\(h\)&lt;/span> under that assumption. That value, it turns out, is approximately &lt;span class="math inline">\(0.54 \times N_\text{tot}^{1/2}.\)&lt;/span> The paper then tests this relationship for a number of famous mathematicians (Fields-medal winners and members of the National Academy of Sciences) and finds that it generally works quite well, though typically as an upper bound. It is rare for a scientist to have &lt;span class="math inline">\(h\)&lt;/span> exceed the predicted value of &lt;span class="math inline">\(0.54 \times N_\text{tot}^{1/2}.\)&lt;/span> On the flip side, many scientists who have written famous, highly cited books have an &lt;span class="math inline">\(h\)&lt;/span> quite a bit lower than the predicted value, because the books cause the total citation count to be overinflated.&lt;/p>
&lt;p>I wanted to know to what extent this formula worked in a different field. So I tested it on the members of my department. For each faculty member&lt;a href="#fn3" class="footnote-ref" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a> of the Department of Integrative Biology, I obtained their total number of citations and their &lt;span class="math inline">\(h\)&lt;/span> index from Google Scholar, and then I plotted the observed &lt;span class="math inline">\(h\)&lt;/span> against the predicted &lt;span class="math inline">\(h\)&lt;/span> using Yong’s formula (Figure &lt;a href="#fig:figure1">1&lt;/a>). As you can see, the formula works remarkably well. Almost everybody falls right on top of the line. Importantly, this sample covers a wide range of different career stages.&lt;/p>
&lt;div class="figure">&lt;span id="fig:figure1">&lt;/span>
&lt;img src="observed_v_predicted_h.png" alt="Observed vs. predicted \(h\) for 29 faculty members in Integrative Biology. Members of the National Academy are plotted in red." width="80%" />
&lt;p class="caption">
Figure 1: Observed vs. predicted &lt;span class="math inline">\(h\)&lt;/span> for 29 faculty members in Integrative Biology. Members of the National Academy are plotted in red.
&lt;/p>
&lt;/div>
&lt;p>Three faculty members are plotted in red in the figure: those are members of the National Academy, and they are the highest-cited scientists in the department. Interestingly, two have very high total citation counts but, in comparison, not that high of an &lt;span class="math inline">\(h\)&lt;/span> index, while one has the highest overall &lt;span class="math inline">\(h\)&lt;/span> index with comparatively fewer citations. The former two both have written famous books, and many of their citations are to these books. By contrast, the latter scientist stands out by having published a particularly large number of articles that all have been well cited. In fact, that scientist is performing slightly better than the &lt;span class="math inline">\(h = 0.54 \times N_\text{tot}^{1/2}\)&lt;/span> prediction, a truly remarkable result at that high of a total citation count.&lt;/p>
&lt;p>In summary, I find that the predicted relationship between &lt;span class="math inline">\(h\)&lt;/span> and &lt;span class="math inline">\(N_\text{tot}\)&lt;/span> works well in my field. However, since major deviations between this relationship can be observed for scientists with a few extremely highly cited works, I prefer using &lt;span class="math inline">\(h\)&lt;/span> instead of &lt;span class="math inline">\(N_\text{tot}\)&lt;/span> to estimate a scientist’s total impact on their field.&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>A. Yong (2014). &lt;a href="https://doi.org/10.1090/noti1164">Critique of Hirsch’s Citation Index: A Combinatorial Fermi Problem.&lt;/a> &lt;em>Notices of the AMS&lt;/em> 61:1040-1050.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>The &lt;span class="math inline">\(h\)&lt;/span> index is the number of papers a scientist has written that have received at least &lt;span class="math inline">\(h\)&lt;/span> citations. For example, if you have &lt;span class="math inline">\(h = 10\)&lt;/span>, then you have written 10 papers that have been cited 10 or more times. You may have written more than 10 papers total, but none of the other papers you may have written has received more than 10 citations yet.&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>To be precise, each faculty member with a Google Scholar profile. This covers almost but not exactly the entire department.&lt;a href="#fnref3" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>How Google Scholar discourages young scientists from posting preprints</title><link>https://sevimcengiz.github.io/blog/2014/12/02/how-google-scholar-discourages-young-scientists-from-posting-preprints/</link><pubDate>Tue, 02 Dec 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/12/02/how-google-scholar-discourages-young-scientists-from-posting-preprints/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>I have previously blogged about the issues that &lt;a href="https://sevimcengiz.github.io/blog/2014/11/1/the-google-scholar-preprint-bug">preprints can cause on Google Scholar.&lt;/a> Today I was reminded that these issues have real-world implication for junior scientists, and that they may discourage junior scientists from posting preprints.&lt;/p>
&lt;p>I had the following conversation with one of my students (paraphrased):&lt;/p>
&lt;p>&lt;em>Me:&lt;/em> So, do you want to post the paper we just submitted as a preprint?&lt;/p>
&lt;p>&lt;em>Student:&lt;/em> No, not really.&lt;/p>
&lt;p>&lt;em>Me:&lt;/em> Are you concerned about keeping your competitive advantage, so you can finish a second paper on the topic before we reveal to the world what we’re up to?&lt;br />
&lt;em>(With this particular paper, I had wondered whether we should submit it as a preprint or not. There are a number of obvious follow-up works we can do relatively quickly, and so could others.)&lt;/em>&lt;/p>
&lt;p>&lt;em>Student:&lt;/em> No, I’m not particularly worried about that. I just don’t want Google Scholar to list my paper as bioRxiv for the next few years, way past the time the paper has actually come out. Several of my current papers are still listed as their preprint version even though they’ve appeared ages ago. Maybe once I have 100 papers and 10,000 citations I won’t care anymore, but at my current stage I can’t afford having Google Scholar obscure my record by listing all my papers in their preprint version only.&lt;/p>
&lt;p>&lt;strong>Update #1, 12/03/2014:&lt;/strong> I’m getting a lot of comments to the effect that one can edit the Google Scholar profile. A couple to responses to that:&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;p>Yes, there are manual workarounds for most issues. That doesn’t mean the default behavior of Scholar is not &lt;em>discouraging&lt;/em>.&lt;/p>&lt;/li>
&lt;li>&lt;p>Merging of articles doesn’t work when the &lt;a href="https://sevimcengiz.github.io/blog/2014/11/1/the-google-scholar-preprint-bug">preprint shadows the final article,&lt;/a> because the final article is simply not visible in the Scholar database.&lt;/p>&lt;/li>
&lt;li>&lt;p>Even if you fix your own profile, that doesn’t fix how the article appears on your co-authors’ profile or in a general search for the article, e.g. by title.&lt;/p>&lt;/li>
&lt;li>&lt;p>It is not clear what happens to citations of shadowed articles. Are they or are they not counted? We don’t know. There’s certainly the worry that they are not.&lt;/p>&lt;/li>
&lt;li>&lt;p>The only way I know to fix shadowed articles &lt;em>on your own profile&lt;/em> is to manually add the reference, then merge, and then undo all of that a year later when Scholar has finally caught up to the existence of your article. It’s cumbersome, prone to errors, and certainly &lt;em>discouraging.&lt;/em>&lt;/p>&lt;/li>
&lt;/ol>
&lt;p>I will not stop posting preprints. But I will also not pretend everything is fine with Google Scholar and preprints when there are some glaring issues. Google Scholar is being used increasingly by departments in hiring and promotion decisions. Scientists should rightfully worry about how their work does or does not appear on Scholar.&lt;/p>
&lt;p>&lt;strong>Update #2, 12/03/2014:&lt;/strong> So it turns out manually editing entries doesn’t work as expected when articles are shadowed by their preprint. You can add the reference, but you cannot make it link to the correct article. Check out &lt;a href="https://scholar.google.com/citations?view_op=view_citation&amp;amp;hl=en&amp;amp;user=Vssu9d0AAAAJ&amp;amp;sortby=pubdate&amp;amp;citation_for_view=Vssu9d0AAAAJ:nrtMV_XWKgEC">this entry.&lt;/a> The title is not clickable, and the Scholar articles listed at the bottom do not include any links to the actual journal version of the article (or even the latest preprint version).&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>My statements are correct as of 12/03/2014. Eventually Google Scholar will catch up and the links will appear.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>How to prepare an article for resubmission</title><link>https://sevimcengiz.github.io/blog/2014/11/16/how-to-prepare-an-article-for-resubmission/</link><pubDate>Sun, 16 Nov 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/11/16/how-to-prepare-an-article-for-resubmission/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>So your latest scientific masterpiece has come back from review with the most likely outcome other than rejection: major revision. The reviewers and the editor think that your work has merit, but they also have a long list of comments and criticism that they expect you to address before the article is acceptable for publication. You read the reviews and you feel like they lay out two years worth of work. How do you best deal with this situation?&lt;/p>
&lt;div id="your-life-will-be-easier-if-you-understand-everybodys-objectives" class="section level2">
&lt;h2>Your life will be easier if you understand everybody’s objectives&lt;/h2>
&lt;p>Let’s first consider the perspective of the three groups of people involved: the editor, the reviewers, and the authors (i.e., you). The editor wants to make sure there are no major problems with your paper, in particular problems that would potentially embarrass her&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> down the line. So the editor will pay close attention to any points the reviewers raise that look like your work might be flawed. She will generally be less worried about whether you actually do every additional analysis the reviewers suggest. A good editor knows that most reviewers will suggest more changes than are strictly necessary to get the paper publication ready.&lt;/p>
&lt;p>The reviewers, primarily, will want to be recognized for their knowledge of the field. They want you to acknowledge that they noticed or knew something you didn’t. Even if it may not seem that way, most reviewer comments are written as constructive criticism, suggestions from the reviewers to you on how you could improve your work. As long as your revisions acknowledge the reviewers’ views, you should be fine. However, on occasion, a reviewer thinks that something you’re doing is fundamentally flawed. In those cases, you may have to put in some extra effort to appease the reviewer.&lt;/p>
&lt;p>I assume you know what your objective is in this interaction, but in case you had doubts I’ll tell you: You want to get the paper published with as little extra work as possible. You thought your paper was done when you first submitted, so any additional work you’re asked to do amounts to pointless busywork from your perspective.&lt;/p>
&lt;p>Now that we know what everybody’s objectives are in this game, let’s discuss some strategies for successful resubmission.&lt;/p>
&lt;/div>
&lt;div id="start-by-drafting-a-response-to-the-reviewers" class="section level2">
&lt;h2>1. Start by drafting a response to the reviewers&lt;/h2>
&lt;p>The absolute worst thing you can do after having received reviewer comments is to run back into the lab and start all the additional experiments the reviewers want you to do. This will drag you down a rabbit hole that you will find difficult to come out of, and you will waste a lot of time doing unnecessary work. You need a clear plan of what to do. The best way to develop that plan is to start drafting a response to the reviewers. Copy all the reviewer comments into a file, mark them in some color other than black (I like blue), and then start adding your responses in black.&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> See how many reviewer points you can dispense with by writing a response that requires only very minor edits to your manuscript.&lt;/p>
&lt;p>For the reviewer points that require more extensive rewriting or additional experiments, write out a plan of what you will do to address these points. I like to highlight the parts in the response that I still have to address in the manuscript, and I remove the highlights once I have done so. In this way, I don’t lose track of which edits I have or haven’t done.&lt;/p>
&lt;p>From what I have seen, the winning strategy employed by some of the most experienced and successful scientists is to write a very long, detailed response and keep the actual manuscript edits to a minimum. It’s not unusual to see a 5 page response to the reviewers accompanying very minor revisions in the actual paper, a few sentences added here and there, and a few additional references thrown in for good measure. These scientists have, over the years, developed a good sense of the minimum amount of work they can get away with and still have their revisions accepted.&lt;/p>
&lt;/div>
&lt;div id="realize-that-the-reviewer-is-always-right" class="section level2">
&lt;h2>2. Realize that the reviewer is always right&lt;/h2>
&lt;p>Regardless of how inane a reviewer’s comments may seem, the reviewer is always right. You don’t gain anything from being upset about the reviewer’s incompetence or lack of knowledge in your area. Instead, think why the reviewer may have reacted the way he did. Maybe you didn’t explain something carefully enough, or you assumed something was widely known that actually isn’t. In your response to the reviewers, always acknowledge the validity of the reviewers’ comments, and then either try to explain the issue in the response or modify the manuscript appropriately.&lt;/p>
&lt;/div>
&lt;div id="take-the-reviewer-comments-seriously" class="section level2">
&lt;h2>3. Take the reviewer comments seriously&lt;/h2>
&lt;p>It’s very easy to discount reviewer comments and say “the reviewer knows nothing about this topic.” Often the reviewer knows more than you may think, and you may simply not be understanding the reviewer’s point of view. (I’ve certainly reviewed more than one paper where I felt the authors were simply not getting what I was trying to tell them.) So make a serious effort and try to figure out what exactly it is the reviewer wants and how you can make it happen.&lt;/p>
&lt;/div>
&lt;div id="cite-every-reference-the-reviewers-mention" class="section level2">
&lt;h2>4. Cite every reference the reviewers mention&lt;/h2>
&lt;p>Sometimes it’s very clear that a reviewer wants you to cite a given paper while at other times it may seem like citing certain papers is optional. (Example: “In this context, the authors could consider citing Jones et al. 1975.”) Either way, cite all mentioned papers unless they are totally inappropriate. Regardless of whether the reviewer actually is Jones himself, or only is good friends with Jones, or simply thinks that the Jones et al. paper was a breakthrough for the field, the reviewer clearly cares for Jones et al. 1975. Therefore, he will have a little more respect for you if you demonstrate that you care for Jones et al. 1975 as well.&lt;/p>
&lt;/div>
&lt;div id="openly-admit-to-your-works-limitations-and-shortcomings" class="section level2">
&lt;h2>5. Openly admit to your work’s limitations and shortcomings&lt;/h2>
&lt;p>When reviewers point out that the research performed has certain shortcomings and limitations, junior scientists will often think they have to overcome these limitations before the work can be published. However, more often than not, all that is needed is a clear statement that these limitations exist and should be addressed in future work. Between this strategy and #4 (cite additional papers), you can probably handle at least 60-70% of all reviewer comments without doing any additional experiments or analysis.&lt;/p>
&lt;/div>
&lt;div id="understand-that-reviewer-comments-are-written-as-much-for-the-editor-as-they-are-for-you" class="section level2">
&lt;h2>6. Understand that reviewer comments are written as much for the editor as they are for you&lt;/h2>
&lt;p>The reviewer doesn’t just want to criticize your work, he also wants to make a good impression in front of the editor, who may be a close colleague, former advisor, or general heavyweight in the reviewer’s field of research. For this reason, the reviewer will always come up with at least a handful of points to criticize, just so he doesn’t appear lazy or incompetent. You will have to figure out which of the comments actually address crucial limitations of your paper and which were written just to impress the editor. The latter ones can always be dispatched with a combination of strategies #4 and #5.&lt;/p>
&lt;/div>
&lt;div id="say-no-to-excessive-requests" class="section level2">
&lt;h2>7. Say “No” to excessive requests&lt;/h2>
&lt;p>Finally, be aware that it is perfectly acceptable to not do certain things the reviewers ask for. Unless the validity of your core findings is at doubt, you always have the option of saying something like “these additional analyses are beyond the scope of the current work: or”we agree that the reviewer’s suggestion should be pursued in future work, and we now say so in the Discussion." In case of doubt, don’t do the extra work, just say “No”.&lt;/p>
&lt;p>&lt;strong>Update 12/18/2014:&lt;/strong> Also read &lt;a href="https://sevimcengiz.github.io/blog/2014/12/18/how-to-prepare-an-article-for-resubmission-part-ii">my follow-up post&lt;/a> on this topic.&lt;/p>
&lt;/div>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>In this story, the editor is female and the reviewers are male.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>There’s a reason for the specific color choices I suggest. Your goal is to visually separate the reviewer comments from the responses. You could do this by making either the reviewer comments or the responses bold or italics. However, extended sections in italics tend to be hard to read, and extended sections in bold tend to be jarring. So colors are the best option. In your color choice, keep in mind that your responses need to be more visually present than the reviewer comments, because you want the reviewers and the editor to focus on your responses, not the reviewer comments, when they evaluate your revision. So your responses need to be in black, and the reviewer comments need to be in a color that doesn’t stand out relative to black. Blue is a good choice. Maybe green or gray would also work. Red or yellow would probably be bad choices.&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>The Google Scholar preprint bug</title><link>https://sevimcengiz.github.io/blog/2014/11/01/the-google-scholar-preprint-bug/</link><pubDate>Sat, 01 Nov 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/11/01/the-google-scholar-preprint-bug/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>Google Scholar has a serious bug when it comes to preprints. If you have published a preprint of your paper, the later journal publication can be completely invisible to Google Scholar, seemingly absent from their entire database. Even a search for the exact article title will not find the article. And this condition remains for months. (It will eventually fix itself, though. After about a year.) I have now seen this bug in action for several of my papers, and I am confident it’s a reproducible flaw and not a one-off. I reported the issue to the Google Scholar team about a year ago (or at least, I filled in some web form that seemed to be designed to send them feedback) but I have received no response and the bug clearly still exists. I hope that with this blog-post I can draw some attention to this serious issue, so we can have it fixed. Thousands of scientists rely on Google Scholar every day. For many recent articles, this bug will steer these scientists towards outdated, early versions and make the authoritative article versions completely inaccessible.&lt;/p>
&lt;p>As far as I can tell, what triggers the bug for sure is the publication of an updated version of the same article with a changed title or author list. It is possible that the same bug occurs even when title or author list hasn’t changed, but I haven’t noticed it under those conditions. Here is an example of this bug in action. My lab published the following article on BioRxiv on April 24, 2014:&lt;/p>
&lt;blockquote>
&lt;p>Amir Shahmoradi, Dariya K. Sydykova, Stephanie J. Spielman, Eleisha L. Jackson, Eric T. Dawson, Austin G.Meyer, Claus O. Wilke. Predicting evolutionary site variability from structure in viral proteins: buriedness, flexibility, and design. &lt;a href="https://www.biorxiv.org/content/10.1101/004481v1">doi:10.1101/004481&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>If you click on the link, you’ll see that BioRxiv encourages you to check out the latest version of the article, with slightly different title, posted on July 21, 2014:&lt;/p>
&lt;blockquote>
&lt;p>Amir Shahmoradi, Dariya K. Sydykova, Stephanie J. Spielman, Eleisha L. Jackson, Eric T. Dawson, Austin G.Meyer, Claus O. Wilke. Predicting evolutionary site variability from structure in viral proteins: buriedness, packing, flexibility, and design. &lt;a href="https://doi.org/10.1101/004481">doi:10.1101/004481&lt;/a>&lt;/p>
&lt;/blockquote>
&lt;p>The doi is the same, so clearly those are two subsequent versions of the same article. BioRxiv also knows that the article was published in its final form by the Journal of Molecular Evolution under &lt;a href="https://doi.org/10.1007/s00239-014-9644-x">doi:10.1007/s00239-014-9644-x&lt;/a> on September 13, 2014. Finally, the article has a PubMed entry (&lt;a href="https://www.ncbi.nlm.nih.gov/pubmed/25217382">PMID: 25217382&lt;/a>) and if you do a normal Google search using the complete, final article title the &lt;a href="https://www.google.com/search?q=Predicting+evolutionary+site+variability+from+structure+in+viral+proteins%3A+buriedness%2C+packing%2C+flexibility%2C+and+design&amp;amp;oq=Predicting+evolutionary+site+variability+from+structure+in+viral+proteins%3A+buriedness%2C+packing%2C+flexibility%2C+and+design&amp;amp;aqs=chrome..69i57j69i59j69i60l3.549j0j1&amp;amp;sourceid=chrome&amp;amp;es_sm=91&amp;amp;ie=UTF-8">top three hits&lt;/a> are two different preprint postings and the final journal article.&lt;/p>
&lt;p>Now that we have established that the article clearly exists, has been published in its final form for over three months (since July 21, 2014), and is known to regular Google, let’s try to find it on Google Scholar. First, we search for the exact title. Here is the result:&lt;/p>
&lt;p>&lt;img src="Google_Scholar_screen_shot.png" />&lt;/p>
&lt;p>Yes, Google Scholar suggests to me that I misspelled the title and meant to type “busineses” instead of “buriedness.” Importantly, it doesn’t find the correct, latest article! It does find the preprint, though, as the second hit. If I click on “all 8 versions” for the preprint, I get all sorts of different versions of the preprint, but the &lt;a href="https://scholar.google.com/scholar?cluster=1799163645855055780">final, published article is not found&lt;/a> as of this writing (Nov. 1, 2014). The latest version also doesn’t show up among my 2014 publications in my &lt;a href="https://scholar.google.com/citations?hl=en&amp;amp;user=Nc8U6E4AAAAJ&amp;amp;view_op=list_works&amp;amp;sortby=pubdate">Google Scholar profile,&lt;/a> only the first preprint version is shown. For all intents and purposes, the July 21 and September 13 versions of the article are completely missing from the Scholar database. I cannot retrieve them in any way through Scholar. Let me say this one more time: We’re not simply talking about Google Scholar creating multiple redundant entries and not noticing that two articles are just different versions of the same article. &lt;strong>We’re talking about an earlier article completely hiding all later versions.&lt;/strong> Note that, as I said at the beginning of the post, this issue will correct itself eventually. The paper for which I first noticed this is now, after a year, correctly indexed in Google Scholar.&lt;/p>
&lt;p>To demonstrate that this is not a one-off, consider &lt;a href="https://doi.org/10.1101/002287">this article,&lt;/a> posted in revised version on October 14. I’ll leave it as an exercise to the reader to verify that this article exists, is known to regular Google, and is completely invisible in Google Scholar.&lt;/p>
&lt;p>In my mind, this is a serious bug that severely interferes with efficient scientific communication. It also is a huge embarrassment for a company that prides itself of being the world’s leading expert in information retrieval. I hope this post will give this bug more visibility, and will eventually lead the Scholar Team to fix the problem.&lt;/p>
&lt;p>&lt;strong>Update:&lt;/strong> In case you’re wondering if this is just an issue of Google Scholar not having indexed the latest issues of J. Mol. Evol. and/or BiorRxiv yet, that is clearly not the case. Other articles from the &lt;a href="https://link.springer.com/journal/239/79/3/page/1">same J. Mol. Evol. issue&lt;/a> can be found by a search for their title, e.g. &lt;a href="https://scholar.google.com/scholar?hl=en&amp;amp;q=Limits+of+Neutral+Drift%3A+Lessons+From+the+In+Vitro+Evolution+of+Two+Ribozymes">this one&lt;/a> or &lt;a href="https://scholar.google.com/scholar?hl=en&amp;amp;q=One+origin+for+metallo-%CE%B2-lactamase+activity%2C+or+two%3F+An+investigation+assessing+a+diverse+set+of+reconstructed+ancestral+sequences+based+on+a+sample+of+phylogenetic+trees">this one&lt;/a> or &lt;a href="https://scholar.google.com/scholar?q=Essential+is+Not+Irreplaceable%3A+Fitness+Dynamics+of+Experimental+E.+coli+RNase+P+RNA+Heterologous+Replacement">this one&lt;/a>.&lt;/p></description></item><item><title>Should peer-review be double-blind?</title><link>https://sevimcengiz.github.io/blog/2014/10/18/should-peer-review-be-double-blind/</link><pubDate>Sat, 18 Oct 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/10/18/should-peer-review-be-double-blind/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>As part of the &lt;a href="https://sevimcengiz.github.io/blog/2014/10/12/in-defense-of-anonymous-peer-review">recent discussion on anonymous peer review,&lt;/a> several people spoke out in favor of double-blind peer review, where neither the authors nor the reviewers know who the others are. I have thought a lot about double-blind peer review, and I’m not entirely convinced, in particular when it comes to grant applications. While double-blind review might solve certain problems and remove certain biases, it would almost certainly amplify other issues, and whether the net effect would be good or bad is unclear. It would also give more power to people such as editors and program managers who operate outside the blinded process.&lt;/p>
&lt;p>So let’s discuss. I’ll first cover journal articles and then grant proposals. The two are very different, and what applies to one does not necessarily apply to the other.&lt;/p>
&lt;div id="journal-articles" class="section level2">
&lt;h2>Journal articles&lt;/h2>
&lt;p>On the face of it, double-blind peer review for journal articles seems like a no-brainer. It allows junior scientists to be judged on the merit of their work alone, and it prevents senior scientists from coasting through peer review on the basis of their good name. However, as always, the devil is in the detail. There are at least three reasons I can think of why double-blind review may not be such a great idea after all.&lt;/p>
&lt;p>First, the real power is with the editors, not the reviewers. It’s the editors who make the final decisions. And this power tends to increase with the perceived rank of the journal; editors of more prestigious journals are more likely to reject papers without review or because of a perceived lack of interest. We all know that you won’t publish in &lt;em>Nature&lt;/em> if the &lt;em>Nature&lt;/em> editors don’t like your work. And we also know that you can survive quite harsh reviewer criticisms if the &lt;em>Nature&lt;/em> editors really want to publish your work.&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> Thus, one could make an argument that author names should be blinded to both reviewers and editors. But how would the editors invite unbiased reviewers if they don’t know who has a potential conflict of interest? The only practical way would be to have one editor invite the reviewers and another make the decision. This would be an interesting experiment, but I doubt any journal will go for it any time soon. Thus, as long as author names remain known to the handling editor, I doubt that double-blind review will make much of a difference.&lt;/p>
&lt;p>Second, blinding the authors of an article is incredibly hard. Just removing the author names from the first page of a paper will frequently not do. If the authors work on a unique study system, or make extensive use of their prior work, or have developed a specific software package, or have posted their data on a public repository, reviewers will likely be able to find out who they are. I once reviewed a paper where the authors had not only removed their names from the title page but also from citations to their own work in the reference list. I’m still amazed that somebody would (i) go to these lengths to conceal their identity and (ii) not realize that this action completely obliterated any anonymity they might otherwise have had. Double-blinding may create an illusion of anonymity where none actually exists.&lt;/p>
&lt;p>Third, double-blind review gives more power to scientists who are intent on submitting fraudulent work, because it is going to be harder for reviewers to identify patterns in the perpetrators’ activities. For example, I have my list of crooks with a solid portfolio on &lt;a href="http://retractionwatch.com/">Retraction Watch,&lt;/a> and when I get to review one of their papers I’ll be extra careful. These are usually scientists whose activities slipped by me the first time I reviewed one of their papers, because everything looked fine on the surface. If I regularly had to review their papers in a double-blind fashion, they would probably manage to slip by me more frequently.&lt;/p>
&lt;p>One benefit of double-blind peer review, however, could be that even if the reviewers have a sense of which lab(s) may have been involved in a given study, they still won’t be able to guess the exact author list. For example, I don’t know to what extent reviewers are biased by the gender of the first author if a paper comes from an established lab, but if they are, that bias would likely disappear in double-blind review. Reviewers may guess correctly that the paper comes out of my lab, but they won’t know which of my students wrote it. Evidence in favor of this notion comes from one experiment in which double-blind peer review &lt;a href="http://blogs.nature.com/peer-to-peer/2008/01/doubleblind_peer_review_reveal.html">increased the number of female first authors.&lt;/a> Similarly, when junior PIs continue working on research they begun in an established person’s lab, reviewers won’t be able to tell whether the paper comes from the established lab or the junior PI. This could work to the advantage of junior PIs.&lt;/p>
&lt;p>In summary, the positive and the negative aspects of double-blind review are about even, in my opinion. I have no major concerns about double-blind review, as long as I as an author am not expected to do anything more than remove my name from the author list. I’m not interested in going through my entire paper and making sure not a single sentence (e.g. “We have previously investigated…”) could give a hint at who I am. Also, we now frequently make all our data and code available in a github repository, and I’m not going to go through extra effort to conceal who I am there. Other than that, I’d be happy to support more experiments in double-blind peer review, and I’ll also be happy to support double-blind peer review more strongly if evidence in its favor continues to accumulate.&lt;/p>
&lt;/div>
&lt;div id="grant-proposals" class="section level2">
&lt;h2>Grant proposals&lt;/h2>
&lt;p>Grant proposals are an entirely different beast than journal articles, and I do not think that double-blind proposal review is a good idea. There is a fundamental difference between a journal article and a proposal. An article is the finished product. A grant proposal, by contrast, is only the promise of a future product. If one scientist writes ten times more high-profile papers than another, then she should publish ten times more frequently in high-profile journals, without question. However, just because one scientist is ten times better at writing grant proposals than another doesn’t mean he deserves ten times the funds. In fact, only if that scientist can write ten times as many papers or write papers that are ten times as important (however measured) would he deserve ten times the grant funding.&lt;/p>
&lt;p>I strongly believe that the track record of past performance needs to be considered in proposal review. If you had to hand one person a check over a million dollars, would you rather give the money to somebody who consistently delivers interesting results, even if that person’s grant application doesn’t sound overly exciting, or would you prefer to give the money to somebody who can tell a great story but about whom you know nothing beyond that story. This thought is related to the idea (&lt;a href="http://loop.nigms.nih.gov/2014/07/comment-on-proposed-pilot-to-support-nigms-investigators-overall-research-programs/">which is slowly sinking in with the NIH as well&lt;/a>) that it is generally better to fund people than projects, or at least to have a healthy mix of people-based and project-based funding. By definition, if you’re evaluating people, you cannot blind the evaluators to their identity.&lt;/p>
&lt;p>Now you could argue that the scientific review should be done blinded and the final funding decision be made by the program officer, who can take into account all the other relevant factors, such as track record, current funding of the applicant, etc. However, this would simply put more power into the hands of program officers, who might or might not use that power wisely. It’s certainly not unheard of for program officers in some agencies to preferentially fund their good buddies. The more power a program officer has to override a panel decision the more likely those situations are going to arise.&lt;/p>
&lt;p>Double-blind grant review is also open to several sorts of manipulation by applicants. First, it would be easier than it already is to base an application on dubious, sketchy, or even entirely made-up data, because nobody would ever know.&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> Second, applicants could pack their proposals with prior results obtained by the biggest shot in the field, causing the reviewers to think they’re reviewing an application by that lab and rank it higher because of that. You might say that that’s exactly the point, only ideas matter, but I’ve seen too many scientists with great ideas and poor execution to feel comfortable with funding decisions based exclusively on ideas.&lt;a href="#fn3" class="footnote-ref" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a>&lt;/p>
&lt;p>In conclusion, I don’t think that double-blind grant applications are the way to go. There are other ways to minimize biases in the review process. For example, panels could be given statistics on how many women and junior scientists submitted applications to a given competition, and if the composition of the top-ranked applicants deviates substantially from the overall composition of applicants then the panel could be asked to reconsider their rankings. In general, just paying attention to these kinds of biases and monitoring whether certain groups of applicants are disproportionally affected by either positive or negative decisions should prevent the most egregious biases.&lt;/p>
&lt;p>&lt;strong>Update (10/19/2014):&lt;/strong> The article I quoted &lt;a href="http://blogs.nature.com/peer-to-peer/2008/01/doubleblind_peer_review_reveal.html">claiming an increased number of female first authors&lt;/a> under double-blind review has later &lt;a href="http://www.nature.com/news/2008/080604/full/453711c.html">been called into question,&lt;/a> as comparable journals have similarly seen an increase in the number of female first authors during the same time period, without instituting double-blind review. Thanks to &lt;a href="https://twitter.com/mattjhodgkinson">Matt Hodgkinson&lt;/a> for pointing this out.&lt;/p>
&lt;p>&lt;strong>Update #2 (10/19/2014):&lt;/strong> &lt;a href="http://onlinelibrary.wiley.com/doi/10.1002/asi.22784/full">This paper,&lt;/a> pointed out to me by Matt Hodgkinson, provides a thorough review of what is currently known about biases in peer review. It shows mixed evidence on gender bias. In particular with respect to journal articles, current evidence suggests bias isn’t that pronounced (female and male authors have comparable acceptance rates).&lt;/p>
&lt;/div>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>I certainly have reviewed papers for &lt;em>Nature&lt;/em> that I thought should not be published there and the editors overruled me. And this is fine; editors should have the ultimate decision power. I’m an editor myself, and on occasion I accept papers that reviewers say should be rejected. The point remains, though, that an editor who really wants to publish a paper will rarely be deterred by negative reviews, in particular if the reviews don’t call out egregious errors in the work.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>Even under the current system of non-blinded review, grant applicants can include sketchy or made-up data with little risk to their career or reputation. While such activity is obviously fraudulent and will have severe consequences if discovered, the likelihood of discovery is low. First, only three to five other scientists ever see the application, and only for a short period of time. So if an applicant, for example, reuses the same data set in subsequent applications but labels the resulting figure differently, it’s very unlikely anybody would notice. Similarly, if an applicant claims preliminary data support one hypothesis and later publishes a paper supporting a different hypothesis, he could always argue that that is indeed how discovery went: first things looked one way but after more careful study it became clear the other way was right. Only the most blatantly obvious fraud, such as publishing fraudulent data in a paper and then using that paper as preliminary results in an application, has any likelihood of being discovered. For these reasons, a colleague of mine here at UT thinks that results that aren’t published or maybe at least deposited on a public archive should not be allowed in grant applications at all.&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>As with everything in life, I think some balance is required here. Grant applicants should have to demonstrate some amount of prior expertise in the work they propose, but they should also be given the benefit of the doubt that some things can be worked out as the research is done.&lt;a href="#fnref3" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>How to schedule a committee meeting</title><link>https://sevimcengiz.github.io/blog/2014/10/14/how-to-schedule-a-committee-meeting/</link><pubDate>Tue, 14 Oct 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/10/14/how-to-schedule-a-committee-meeting/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>One of the key challenges in obtaining a PhD is scheduling a committee meeting. In fact, I think that anybody who has managed to successfully schedule three or four committee meetings probably deserves a PhD just for that feat. After all, getting five professors into the same room at the same time is a tall order. Since scheduling committee meetings is such an integral part of graduate education, there should probably be a class on how to do this successfully. However, I don’t think any such class exists. So maybe this blog post can serve as a substitute.&lt;/p>
&lt;p>We faculty members understand that we have to do committee meetings, as a service to the department and to help the students. Nearly all faculty members I know are strongly committed to serving on thesis committees. At the same time, we don’t really want to be in these meetings. Committee meetings take up a lot of time. In fact, just fielding questions related to scheduling committee meetings takes up a lot of time. So please try to keep this in mind, and make things as easy on us as possible. We want to help you, but you need to help us in return.&lt;/p>
&lt;p>Now, how do you actually go about scheduling a meeting? First, let’s talk about some things that would best be avoided:&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>Don’t ask me to list all my availabilities between March 15 and June 1st. I’m not going to replicate my entire calendar into an email to you.&lt;/li>
&lt;li>Don’t give me a list of 120 possible date/time combinations and ask me to check off all the ones that don’t work. See the previous point.&lt;/li>
&lt;li>Don’t assume my availabilities remain unchanged for more than a couple of days. I once had a student ask me if my afternoon was open on a given Monday. I said yes. Six weeks later, and about a week before that Monday, he informed me that the committee meeting was going to be at 3pm. By that time I had already scheduled something else into that time slot.&lt;/li>
&lt;/ol>
&lt;p>Now, I’d like to propose a scheduling strategy that generally works:&lt;/p>
&lt;p>First, discuss possible dates and times with your adviser. Any times your adviser can’t make are a no-go, obviously. Then, ask your committee members to outline broadly which days/times generally do or don’t work. You can do this in an email or in person. You can also try to figure this out for yourself, by checking their teaching schedule, office hours, lab-meeting schedule, and so on. But I think asking is better.&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> Also, you should ask the committee members whether they are going to be out of town any specific days/weeks during the time window in which you’d like to hold your meeting.&lt;/p>
&lt;p>Once you’ve got a rough sense of everybody’s availability, find a few times that seem to work for everybody and propose a few variants of those times. For example, if it looks like everybody is mostly free on Tuesday afternoons, propose 2pm, 3pm, and 4pm on three successive Tuesdays. At this stage, I would recommend using a system such as &lt;a href="http://doodle.com/">Doodle&lt;/a> to quickly poll availability. The nice thing about Doodle is that I can see my colleagues’ answers, so if it looks like nobody can make Mon. afternoon then I don’t even have to check my calendar for that slot, I can just click “no” as well.&lt;/p>
&lt;p>Importantly, limit the number of options you propose. If you’re proposing more than about 10 options you’re doing it wrong. Remember from point 3 of the list of things best avoided that quick turn-around is key. You want your committee members to read your message, click on the Doodle link, and quickly answer the poll. You don’t want them to read your message, click on the Doodle link, then recoil in horror and move on to do something else. In a perfect scenario, if you’ve done your leg-work properly, you can propose three to five possible times and one will work.&lt;/p>
&lt;p>I strongly believe that proposing a small number of time slots is important even if you don’t have complete information about who is or is not available when. Quick turn-around always beats out having more complete information when it comes to scheduling. So, if you’re not sure what times would be good, just pick a few time slots at random and see what happens. Worst case scenario, none will work, and you do another round of Doodle. From your perspective, this may seem like an awful outcome, but it’s actually fine. Failed scheduling attempts happen all the time and we’re used to them. I’d rather complete two or even three Doodle polls with 10 options each than one with 100.&lt;/p>
&lt;p>Finally, even if you make things really easy on your committee members, some may not respond to your email requests. In this case, the best strategy is just to show up in their office unannounced and ask them whether they’re available for a meeting on Thurs May 7 at 3pm. And of course, I hope you didn’t put anybody onto your committee who &lt;a href="https://sevimcengiz.github.io/blog/2014/1/26/how-to-pick-a-thesis-committee">is notoriously difficult to schedule.&lt;/a> That would just be asking for trouble.&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>You may wonder what the difference is between asking people about their general availability and asking them specifically when they can or cannot meet. The difference is efficiency. If you send me an email such as this one:&lt;/p>
&lt;blockquote>
&lt;p>Dear Claus,&lt;/p>
&lt;p>I’d like to schedule a committee meeting for late May or early June. Are there any days that you are out of town during that time? Also, are there days/times that generally do or do not work for you?&lt;/p>
&lt;/blockquote>
&lt;p>I can respond:&lt;/p>
&lt;blockquote>
&lt;p>I’m around. MWF is usually bad, but I’m free most times TTH.&lt;br />
Claus&lt;/p>
&lt;/blockquote>
&lt;p>Writing this kind of a response will take me all of 2 minutes, and I’ll likely do it the moment I get your message. As a result, this exchange has saved you from proposing numerous times I would have declined, and it has saved me the time and effort it would have taken me to enter my entire calendar into Doodle.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>In defense of anonymous peer review</title><link>https://sevimcengiz.github.io/blog/2014/10/12/in-defense-of-anonymous-peer-review/</link><pubDate>Sun, 12 Oct 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/10/12/in-defense-of-anonymous-peer-review/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>In a recent blog post, Mick Watson argued that &lt;a href="http://biomickwatson.wordpress.com/2014/10/08/why-anonymous-peer-review-is-bad-for-science/">anonymous peer review is bad for science.&lt;/a> The post makes a number of insightful and valid points. However, the one point I cannot agree with is that junior scientists don’t need anonymity so they can freely speak their mind without fear of retaliation. Mick Watson argues that retaliation should be a non-issue, and that in the cases where it is not we just have to make it so. Frankly, I think this is simplistic black-and-white thinking. There are so many ways in which a senior person can make a junior person’s life more difficult; I would always recommend my graduate students and postdocs that they review anonymously unless they can write a very positive review.&lt;/p>
&lt;p>A senior person can retaliate against a junior person in a million subtle ways, and all of them are entirely ethical &lt;em>unless they are done in bad faith.&lt;/em> In fact, they are the exact same behaviors we engage in all the time to separate stronger science/scientists from weaker science/scientists. Let me just list a few examples:&lt;/p>
&lt;ul>
&lt;li>I don’t have to prominently cite Junior Person’s work in all of my papers if my papers don’t build directly on top of Junior Person’s work.&lt;/li>
&lt;li>When I give invited lectures, I don’t have to mention Junior Person’s work.&lt;/li>
&lt;li>I don’t have to invite Junior Person to give a Departmental Seminar at my institution.&lt;/li>
&lt;li>I am free to rank Junior Person’s grant as “very good” rather than “excellent.”&lt;/li>
&lt;li>If I’m on a grant panel and my colleagues are tearing apart Junior Person’s grant, I don’t have to speak up. I’m allowed to have no strong opinion.&lt;/li>
&lt;li>I don’t have to invite Junior Person to give a keynote lecture at the conference I’m organizing. In particular, if Junior Person is a man, I can always say “we needed more women speakers.”&lt;/li>
&lt;li>If Junior Person comes up for tenure, I don’t have to write a letter. I can claim I’m busy. Or, if I accept the assignment, I can weaken my statements of support, e.g., by saying “I think Junior Person would get tenure at my institution” instead of saying “Without doubt Junior Person would get tenure at my institution.”&lt;/li>
&lt;li>If I’m handling one of Junior Person’s papers as Associate Editor, I can invite reviewers who I suspect are going to be critical of Junior Person’s work.&lt;/li>
&lt;li>If I’m handling one of Junior Person’s papers as Section Editor, I can place little seeds of doubt in the mind of my Associate Editor, e.g. by forwarding the paper with a note that says “I’m not entirely sure this fits into the scope of &lt;em>Journal of Amazing Results.&lt;/em> Feel free to reject without review if you have doubts yourself.”&lt;/li>
&lt;li>When I’m reviewing a paper by somebody else, I don’t have to tell the authors that they should cite Junior Person’s work.&lt;/li>
&lt;li>When I’m reviewing Junior Person’s paper, I can place little seeds of doubt in the handling editor’s mind, e.g. by placing the following in the confidential comments to the editor: “There’s nothing technically wrong with this work, but I don’t quite see it meeting the standards of &lt;em>Journal of Amazing Results.&lt;/em>”&lt;/li>
&lt;li>When I speak informally with colleagues, I don’t have to mention how amazing Junior Person’s work is. In fact, I don’t have to mention Junior Person at all.&lt;/li>
&lt;/ul>
&lt;p>And of course, I can do the opposite of all these behaviors if I really want to promote a junior scientist. In fact, I strongly suspect that these kinds of behaviors (subtle promotion or demotion of individuals) are at the heart of observed differences in recognition of male vs. female scientists, but that’s a topic for another day. For now, it suffices to emphasize that all of these behaviors are entirely reasonable, ethical, and even desired &lt;em>if&lt;/em> they are driven by an objective assessment of the quality of one person’s science over another’s, and not by personal biases, preferences, or desire for revenge.&lt;/p>
&lt;p>Mick Watson argues that the scientific community should expel retaliating scientists. This suggestion sounds good in theory, but in practice it won’t work for any but the most egregious cases. And importantly, expelling retaliating scientists must not turn into a witch hunt. If I have to be concerned that any time I rank a grant proposal as “very good” or even just “good” somebody is going to accuse me of retaliation then I might as well stop reviewing grants or papers altogether.&lt;/p>
&lt;p>Mind you, I’m strongly in favor of &lt;em>open&lt;/em> peer review, where the entire review history is routinely published alongside the paper. It adds a lot of transparency to the process. And I think (though I have no data) that people will generally write more polite and factual reviews if they know that their reviews will become public eventually. In the end, though, science—like anything else in life—is always going to be somewhat unfair, open to manipulation, and subject to personal biases and opinion. As a minor protection against these mechanisms, in particular for junior people and women, scientists should be allowed to give anonymous feedback if they so choose.&lt;/p></description></item><item><title>Double Jeopardy</title><link>https://sevimcengiz.github.io/blog/2014/09/13/double-jeopardy/</link><pubDate>Sat, 13 Sep 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/09/13/double-jeopardy/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>Lately it keeps happening to me that I try to invite somebody to review a paper and they decline, giving as reason that they have reviewed the paper already for a different journal&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> and reviewing the paper again would put the authors into a situation of double jeopardy. This got me thinking. Should reviewers really decline for that reason? As reviewer, I’ve always thought the opposite. For a paper I have reviewed already, if the authors have made a reasonable effort to address my comments and have now chosen a more adequate journal, I can keep my review short and recommend acceptance. Thus, I’m actually preventing a situation of double jeopardy. I keep the authors from facing yet another reviewer with new opinions and requests. So, which is right? Should reviewers recuse themselves if they are asked to review again for a different journal, or should they instead leap at the opportunity and give the authors a break? I’d be interested in your thoughts.&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>Where the paper was rejected, presumably.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Surviving the pre-tenure years at an R1 university</title><link>https://sevimcengiz.github.io/blog/2014/07/12/surviving-the-pre-tenure-years-at-an-r1-university/</link><pubDate>Sat, 12 Jul 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/07/12/surviving-the-pre-tenure-years-at-an-r1-university/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>A few days ago, Pröf-like Substance &lt;a href="http://scientopia.org/blogs/proflikesubstance/2014/07/02/blog-carnival-surviving-the-pre-tenure-years/">asked for posts with suggestions on how to survive the pre-tenure years.&lt;/a> I went over my blogging history and realized that I hadn’t really written anything on this topic yet. Most of my advice to date is targeted at more junior scientists. So here is my attempt at giving some suggestions on how to make the most out of your years on the tenure track.&lt;/p>
&lt;p>The below applies to a tenure-track position at an R1 university, where your promotion will largely depend on your research productivity. I’m assuming that you’re teaching one course a semester or less, you have limited requirements in terms of departmental service, and you have access to a pool of capable graduate students.&lt;/p>
&lt;div id="relax-youre-not-going-to-die" class="section level2">
&lt;h2>Relax, you’re not going to die&lt;/h2>
&lt;p>Well, you are, but likely not any time soon. Being a fresh Assistant Professor on the tenure track is a pretty sweet deal. You have 5-7 years of guaranteed job security, during which nobody is going to tell you what to do. Your teaching load is pretty light. You get to spend most of your time doing stuff you really enjoy. Also, unless you’ve signed up with a place known for not tenuring their junior faculty members, such as Harvard, odds are in your favor. As long as you perform reasonably, you will probably get tenure. And, even if you are denied tenure, you’ll likely land on your feet and find a good job elsewhere. I can think of only a handful of people I know who were denied tenure, and all of them have done Ok. In fact, the vast majority of them are now in permanent academic positions at different (or even the same&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>) universities, or at national labs.&lt;/p>
&lt;p>Stressing over tenure will only make you perform worse. To be successful, you need to be original, you need to be productive, and you need to inspire the students and postdocs in your lab to perform at their best. Worrying about tenure will interfere with all of this. So you might as well forget that there is such a thing as tenure, do your day-to-day job as best you can, and enjoy the ride.&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a>&lt;/p>
&lt;/div>
&lt;div id="carefully-evaluate-any-advice-you-receive" class="section level2">
&lt;h2>Carefully evaluate any advice you receive&lt;/h2>
&lt;p>You’ll receive tons of advice on how to get tenure, including this piece you’re reading right now. Chances are, some of the advice you hear will not jibe with you. Some of it may even conflict with other advice you’re hearing. If you try to follow all this advice to the letter, you may feel dragged back and forth, and you may be doing all sorts of things that aren’t really you. Being an academic is all about being original and independent, doing things differently than other people have done, swimming against the stream. For any piece of advice somebody gives you, I’ll be able to point to a person who ignored it and got tenure anyway.&lt;/p>
&lt;p>Now this shouldn’t be a license to behave like a complete idiot. You will need to show some productivity, you will likely need some external funding, and you need to behave reasonably towards your colleagues and your students. But beyond that, there’s many ways to skin a cat, and you’ll have to find your own.&lt;/p>
&lt;/div>
&lt;div id="write-at-least-two-papers-a-year" class="section level2">
&lt;h2>Write at least two papers a year&lt;/h2>
&lt;p>A minimum of two papers a year will provide insurance against any potential claims of poor productivity somewhere up the chain in the promotion process. These claims are usually brought up when applicants have on their cv one or more years without any papers, in particular in succession. One paper a year might be sufficient, but two is safer. It protects against the vagaries of the review process, which may overly delay some of your papers.&lt;/p>
&lt;p>Since you’re working at a place that emphasizes research, writing two papers a year should be eminently doable, even if you’re doing difficult experimental work that progresses slowly. Let’s do the math. Over a five-year period, that’s about 10 papers. Three of them can be review papers, which you can write without needing any new data. Two of them should be major contributions. Let’s say one is a piece of work you started as a postdoc. That’s a paper for which you should have most or all of the data already, and you should be able to write that quickly. The other should be the first major, independent piece from your own lab, which you may submit late in year three or early in year four so it comes out in time for your tenure review. Surely your research isn’t so complicated that you can’t generate enough data for a solid paper in three years. (If it is, maybe you should reevaluate your research program.)&lt;/p>
&lt;p>This leaves five more papers to write. Those can be small, “least publishable unit” (LPU) papers. You should be able to write one of those each year. Write something about a method you developed. Re-analyze a previously published data set. Publish some of the partial results that will eventually lead to your big paper, three years down the line. Honestly, if you can’t write at least one LPU paper a year, you have to take a hard look at your standards and ask yourself whether they’re too high.&lt;a href="#fn3" class="footnote-ref" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a>&lt;/p>
&lt;/div>
&lt;div id="publish-the-same-idea-multiple-times" class="section level2">
&lt;h2>Publish the same idea multiple times&lt;/h2>
&lt;p>I’m not asking you to self-plagiarize, I’m just encouraging you to keep beating the horse even though you may think you have slain it already. If you’ve shown something once, show it again in a different way. Or in a different system. Or write a follow-up paper showing something that may be totally obvious to you given your earlier results. Then write a review paper about all of the above.&lt;/p>
&lt;p>First, this approach will help you with productivity. Second, and more importantly, it will associate your name with the particular effect you’re investigating. As part of the promotion process, letter writers will be asked whether you’re a leader in your field. One of the best ways to become known and recognized as a leader is to say the same thing, over and over, until it’s been heard in even the last corner of every ivory tower.&lt;/p>
&lt;/div>
&lt;div id="say-yes-to-as-many-conference-and-seminar-invitations-as-possible" class="section level2">
&lt;h2>Say “yes” to as many conference and seminar invitations as possible&lt;/h2>
&lt;p>As I said in the previous point, being known helps tremendously with getting tenure. And traveling around the country giving talks at departmental seminars and conferences helps tremendously with being known. Thus, if you’re invited to speak somewhere, try to say “yes.” For some, this advice is a no-brainer. But if you don’t enjoy traveling, or if you have health concerns, or if you have teaching or family obligations that make it difficult to travel, you may be inclined to say “no.” Of course there are perfectly valid reasons to decline a travel invitation, and in the end you have to weigh the various priorities and make your own decision. My advice, if you have a tendency to say “no,” is to make an honest assessment of how much travel you can realistically accommodate into your life, and then plan accordingly. For example, you might decide that you can travel &lt;em>X&lt;/em> times a year, or that you need at least &lt;em>Y&lt;/em> weeks between trips, or that you can never travel in the spring. If you have a clear system like that, then it’ll be easy for you to take advantage of the opportunities that come your way. And you’ll also feel more comfortable saying “no” if you have a straightforward reason to decline, e.g.: “I’m sorry, this would be my second trip in August, and I never make more than one trip a month.”&lt;/p>
&lt;/div>
&lt;div id="apply-for-funding-early-often-and-widely" class="section level2">
&lt;h2>Apply for funding early, often, and widely&lt;/h2>
&lt;p>You’ll probably need funding to receive tenure. Even if your university doesn’t make funding a requirement, you’ll probably need funding to keep your lab going/productive, and you’ll definitely need a productive lab to get tenure.&lt;/p>
&lt;p>Compared to publishing a paper, getting a grant is much harder. Most papers I write get published; most grants I write get rejected. However, the good thing about grants is that you don’t need to obtain that many. If you’re receiving one medium-sized grant every other year or so you’re doing pretty good. To maximize your chances of receiving funding, apply often and widely. You should probably write 3-5 grants a year. Most importantly, don’t just try one funding agency or one program. Even if you’re told you need the R01 to get tenure, I doubt your colleagues will be upset with you if you’re getting a nice grant from the Navy instead. Also, don’t write all of these grants entirely by yourself. Build some collaborations, and try to be part of some larger research teams. Again, even if you’re told you need the single-investigator grant, your promotion committee will certainly rank collaborative funding higher than no funding at all. And, any funding you manage to secure helps you to hire people and pay for experiments which may be preliminary results in your next single-investigator grant application.&lt;/p>
&lt;/div>
&lt;div id="make-sure-you-recruit-graduate-students-as-soon-as-possible" class="section level2">
&lt;h2>Make sure you recruit graduate students as soon as possible&lt;/h2>
&lt;p>Graduate students are the lifeblood of a new lab. Attempt to recruit one or two good ones as early as possible. The moment you receive your offer letter, find out how graduate recruitment works, and make sure you’re in the system and prospective students know about you. If possible, attend events for prospective graduate students even if you haven’t actually started your position yet. Ask your (prospective) department to add you to their web site as soon as possible. If your department has a rotation system, make sure you’re on the rotation schedule.&lt;/p>
&lt;p>Graduate student recruitment happens only once a year, and if you miss the first year, you’ll risk sitting in an empty lab for a long time.&lt;/p>
&lt;/div>
&lt;div id="be-careful-with-your-postdoc-hires" class="section level2">
&lt;h2>Be careful with your postdoc hires&lt;/h2>
&lt;p>Hiring a postdoc can be tricky for a young faculty member, unless you’re at Harvard or similar, where postdocs are willing to join any lab just for the overall reputation of the university. Most really good postdocs prefer to go to large, established labs with a proven track record. I’ve heard lots of stories from young faculty members about the postdoc woes they have gone through. This doesn’t mean you shouldn’t hire a postdoc at all. It just means you should focus on getting someone really good and vet them well. One option that may work is hiring a student from a past adviser, possibly somebody you worked with when you were a postdoc yourself. In case of doubt, recruit graduate students rather than postdocs.&lt;/p>
&lt;/div>
&lt;div id="teaching-may-hurt-you-but-it-is-unlikely-to-help-you" class="section level2">
&lt;h2>Teaching may hurt you but it is unlikely to help you&lt;/h2>
&lt;p>If your teaching is atrocious, you may be denied tenure even if your research is stellar. However, if your teaching is stellar and your research weak, chances are nobody will care about your teaching performance. So plan accordingly. Put enough effort into your teaching so that nobody can say you are a bad teacher, but don’t sacrifice your research program for the goal of becoming the best teacher in the department.&lt;/p>
&lt;/div>
&lt;div id="do-things-that-make-you-happy" class="section level2">
&lt;h2>Do things that make you happy&lt;/h2>
&lt;p>No matter how much you enjoy being an academic, there will be elements to your job that you don’t enjoy. It’s a job after all. Therefore, it is important that you find a balance between doing the things that you do enjoy and those that you don’t. When you’re under pressure to perform, such as with tenure looming, it is easy to get dragged down into doing mostly the things that you don’t enjoy but that must get done. You need to be aware of this dynamic and consciously work against it.&lt;/p>
&lt;p>For example, assume you have successfully set up lab, and you now have a couple of grad students and a technician. They are all reasonably capable and they produce results. What your lab now needs is papers and grants. And you’re the only one in the lab who can write them. So, clearly, you should be spending all your time writing and none of your time doing experiments, right? This is only true if you really enjoy writing papers and grants. Let’s say you don’t. Let’s say what you really enjoy is standing at the bench doing experiments. In this case you need to find a balance such that you sometimes get to do the things that made you become an academic in the first place. Maybe you write in the morning and work at the bench in the afternoon. Or you work at the bench one day a week. Even though theoretically your productivity would be higher if you spent all your time doing the things only you can do, in practice your productivity will only stay high if you’re happy. If standing in front of a bench makes you happy, then absolutely do so, without any regrets.&lt;a href="#fn4" class="footnote-ref" id="fnref4">&lt;sup>4&lt;/sup>&lt;/a>&lt;/p>
&lt;/div>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>Not getting tenure the first time round but eventually getting it anyway seems to be somewhat common at UT. I can think of at least four cases since I’ve been here.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>See also: &lt;a href="http://blogs.scientificamerican.com/guest-blog/2013/07/21/the-awesomest-7-year-postdoc-or-how-i-learned-to-stop-worrying-and-love-the-tenure-track-faculty-life/">The Awesomest 7-Year Postdoc.&lt;/a>&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>On the topic of whether it is worth it to write low-impact papers, see also &lt;a href="https://sevimcengiz.github.io/blog/2013/11/3/no-one-reads-your-paper-either">this post&lt;/a> I wrote a while back.&lt;a href="#fnref3" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn4">&lt;p>The same concept applies to balancing your job with the rest of your life. You need to do things that make you happy. Go exercise, watch a play, learn how to juggle, write a blog, write a novel. Anything that gives you joy deserves some of your time.&lt;a href="#fnref4" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>How to develop a research question, Part II</title><link>https://sevimcengiz.github.io/blog/2014/06/18/how-to-develop-a-research-question-part-ii/</link><pubDate>Wed, 18 Jun 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/06/18/how-to-develop-a-research-question-part-ii/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>After my last post discussing &lt;a href="https://sevimcengiz.github.io/blog/2014/6/15/how-to-develop-a-research-question">how to develop a research question&lt;/a>, Sergey Kryazhimskiy asked me to write about how to find the rare good research idea among the many mediocre ones.&lt;/p>
&lt;blockquote class="twitter-tweet" lang="en">
&lt;p lang="en" dir="ltr">
&lt;a href="https://twitter.com/ClausWilke">&lt;span class="citation">@ClausWilke&lt;/span>&lt;/a> After 2 successful projects the problem shifts to choosing a rare good research idea among many mediocre ones. Next post? 2/2
&lt;/p>
— Sergey Kryazhimskiy (&lt;span class="citation">@skryazhi&lt;/span>) &lt;a href="https://twitter.com/skryazhi/status/478349857540042753">June 16, 2014&lt;/a>
&lt;/blockquote>
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>The truth is that I don’t really know how to do this. If you do, please tell me. I’m sure I could strengthen my research program by picking better problems. Nevertheless, despite my ignorance, I’ve had a reasonably successful career to date. And it was probably not entirely due to sheer luck. So this should give you hope. Even if you don’t know how to pick good problems, you may succeed in science nonetheless. Just work on the problems that seem important to you and hope for the best.&lt;/p>
&lt;p>Because I don’t know how to answer Sergey’s question, at first I thought that I wouldn’t have much to say on this topic. However, not knowing something hasn’t kept me from writing a 1500-word blog post about it. After some pondering, I thought it might be useful to review what other people have said on this topic. If you spend some time with Google, you’ll find expert advice on how to choose a good research problem. For example, in Uri Alon’s paper &lt;a href="http://wws.weizmann.ac.il/mcb/UriAlon/sites/mcb.UriAlon/files/uploads/nurturing/howtochoosegoodproblem.pdf">“How To Choose a Good Scientiﬁc Problem”&lt;/a>,&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> there is a nice graphic (here reproduced as Figure &lt;a href="#fig:figure1">1&lt;/a>) ranking potential problems according to their difficulty (hard to easy) and according to the gain in knowledge their solution would provide (small to large). Easy problems with a small gain in knowledge are good beginner problems, hard problems with a large gain in knowledge are good long-term goals for an established researcher, and easy problems with a large gain in knowledge are perfect for a postdoc. And nobody should work on hard problems that lead to small gains in knowledge.&lt;/p>
&lt;div class="figure">&lt;span id="fig:figure1">&lt;/span>
&lt;img src="Fig1.png" alt="Pareto front of worthwhile research questions. Research questions can be ranked according to difficulty (hard to easy) and gain in knowledge (small to large). The best problems are those that provide the maximum gain of knowledge for the chosen difficulty level. One should never work on hard problems that provide little gain in knowledge. After U. Alon (2009)." width="80%" />
&lt;p class="caption">
Figure 1: Pareto front of worthwhile research questions. Research questions can be ranked according to difficulty (hard to easy) and gain in knowledge (small to large). The best problems are those that provide the maximum gain of knowledge for the chosen difficulty level. One should never work on hard problems that provide little gain in knowledge. After U. Alon (2009).
&lt;/p>
&lt;/div>
&lt;p>This is all nice and well, until you realize that it is basically impossible to rank problems &lt;em>a priori&lt;/em> along either dimension. Uri Alon’s paper explains why. Science does not normally progress in a direct path from A to B. We may intend to work towards B, but on our way there we get stuck in “the cloud,” where every attempt to get closer to B fails, until eventually we give up and go for C, a problem that we hadn’t even considered beforehand (Figure &lt;a href="#fig:figure2">2&lt;/a>). The two immediate consequences of this process are that (i) we don’t know how hard it will be to get from A to C, and (ii) we don’t know how much of a gain in knowledge C will provide, in both cases because we don’t even know C exists when we start. Thus, even though Uri Alon’s ranking of problems along difficulty and gain in knowledge is beautiful and convincing, it is also quite useless.&lt;/p>
&lt;div class="figure">&lt;span id="fig:figure2">&lt;/span>
&lt;img src="Fig2.png" alt="How we would like to do science (left) and how it actually works (right). Here, A represents what we currently know and B represents what we would like to know. Our desire is to move from A to B in as direct a line as possible. However, we usually get stuck as we are approaching B, things don’t work out, and we keep taking detours and going in circles. Uri Alon calls this state the cloud. Eventually, we give up on reaching B and instead head for C, a new insight that we found while wandering in the cloud. Usually, C represents the solution to a problem we weren’t even aware of when we started. After U. Alon (2009)." width="80%" />
&lt;p class="caption">
Figure 2: How we would like to do science (left) and how it actually works (right). Here, A represents what we currently know and B represents what we would like to know. Our desire is to move from A to B in as direct a line as possible. However, we usually get stuck as we are approaching B, things don’t work out, and we keep taking detours and going in circles. Uri Alon calls this state &lt;em>the cloud.&lt;/em> Eventually, we give up on reaching B and instead head for C, a new insight that we found while wandering in the cloud. Usually, C represents the solution to a problem we weren’t even aware of when we started. After U. Alon (2009).
&lt;/p>
&lt;/div>
&lt;p>So, what can be done? If we keep reading Uri Alon’s article, we find that he makes some useful suggestions on how to pick important problems. He writes:&lt;/p>
&lt;blockquote>
&lt;p>One of the fundamental aspects of science is that the interest of a problem is subjective and personal. (…) Ranking problems with consideration to the inner voice makes you more likely to choose problems that will satisfy you in the long term. (…) One way to help listening to the inner voice is to ask: ‘‘If I was the only person on earth, which of these problems would I work on?’’ (…) Another good sign of the inner voice are ideas and questions that come back again and again to your mind for months or years. (…) It is remarkable that listening to our own idiosyncratic voice leads to better science. It makes research self-motivated and the routine of research more rewarding. In science, the more you interest yourself, the larger the probability that you will interest your audience.&lt;/p>
&lt;/blockquote>
&lt;p>So, if you’re not sure which problems to work on, work on the ones that excite you!&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a>&lt;/p>
&lt;p>Uri Alon is not the only one who has commented on this topic. The famous computer-science pioneer Richard Hamming (of the Hamming distance and Hamming codes) used to give a talk entitled “You and Your Research,” which touches on this issue among other things. You can read a transcript &lt;a href="http://www.cs.virginia.edu/~robins/YouAndYourResearch.html">here&lt;/a>.&lt;a href="#fn3" class="footnote-ref" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a> The whole thing is worth reading. Here, I’ll just cite a few relevant paragraphs. First this one:&lt;/p>
&lt;blockquote>
&lt;p>When you are famous it is hard to work on small problems. This is what did Shannon in. After information theory, what do you do for an encore? The great scientists often make this error. They fail to continue to plant the little acorns from which the mighty oak trees grow. They try to get the big thing right off. And that isn’t the way things go. So that is another reason why you find that when you get early recognition it seems to sterilize you. In fact I will give you my favorite quotation of many years. The Institute for Advanced Study in Princeton, in my opinion, has ruined more good scientists than any institution has created, judged by what they did before they came and judged by what they did after. Not that they weren’t good afterwards, but they were superb before they got there and were only good afterwards.&lt;/p>
&lt;/blockquote>
&lt;p>In other words, don’t try too hard to make a big splash. Just keep working on a variety of problems and see which ones turn out to be useful. While you do so, take notice of things that repeatedly don’t work. Those may be hints that can lead to major insights:&lt;/p>
&lt;blockquote>
&lt;p>I think that if you look carefully you will see that often the great scientists, by turning the problem around a bit, changed a defect to an asset. For example, many scientists when they found they couldn’t do a problem finally began to study why not. They then turned it around the other way and said, “But of course, this is what it is” and got an important result.&lt;/p>
&lt;/blockquote>
&lt;p>And finally, keep an eye out for great opportunities:&lt;/p>
&lt;blockquote>
&lt;p>The great scientists, when an opportunity opens up, get after it and they pursue it. They drop all other things. They get rid of other things and they get after an idea because they had already thought the thing through. Their minds are prepared; they see the opportunity and they go after it. Now of course lots of times it doesn’t work out, but you don’t have to hit many of them to do some great science. It’s kind of easy. One of the chief tricks is to live a long time!&lt;/p>
&lt;/blockquote>
&lt;p>What can you do to increase the chance that opportunities come your way? Here is Feynman’s suggestion, &lt;a href="http://www.ams.org/notices/199701/comm-rota.pdf">as recounted by Gian-Carlo Rota&lt;/a>:&lt;a href="#fn4" class="footnote-ref" id="fnref4">&lt;sup>4&lt;/sup>&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>You have to keep a dozen of your favorite problems constantly present in your mind, although by and large they will lay in a dormant state. Every time you hear or read a new trick or a new result, test it against each of your twelve problems to see whether it helps. Every once in a while there will be a hit, and people will say, “How did he do it? He must be a genius!”&lt;/p>
&lt;/blockquote>
&lt;p>The goal is thus to wander around in the cloud and always keep an eye out for exciting opportunities that may open up. While you’re in the cloud, aiming for B, there may be many C’s that come your way that you could pursue, but most of them will not be worthwhile (Figure &lt;a href="#fig:figure3">3&lt;/a>). However, on occasion, you stumble upon something that is really neat (C&lt;sub>6&lt;/sub> in the Figure), and when that happens you should drop everything else and pursue that opportunity. I would recommend applying the following test: Do you personally think you’ve stumbled upon an exciting opportunity? If yes, go for it. If no, keep looking for something else to work on.&lt;/p>
&lt;div class="figure">&lt;span id="fig:figure3">&lt;/span>
&lt;img src="Fig3.png" alt="Scientific opportunities in the cloud. While we are stuck in the cloud, we encounter all sorts of new insights. Most of them are boring, however, and we shouldn’t pursue them further. But, on occasion, we stumble upon an exciting new insight. When this happens, great scientists drop everything else and seize the opportunity." width="80%" />
&lt;p class="caption">
Figure 3: Scientific opportunities in the cloud. While we are stuck in the cloud, we encounter all sorts of new insights. Most of them are boring, however, and we shouldn’t pursue them further. But, on occasion, we stumble upon an exciting new insight. When this happens, great scientists drop everything else and seize the opportunity.
&lt;/p>
&lt;/div>
&lt;p>In this whole process, you might wonder what’s the point of B. If we never get to B, do we need it in the first place? I think we do. B gives us a broad sense of direction while we’re not sure where we’re going in the cloud. Until we have identified an exciting opportunity C, we might as well keep chasing B. Who knows, with luck, we might even manage to get to B at some point. It happens on occasion.&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>U. Alon (2009) &lt;a href="http://wws.weizmann.ac.il/mcb/UriAlon/sites/mcb.UriAlon/files/uploads/nurturing/howtochoosegoodproblem.pdf">How To Choose a Good Scientiﬁc Problem.&lt;/a> Mol. Cell 35:726-728.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>It should be noted here that the degree to which a problem is of interest to the broader scientific community depends also on how well it is marketed. You can pick problems you know the community finds interesting, or alternatively you can convince the community that they should find interesting what you are working on. Many of the very successful scientists do the latter. In fact, fame and recognition often go to the person who convinced the community that a problem was worthwhile, not to the person who actually solved the problem in the first place.&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>Hamming gave this talk many times. The &lt;a href="http://www.cs.virginia.edu/~robins/YouAndYourResearch.html">transcript available here&lt;/a> is from March 7, 1986. There is also a &lt;a href="https://www.youtube.com/watch?v=a1zDuOPkMSw">video recording,&lt;/a> from June 6, 1995. The transcript and the video are largely identical, but I found that the video added a few interesting points that weren’t in the transcript.&lt;a href="#fnref3" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn4">&lt;p>G.-C. Rota (1997) &lt;a href="http://www.ams.org/notices/199701/comm-rota.pdf">Ten Lessons I Wish I Had Been Taught.&lt;/a> Notices of the AMS 44:22-25.&lt;a href="#fnref4" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>How to develop a research question</title><link>https://sevimcengiz.github.io/blog/2014/06/15/how-to-develop-a-research-question/</link><pubDate>Sun, 15 Jun 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/06/15/how-to-develop-a-research-question/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>One of the most daunting prospects for a fresh graduate student is having to develop a solid research question.&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> In my experience, many graduate students feel like they don’t even know where to start. The literature can seem overwhelming, everything has already be done by somebody, and in any case it’s impossible to really know all the literature there is anyway. Making matters worse, almost every cohort or lab inevitably has one or two students who just seem to be fountains of good ideas, who constantly come up with new research ideas they want to pursue. As a result, students who are less inventive or less imaginative can feel like they’re not cut out for a career in research, they’re never going to have the necessary ideas to sustain a research program.&lt;/p>
&lt;p>I strongly believe that having good ideas is a skill that can be learned. There are simple strategies that almost always work. In the following, I describe one strategy in particular that I’ve found useful over the years.&lt;/p>
&lt;div id="define-a-vision-for-your-research" class="section level2">
&lt;h2>Define a vision for your research&lt;/h2>
&lt;p>Before you start doing any concrete work towards developing your specific research question, you need to know what broad topic you want to work on. I call this the research vision. It turns out that developing a research vision is not that hard, for two reasons: First, the vision doesn’t have to be that specific; it doesn’t have to come with specific ideas for projects you want to do or questions you want to pursue. It’s just a guiding idea that tells you where to start. For example, a vision could be “I want to do computational work in cancer genomics” or “I want to study experimentally how bacteria adapt to novel environments” or “I want to work in infectious disease epidemiology.” Second, choosing a particular vision over another one is generally a low-stakes decision. There is interesting and valuable research to be done in the context of nearly any reasonable research vision.&lt;/p>
&lt;p>The one thing you should double-check though, in particular as graduate student or postdoc, is whether the vision you want to pursue fits broadly into the topics your lab is working on. If you’re in a molecular biology lab that studies cancer genetics but your research vision is to investigate the effects of climate change on future precipitation patterns then you have a problem. In this situation, either find a different research vision or consider switching labs.&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a>&lt;/p>
&lt;/div>
&lt;div id="read-the-literature" class="section level2">
&lt;h2>Read the literature&lt;/h2>
&lt;p>Once you have decided on your research vision, you need to start reading the relevant literature. There are two ways to proceed: First, if your research vision matches well with the work that is already going on in the lab you’re in, then start by reading the lab’s papers. Also, ask your PI for suggestions on which papers to read. Use all these papers as your starting point for a careful literature search.&lt;/p>
&lt;p>Second, if your research vision deviates somewhat from the current direction of the lab,&lt;a href="#fn3" class="footnote-ref" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a> or if there are other reasons why you can’t ask anybody for relevant papers, then skip right ahead to the literature search.&lt;/p>
&lt;p>To start your literature search, enter some key words or phrases into Google Scholar and see what comes up. Google Scholar tends to place the most highly cited papers at the top of its search results, so you’ll almost never go wrong by looking into the top hits. Using these papers as your starting point, expand your search by reading the papers that they cite (searching backwards in time), and also look up the more recent papers that cite them (searching forward in time).&lt;a href="#fn4" class="footnote-ref" id="fnref4">&lt;sup>4&lt;/sup>&lt;/a> By alternating between backwards and forwards search you will develop a solid grasp of the field.&lt;/p>
&lt;p>In addition to Google Scholar, the “related citations” function on PubMed is also an excellent way to deepen your knowledge of the field. Look up a paper on PubMed, and then read through the papers that PubMed flags as related to the paper you looked up.&lt;/p>
&lt;/div>
&lt;div id="stop-reading-the-literature-and-start-doing-something" class="section level2">
&lt;h2>Stop reading the literature and start doing something&lt;/h2>
&lt;p>It’s great to be a well-read scientist. Most students don’t read enough. There’s always something else to read. However, at some point, you have to stop reading and start doing. To give a concrete (but somewhat arbitrary) cutoff: If you’ve been reading for two months or more, or if you’re familiar with over 100 papers in your broad area, and you still feel like you don’t know enough of the literature to come up with your own project, then reading even more is likely not going to improve your situation much. At this point, it’s more important that you start doing actual research.&lt;/p>
&lt;p>How do you start if you’re not sure what your project is? My recommendation is to always start by reproducing somebody else’s work. Among all the papers in your broad area that you have read, pick one or two that you liked the most, and simply try to repeat what they did.&lt;a href="#fn5" class="footnote-ref" id="fnref5">&lt;sup>5&lt;/sup>&lt;/a> Very quickly, you will discover a few things: 1. It’s not that easy to reproduce existing work, and you can learn a lot in the process. 2. There are flaws, limitations, or pitfalls that weren’t really described in the paper. Maybe the paper’s methods work only under very specific conditions and fail the moment you try something slightly different. Or the methods are somewhat unreliable and fail at random times/under random conditions. 3. There are all sorts of things you’d like to know. Such as why the methods always fail when it’s raining outside. Or why there are certain strange trends you see in the raw data. 4. There are all sorts of things you’d like to have. Like a better way to prep your samples. Or some additional measurements no existing method can produce.&lt;/p>
&lt;p>Voilà, you have your research question. In fact, you probably have more than you bargained for.&lt;a href="#fn6" class="footnote-ref" id="fnref6">&lt;sup>6&lt;/sup>&lt;/a> You may have so many questions that you still don’t know where to start.&lt;/p>
&lt;/div>
&lt;div id="keep-it-simple" class="section level2">
&lt;h2>Keep it simple&lt;/h2>
&lt;p>Now it’s important to keep things simple. Of the many open questions you have, pursue the one that requires the simplest possible extension to existing work but will still provide meaningful progress.&lt;/p>
&lt;p>I don’t think I’ve ever seen a student fail for trying to do something too simple. However, I’ve seen plenty of student fail for trying things that were too complicated. Most students overestimate the complexity that is required to do good science. It’s better to do something simple, write it up, and publish than to do something complicated, get stuck, and get discouraged.&lt;/p>
&lt;/div>
&lt;div id="conclusions" class="section level2">
&lt;h2>Conclusions&lt;/h2>
&lt;p>You may think the whole process I propose is haphazard. I suggested you start with a random topic, do some reading, try to reproduce somebody’s work, and then pursue some extension to the work, an extension that will hopefully reveal itself to you as you work on the topic. The reason why this seems haphazard is because it is. Science doesn’t follow a simple A to B path. Albert Einstein famously said “If we knew what it was we were doing, it would not be called research.” Uri Alon calls it &lt;a href="http://www.ted.com/talks/uri_alon_why_truly_innovative_science_demands_a_leap_into_the_unknown">being stuck in the cloud.&lt;/a> Donald Rumsfeld talked about the unknown unknowns. Even though Rumsfeld wasn’t talking about scientific research, he correctly described the world in which most scientists operate day to day. We usually don’t know what we’re doing, we don’t know where we’re going, and we don’t know what we don’t know. However, we do stuff anyway, and from time to time we stumble upon a useful and novel bit of knowledge.&lt;/p>
&lt;/div>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>And sometimes, postdocs or even young faculty members struggle with the same issue. It mostly depends on when you were asked for the first time to come up with your own project. If your graduate project was basically handed to you by your PI, and similarly during your postdoc you were working on somebody else’s project, then you may never have independently developed a project before becoming an assistant professor.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>I would almost always recommend against switching lab while in grad school, but that is a topic for a different post.&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>It may seem strange that a graduate student would have her own research vision that differs from the lab’s vision. However, this scenario is often quite productive, both for the student and for the lab. The best PhD theses can take an entire lab into a new direction. PIs are generally aware of this and want their students to bring new ideas into the lab.&lt;a href="#fnref3" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn4">&lt;p>Searching forward in time used to be a complicated undertaking but it is trivial with tools such as Google Scholar. Simply click on “cited by” and see which other papers cite the paper you’re interested in.&lt;a href="#fnref4" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn5">&lt;p>Of course, you have to choose a paper that uses methods and/or materials that you have access to. If your favorite paper in the field uses a mass spec and you don’t have access to one then that’s a bad paper to try to reproduce.&lt;a href="#fnref5" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn6">&lt;p>That’s one of the reasons why senior scientists usually have tons of research ideas. The longer you’ve been around in science, the more you’re aware of what we don’t know.&lt;a href="#fnref6" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Uri Alon on creativity and staying sane in science: "Yes and ..."</title><link>https://sevimcengiz.github.io/blog/2014/06/14/uri-alon-on-creativity-and-staying-sane-in-science-yes-and/</link><pubDate>Sat, 14 Jun 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/06/14/uri-alon-on-creativity-and-staying-sane-in-science-yes-and/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>I just saw this &lt;a href="http://www.ted.com/talks/uri_alon_why_truly_innovative_science_demands_a_leap_into_the_unknown">nice TED Talk by Uri Alon&lt;/a> about how new scientific insights are generated. Even though the talk is a year old I think it’s worth posting, so here you go.&lt;/p>
&lt;p>Uri makes a number of points that I’ve been aware of for a long time but have never seen expressed quite so clearly:&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;p>Discovery is not linear. We usually don’t obtain the result we were aiming for. However, as we try, we make worthwhile discoveries that constitute the real scientific progress.&lt;/p>&lt;/li>
&lt;li>&lt;p>It is not helpful to shoot down ideas before you’ve even tried them. Statements like “this is never going to work” “this is too complicated” “X, Y, and Z are going to go wrong” “nobody will believe me anyway” are all not useful. Accept the crazy ideas, try them out, and see what happens. Say “yes and …”&lt;/p>&lt;/li>
&lt;li>&lt;p>Being worried about your research shuts down your creativity. Try to be more relaxed, even if things don’t go the way you think they should. Don’t try to obtain a particular goal, focus more on exploring the unknown.&lt;/p>&lt;/li>
&lt;li>&lt;p>When things don’t go well, talk to other people, look for support. Science can be hard on your mental well being, and to keep going sometimes you just need people to cheer you on.&lt;/p>&lt;/li>
&lt;/ol></description></item><item><title>How to pick a thesis committee</title><link>https://sevimcengiz.github.io/blog/2014/01/26/how-to-pick-a-thesis-committee/</link><pubDate>Sun, 26 Jan 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/01/26/how-to-pick-a-thesis-committee/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>I was asked the other day what factors to consider when picking a thesis committee. And I realized that this is not a question I have pondered a lot. Normally, when one of my students needs to pick a committee, I just recommend people that seem a good choice. I don’t have a properly thought out, systematic framework to steer the selection process. So with this post I’ll try to develop a more systematic approach to this question.&lt;/p>
&lt;p>Let’s first think about the purpose of the thesis committee. There are at least four distinct functions the committee should perform: 1. The committee should be your personal science advisory board. It should provide relevant expertise you or your adviser may lack. 2. The committee should review your research approach and verify that your data support your conclusions. 3. The committee should make sure you progress adequately and stay on track. 4. The committee should serve as advocates on your behalf in case your adviser develops unreasonable expectations.&lt;/p>
&lt;p>The advisory-board function is probably the most straightforward to satisfy. Pick a group of people that, jointly, cover the topics relevant to your work. For example, if you work on the evolution of influenza virus, you might want to pick an expert in the molecular biology of influenza, an evolutionary biologist, an epidemiologist, and a computational biologist or biostatistician.&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> Of course, to some extent the choice may depend on the expertise of the lab you’re in. If your lab is an influenza lab then your adviser may be the influenza expert and it might be more important to have another evolutionary biologist. By contrast, if your lab is an evolution lab, it might be more important to bring in more influenza expertise.&lt;/p>
&lt;p>For the remaining three points, personality of your committee members matters more than expertise. You want people who will speak up, who won’t let you get away with BS, but also who care for you and won’t put you through any unnecessary difficulties. Basically, people who can give you tough love. I wouldn’t worry too much about picking people who have a reputation of speaking their mind. Once you’re past candidacy, it’s unlikely that you will be kicked out of graduate school, and in any case if there are issues with your performance or research approach you’d want to hear about them earlier rather than later. In my mind, the worst committees are those that let a student bumble along for six years and then say “Well, this work doesn’t quite rise to the level that we expected from a PhD.” I think the best committee members are those that push you to develop a clear plan on how to complete your work, that tell you exactly what they expect from you before you can graduate, and that reign you in when your plans get overly ambitious (&lt;a href="https://sevimcengiz.github.io/blog/2013/12/7/excess-ambitionthe-eternal-flaw-of-all-phd-thesis-proposals">which happens to almost every student&lt;/a>).&lt;/p>
&lt;p>Next, consider possible inter-faculty dynamics. Don’t put two professors on your committee that are known to have issues with each other. You might end up as collateral damage in a fight between them.&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> Also, make sure your committee has at least some members who could speak up against your adviser if necessary. If your adviser is a very senior scientist, choosing four assistant professors as committee members would be inadvisable. Have at least one, and better two or more, committee members of comparable rank and seniority.&lt;/p>
&lt;p>Committee members to avoid are those that are overly passive, that like to talk just to hear themselves speak, and that tend to get lost in tangents or irrelevant minute details. Your adviser and your fellow graduate students should know who they are. Finally, it’s important that your committee members are actually available to you. The best committee doesn’t do you any good if you can never get them all into the same room at the same time. Therefore, I’d advise against any committee members who have a reputation for being difficult to schedule. It is generally known in the department who is never around, or who may rarely have more than one open time slot every few weeks. All else being equal, I would recommend against putting such a person on your committee.&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>Every committee should have a computational biologist or biostatistician, to verify data is analyzed properly and results are statistically sound.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>I have never personally witnessed something of this sort happening, but I’m sure some poor graduate student somewhere is finding himself or herself in exactly this situation right now.&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>6 reasons to do your graduate work in the lab of a junior PI, and 6 reasons not to</title><link>https://sevimcengiz.github.io/blog/2014/01/25/6-reasons-to-do-your-graduate-work-in-the-lab-of-a-junior-pi-and-6-reasons-not-to/</link><pubDate>Sat, 25 Jan 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/01/25/6-reasons-to-do-your-graduate-work-in-the-lab-of-a-junior-pi-and-6-reasons-not-to/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>One of the eternal questions of graduate schools is whether you should work with a junior or a senior PI. I have commented on this question before &lt;a href="https://sevimcengiz.github.io/blog/2013/9/29/how-to-choose-the-right-lab-for-graduate-school">and argued that either decision can be the right one.&lt;/a> Here, I present a more comprehensive list of arguments for and against. As you’ll see, there are plenty of arguments going both ways. You may assign more weight to some than others and thus arrive at a decision that is best for you. Ultimately, I think it doesn’t matter too much; there are other factors that are more important, such as whether you enjoy and fit in with the lab’s culture and approach to research, collaboration, publication, and so on.&lt;/p>
&lt;p>So here is my list. If you can think of something I forgot, please let me know in the comments.&lt;/p>
&lt;div id="reasons-to-do-your-graduate-work-in-the-lab-of-a-junior-pi" class="section level2">
&lt;h2>6 reasons to do your graduate work in the lab of a junior PI&lt;/h2>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;p>If you’re one of the early students in the lab of a rising star, you can rise to prominence with your PI. You may end up as the first author in one or more of your PI’s key publications, and this in turn may secure your own faculty position and seniority in the field.&lt;/p>&lt;/li>
&lt;li>&lt;p>A junior PI may have more time to supervise you. The lab is likely relatively small and you’re not competing with 10 other lab members for your PI’s attention. Also, your PI may not yet be that involved with university service and other non-research obligations, and thus have more time to interact with the lab (i.e., you).&lt;/p>&lt;/li>
&lt;li>&lt;p>A young lab may be doing some really novel, cutting-edge work. An older lab is more likely to work on the stuff they’ve always worked on, stuff that was real innovative 10 years ago but is an old hat now.&lt;/p>&lt;/li>
&lt;li>&lt;p>If your PI is not that established, there’s less risk that once you graduate your adviser is such a towering influence in the field that you can’t establish yourself as distinct from him/her.&lt;/p>&lt;/li>
&lt;li>&lt;p>In a large, established lab, you might find yourself working on a small part of a larger project. Even if you do excellent work, your name might in the end not get associated with the big paper that comes out of that work. (I’m not saying you won’t be a coauthor. I’m saying you might be one of 20 coauthors and nobody will think you were the person who made it happen.)&lt;/p>&lt;/li>
&lt;li>&lt;p>The younger your adviser, the less likely it is that he or she come down with a debilitating disease or die a sudden death. For example, &lt;a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3298961/figure/fig2/">the risk of death of a 60-year old man is 10 times higher than that of a 35-year old man.&lt;/a> Just avoid younger PIs with a passion for BASE jumping, cave diving, or motorcycle racing.&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div>
&lt;div id="reasons-to-do-your-graduate-work-in-the-lab-of-a-senior-pi" class="section level2">
&lt;h2>6 reasons to do your graduate work in the lab of a senior PI&lt;/h2>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;p>A junior PI is untested. It is less clear how sustainable the PI’s research program is, how likely the PI will be able to attract funding, and how good his/her research ideas are. If the junior PI is on a bad trajectory, it is likely that your PhD won’t be that great either. (Keep in mind, though, that your PI’s success depends to some extent on you!)&lt;/p>&lt;/li>
&lt;li>&lt;p>A junior PI may not be that powerful or well-connected in the field. The two of you may find yourselves fighting uphill battles with reviewers, journal editors, and other labs in the field. The exact same work might be lauded as the world’s greatest invention since sliced bread when coming from an established, senior lab or derided as inconsequential, boring, or wrong when coming from a junior lab. Having a junior adviser can also make it harder to find an academic job after you graduate.&lt;/p>&lt;/li>
&lt;li>&lt;p>A junior PI may not be that powerful or well-connected in the university. This may put you at a disadvantage when it comes to TA positions, university fellowships, and other dealings with university administration. In particular, if something unexpected happens, e.g. the class you were supposed to TA for gets cancelled, a senior PI is more likely going to have resources to deal with the situation.&lt;/p>&lt;/li>
&lt;li>&lt;p>The lab of a junior PI may not have the resources you will need to carry out outstanding research. In particular, if you join a lab in its first or second year, you may find yourself spending a year or longer just setting up lab infrastructure. By contrast, a large, established lab will likely have everything you need to do ground-breaking work the moment you walk into the door.&lt;/p>&lt;/li>
&lt;li>&lt;p>Since your PI is new, he or she still has to prove himself/herself. As a result, your PI might end up competing with you. For example, a junior PI might insist on being the one presenting your work at a conference where a senior PI might let you present your work yourself.&lt;/p>&lt;/li>
&lt;li>&lt;p>If you join the lab of an untenured professor, you risk that your PI won’t get tenure while you’re in the lab. That experience is likely going to be as disruptive to you as it will be to your PI. The worst-case scenario is an upcoming tenure decision 2-4 years out from when you start your PhD. If you’re only in your first year when your PI doesn’t get tenure, you should be able to just join another lab, without having wasted much time and effort. And if you’re in your fifth year or later, you should be able to finish up your dissertation work even if your PI has to close down his/her lab and move on. But if you’re right in the middle of your thesis work, you may have to throw away 2-3 years of work and start from scratch.&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Understanding the graduate-school interview or recruitment event</title><link>https://sevimcengiz.github.io/blog/2014/01/14/understanding-the-graduate-school-interview-or-recruitment-event/</link><pubDate>Tue, 14 Jan 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/01/14/understanding-the-graduate-school-interview-or-recruitment-event/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>It’s the beginning of the new year, and with it comes graduate admissions time. If you are currently applying for graduate programs in the sciences, you hopefully have received or will soon receive one or more invitations to interviews or recruitment events. If you’re wondering what such an invitation means, how these events work, and how to best prepare yourself, read on.&lt;/p>
&lt;p>First off, if you got invited, congratulations! You are well on your way to graduate school. For most programs, if you get invited to an interview, you have at least a 50% chance of getting admitted. Programs rarely invite more than twice the number of candidates they want to offer admission to, and frequently they plan to offer admission to nearly everybody they invite. Thus, a 50% chance of admission is actually a fairly conservative lower bound. Your chances may very well be substantially higher.&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>&lt;/p>
&lt;p>In fact, it’s important for you to realize that most programs are probably more worried about you not accepting their offer than you should be worried about them not making you an offer. Most graduate programs lose approximately half their candidates at the acceptance stage, i.e., the programs offer admission to twice as many students as actually end up joining the program. Therefore, you may be surprised to what an extent an interview weekend can turn into an advertising event for the school rather than an evaluation of your abilities to join the program.&lt;/p>
&lt;p>However, since the recruitment event may nevertheless contain a genuine evaluation component, you’d do well to prepare yourself properly for that aspect of the event. Below follow a few suggestions.&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;p>Relax. The stakes really aren’t that high, and if you just present yourself as a normal and reasonable person chances are good you’ll get admitted. In particular, if you try to sell yourself too hard or appear overly eager you may make a worse impression than if you present yourself simply as an average prospective student. Remember, at an acceptance rate above 50%, many of the average prospective students get accepted.&lt;/p>&lt;/li>
&lt;li>&lt;p>Prepare for one-on-one interviews with faculty. If your program is selective, then the key action happens in one-on-one meetings with faculty members. You will probably be scheduled to meet with 3-5 different faculty members. Prepare yourself for these meetings. Figure out what the faculty members are working on and read some of their recent papers as well as some of the classic papers that made them famous.&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> Keep in mind that stuff they have published three years ago may not be something they are working on today.&lt;/p>&lt;/li>
&lt;/ol>
&lt;ol start="3" style="list-style-type: decimal">
&lt;li>Make the faculty talk. Don’t assume you know what faculty members are interested in just because you have read some of their papers. Most active scientists are particularly excited about the work they are doing right now, or are planning to be doing next month. So, ask the faculty members what they are currently working on, what the main directions are for the lab, and for what projects they are currently recruiting students.&lt;a href="#fn3" class="footnote-ref" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a>&lt;/li>
&lt;/ol>
&lt;ol start="4" style="list-style-type: decimal">
&lt;li>&lt;p>Have broad interests. You will be asked what kinds of topics you are interested in. I would recommend a broad answer to this question, such as “I’m interested in host-pathogen interactions” or “I’m interested in microbial ecology” or “I’m interested in computational systems biology.” Most faculty members who recruit graduate students will have a specific project for which they are looking for a suitable candidate, and you are unlikely to guess what exactly they have in mind. If your answer is too specific (“I want to test this particular hypothesis, using methods A, B, and C in this particular experimental framework”) you risk giving the impression that you have little flexibility to adapt to the needs and interests of the lab. Of course, if you are asked explicitly to describe a particular study you might want to carry out, then describe one in detail.&lt;/p>&lt;/li>
&lt;li>&lt;p>Have a clear vision. It’s important to strike a balance between having broad interests and having no focus. In general, students who know what they want and know what their strengths and weaknesses are appear more competitive. If you see yourself primarily as a computational person, say so. If you want or don’t want to work with particular model systems, say so. (E.g., saying something like “I really want to work with bacteria” or “I am not particularly interested in microbes” is perfectly fine.) If you have one or two labs you are most excited about, say so.&lt;/p>&lt;/li>
&lt;li>&lt;p>Express a clear interest in one or a few labs. The best strategy here depends on the type of graduate program you’re interviewing with. If the program has a rotation system, then you need to be able to list a few labs that you could rotate in, otherwise you won’t look like a good fit for the program. If the program doesn’t have a rotation system and instead admits students directly into particular labs, then it’s Ok to be focused on one particular lab, or maybe two labs. For the latter types of programs, realize however that if you want to join lab A but they don’t have a slot for you then you may not get admitted, even if lab B would have been a perfectly reasonable choice for you and you for them.&lt;/p>&lt;/li>
&lt;/ol>
&lt;p>And finally, if there’s a social event with alcohol involved, don’t get mindlessly drunk and start behaving inappropriately. Even though I’ve known students to do so and get admitted nevertheless.&lt;/p>
&lt;p>&lt;strong>Update (01/15/2014):&lt;/strong> Several additional recommendations have been mentioned to me since I posted this. I’ll keep adding relevant information below.&lt;/p>
&lt;p>For your one-on-one interviews, have answers for the following two questions: 1. Why do you want to get a PhD in …? 2. Why do you want to join this program/attend this university? Also, be prepared to give a 2-5 minute summary of your past research and be able to expand this to 20-40 minutes if prompted by an interviewing faculty member.&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>Unfortunately, there is no way to know for sure, unless you have heard the inside scoop from a member of this year’s admissions committee. Just because a program admitted 80% of their candidates last year doesn’t mean they won’t reduce their admissions pool to 50% this year and vice versa.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>You find these papers by searching for the faculty member’s publications on Google Scholar or Web of Science, sorting by number of citations (Google Scholar does this automatically), and looking at the most highly cited papers on which the faculty member was either first or last author.&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>The last question may not be applicable if it’s unlikely you would join that person’s lab. Some of your one-on-one interviews will likely be with members of the admissions committee or simply other faculty members that were willing to do a few interviews. When you interview with those faculty, don’t pretend you’d want to join their lab if you know you never would. Do, however, ask the questions about current work and main directions of the lab. Those questions are always appropriate.&lt;a href="#fnref3" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>How glamour journals rose to prominence, and why they may not be needed anymore</title><link>https://sevimcengiz.github.io/blog/2014/01/04/how-glamour-journals-rose-to-prominence-and-why-they-may-not-be-needed-anymore/</link><pubDate>Sat, 04 Jan 2014 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2014/01/04/how-glamour-journals-rose-to-prominence-and-why-they-may-not-be-needed-anymore/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>In the ongoing discussion about the value of glamour journals such as Nature, Science, and Cell, I think it’s worth looking back and asking: “How did they rise to prominence?” and “Are they still serving the same role they did when they arose?” So let’s take a quick trip into the history of science communication, before the internet. Then we can ask what the internet has changed, and how we could make the best of current technology.&lt;/p>
&lt;p>I belong to the last generation of scientists that experienced science before the internet. I started doing research as an undergrad in 1995. At that time, I saw a web browser for the first time, and I sent my first email. While the internet had been around for a while by 1995,&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> its use was still very limited, and barely anybody outside academia had ever even heard of it. All this would change over the next 4-5 years, and by 2000 the internet started to become ubiquitous.&lt;/p>
&lt;p>I don’t think anybody who got into science after the year 2000 can imagine what keeping up with the literature was like before the internet. I started my postdoc in 2000. During my entire postdoc time (or since), I rarely ever went into a library. By that time, most journals had a solid online presence, including back issues. Articles that weren’t available online could be requested via inter-library loan, and they would arrive electronically. By contrast, during my PhD, I spent a lot of time at the library. I would make weekly trips to browse the latest issues of the scientific journals I was interested in. Because I was working at the interface between physics and biology, I had to visit the physics library and the biology library. For certain articles I also had to go to the chemistry library. I knew exactly which library had which journals, and which journals were available in multiple libraries. (Almost all libraries had Science, for example.) To figure out whether anybody was citing a particular paper, I had to confer with the &lt;a href="http://en.wikipedia.org/wiki/Science_Citation_Index">Science Citation Index,&lt;/a> which was a big book available at some libraries. For any article of interest, it would list by which other articles it had recently been cited. Invariably, the list of citing articles would contain articles in journals that were only available in a different library on campus, or not in any library at my university. So, after reading the Science Citation Index, I’d make the trip to a different library, or submit an inter-library loan request, or make a note for my next scheduled trip to a different library to look up a particular article. In the worst-case scenario, it could take weeks until I saw a particular article, and then I’d often find out the article wasn’t really relevant to what I was doing.&lt;/p>
&lt;p>Compare this to how literature search works today. I look up an article on Google Scholar, click on “Cited by” or “Related articles,” and find relevant related articles in seconds. For every article listed, I can get at least the title and the abstract, and for the vast majority of articles I can get the full text, all within a few seconds and while sitting at home on my couch. I can similarly browse any open-access journal, everything on Pubmed Central, and any paywalled journal my university has access to, from everywhere in the world. For all intents and purposes, the second I know a particular article exists, I can look it up and read it.&lt;/p>
&lt;p>What has any of this to do with glamour journals? I’m going to argue that in the time before the internet, glamour journals and other highly selective journals served a crucial role. In a world where looking up a reference can take between days and weeks, finding potentially interesting &lt;em>references&lt;/em> is much less valuable than finding potentially interesting &lt;em>articles.&lt;/em> Yes, you would go to the trouble of hunting down a particular article if it seemed directly relevant for your own work, but you certainly wouldn’t do so just to generally keep up with a broader field, much less all of science. Therefore, reading a journal such as Science or Nature, or even a more specialized but still fairly selective journal such as Genetics, was the only way to keep up with scientific progress. You went to the library, you took the physical copy of the journal, you browsed through it, you read the interesting articles, you learned something useful, you went home/back to your office.&lt;/p>
&lt;p>By contrast, these days, with nearly any article right at our fingertips, the process of publishing articles and of selecting articles can be decoupled. For example, I don’t consistently browse through the tables of contents of Nature or Science anymore, because I now have other means of discovering interesting articles. Any interesting article in my field I’ll come across sooner or later because Google Scholar recommends it to me, or somebody tells me about it in person, or it gets cited in a paper I read or review. For generally interesting articles, say the latest findings about global warming, I’ll likely see them mentioned on Twitter or Reddit. The advantage of all these methods of finding articles over browsing through tables of contents is that I’m not tied to the venue in which the article was published. I’m just as likely to come across an interesting article published in Nature as one in PLOS ONE. And the moment I learn about an article, I can read it. But imagine a print version of Twitter, in the time before the internet. If I had received per mail, once a week, a list of potentially interesting things published in the most random venues, I would never have followed up with reading any of them. The barrier to doing so would simply have been too high.&lt;/p>
&lt;p>Some people take this reasoning to the extreme and argue that since now everything is easily available online and search engines are powerful, we don’t need selective journals anymore at all. The best science will rise to the top, it will be cited, tweeted, mentioned on reddit, bloggers will write posts about it, and thus we might as well publish everything in PLOS ONE. I am not entirely convinced by this argument, for the following reason: It’s all well and good if other people cite and tweet your work, but what if they don’t? If you think you have done some really outstanding work, work that deserves more attention than your regular bread-and-butter efforts do, in a world where all science is published in PLOS ONE, what options to you have? In a world that has glamour journals, it’s of course obvious what you can do: You write a nice 3-6 page summary of your work, highlighting the most important findings and the broad relevance, you send it to one or more glamour journals, and you hope for the best. If you get through, you’ll have a much higher chance of getting your article cited, tweeted, etc., because people pay attention to the glamour journals, and they like to read short, clearly written articles that highlight key findings and broader relevance. But if there are no glamour journals, then you have no good option of indicating that in your own opionion, this article is more valuable than that article.&lt;/p>
&lt;p>So let me summarize the facts: (i) In the world of the internet, it doesn’t matter where something is physically published, as long as it is easily accessible through a URL. (ii) Glamour journals have lost the original purpose of making important science easily and broadly accessible. (iii) Publication venues that highlight interesting work by commenting and/or linking to it (such as Twitter, Reddit, Nature News and Views, Google Scholar, etc.) are highly valuable. (iv) Short, clearly written articles highlighting key insights and broader relevance are appreciated and highly valuable. (v) Authors have an interest in pointing out what they think are their most important works.&lt;/p>
&lt;p>These facts lead me to the following proposal: Let’s take all original science out of the glamour journals. Instead, allow authors to submit short summaries (maybe 2-3 pages) of work they have already published elsewhere, e.g. in PLOS ONE. These summaries would be reviewed editorially, and also by one or two expert scientists who’d be asked to judge whether the original article appears to be scientifically sound and noteworthy. Editors might reject a summary because it isn’t deemed sufficiently interesting or novel, and there would still be fighting and politicing about getting summaries into these glamour journals, but the system would relieve authors of several pressures: (i) Authors wouldn’t have to rewrite an article multiple times just to hope to get it published eventually in one of the selective journals. (ii) Authors could get their results out and cite them properly while still trying for that glamour slot. (iii) Since the original article of record would be in PLOS ONE or PeerJ or similar, it would become generally accepted to have even the most important work published in these journals. Nobody could look at a publication list and say “Oh, it’s just a bunch of PLOS ONE papers.” (iv) Hiring committees and granting agencies would still have the option to evaluate candidates by the number of summaries they have published in glamour journals, though I would hope they would do so to a lesser degree and pay more attention to the original articles.&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>The first web browser, which started the development of the modern internet, &lt;a href="http://en.wikipedia.org/wiki/Mosaic_web_browser">was released in 1993.&lt;/a> The concept of an online journal was unthinkable before the invention of the web browser.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Is there an avalanche of low-quality research, and if so, must we stop it?</title><link>https://sevimcengiz.github.io/blog/2013/12/21/is-there-an-avalanche-of-low-quality-research-and-if-so-must-we-stop-it/</link><pubDate>Sat, 21 Dec 2013 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2013/12/21/is-there-an-avalanche-of-low-quality-research-and-if-so-must-we-stop-it/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>&lt;strong>Update:&lt;/strong> &lt;em>It turns out the article in the Chronicle is not recent, I misread the date on the page. (The Chronicle has two dates on each page, today’s date and the article publication date.) I stand by everything else I say, though.&lt;/em>&lt;/p>
&lt;p>A recent article in the Chronicle of Higher Education argues that &lt;a href="http://chronicle.com/article/We-Must-Stop-the-Avalanche-of/65890/">“we must stop the avalanche of low-quality research.”&lt;/a> The authors decry the rapid growth of the scientific literature, which (as they argue) puts increasing strain on readers, reviewers, and editors without producing much benefit. They argue that this growth is driven by an increasing pressure on scientists to publish more, and the result is increasing amounts of low-quality publications. To address the pressure on scientists, they propose three fixes, of which one is Ok and two are positively inane. Maybe what we really have to stop is the avalanche of low-quality, non-reviewed opinion pieces published on web pages?&lt;/p>
&lt;p>Reading through the article, I found it difficult not to wonder whether the authors had ever heard of the internet or of modern information-processing technology (e.g., Google). Now, to be fair, none of the authors are in the natural sciences. The authors work in English, mechanical engineering, medicine, management, and geography. I don’t really know these areas. My own work is in biology, and I’m also somewhat familiar with the publishing cultures in physics and in computer science. So, everything they say may make sense in their fields, but it doesn’t in mine. I’m not convinced we have a major crisis, and I certainly don’t think their proposed fixes are any good. Let’s take a look at their proposed solutions first.&lt;/p>
&lt;div id="limit-number-of-papers-submitted-for-job-applications-or-promotions" class="section level2">
&lt;h2>Limit number of papers submitted for job applications or promotions&lt;/h2>
&lt;p>The first fix, to limit the number of papers that applicants are allowed to submit for job applications or promotions, is actually somewhat reasonable. Applicants should be judged on the quality of their work, not on the mere quantity of output. However, I am strongly opposed to saying applicants are not even allowed to mention anything beyond their key 3-5 papers. Why should productivity be punished? What if they wrote 10 important papers? Should Ed Witten be limited to list only 5 papers? (To date, he has written &lt;a href="http://scholar.google.com/scholar?hl=en&amp;amp;q=edward+witten">over 30 papers with over 1000 citations each!&lt;/a>) While there are negative outliers in academia, people who produce huge amounts of mindless drivel, I definitely see a correlation between quantity and quality. The most interesting and influential papers are generally written by the most productive researchers. I have previously given arguments for why we would &lt;a href="https://sevimcengiz.github.io/blog/2013/11/3/no-one-reads-your-paper-either">expect such a correlation to exist.&lt;/a>&lt;/p>
&lt;p>Most job search and promotion processes that I am aware of have already found a solution to this problem, by asking applicants to submit both (i) a full list of all publications and (ii) the 3-5 most important papers, possibly with a statement explaining their impact. This is good practice that strikes a balance between quality and quantity, it allows applicants to showcase both how good they are and how consistently productive they are, and most importantly, it is already common practice. So point 1 is a non-issue, from where I stand.&lt;/p>
&lt;/div>
&lt;div id="evaluate-researchers-by-impact-factors" class="section level2">
&lt;h2>Evaluate researchers by impact factors&lt;/h2>
&lt;p>Evaluating researchers by impact factor is such an absurd and untimely suggestion, I can’t help but wonder whether the authors have been living under a rock for the last 10 years. It’s particularly ironic that the Chronicle of Higher Education would publish this statement a mere 11 days after nobel-prize winner Randy Schekman publicly proclaimed that luxury (i.e., high impact-factor) journals such as Nature, Cell, and Science &lt;a href="http://www.theguardian.com/commentisfree/2013/dec/09/how-journals-nature-science-cell-damage-science">“are damaging science.”&lt;/a> Did the authors really not see this article, &lt;a href="http://scholarlykitchen.sspnet.org/2013/12/11/this-takes-the-prize-editor-of-new-luxury-oa-journal-boycotts-luxury-subscription-journals/">nor the widespread outrage it caused over containing a cheap plug for a different luxury journal?&lt;/a> If there is one problem we have in science right now, at least in the biomedical field, it’s an over-reliance on impact factors and publications in high-profile journals. The outcry over Schekman’s article shows how sensitive of an issue this is, and how many scientists are concerned about the growing pressure to publish in only the highest-impact journals. Schekman himself addresses this in &lt;a href="http://theconversation.com/how-to-break-free-from-the-stifling-grip-of-luxury-journals-21669">his response to the criticism he received.&lt;/a> Scientists should be judged on the quality of their work, not on whether or not they published in Nature.&lt;/p>
&lt;/div>
&lt;div id="limit-the-length-of-papers-published" class="section level2">
&lt;h2>Limit the length of papers published&lt;/h2>
&lt;p>I don’t see how imposing page limits connects at all to the issue at hand. Surely, if we want fewer but higher-quality publications, the papers should be longer not shorter. Also, I strongly oppose to the split model with a brief (4-6 page) main article (i.e., advertisement) accompanied by longer supporting materials. Invariably, the supporting materials are not written as carefully as the main article, and the quality of the paper as a whole suffers. Notably, PNAS just went the other direction, and now allows papers of up to 10 pages in length in their online-only PNAS Plus edition. This was a very welcome change, I think. The 6-page limit of PNAS was often too limiting, whereas most articles fit comfortably within 10 pages.&lt;/p>
&lt;/div>
&lt;div id="is-there-too-much-pressure-to-publish" class="section level2">
&lt;h2>Is there too much pressure to publish?&lt;/h2>
&lt;p>While there is pressure to publish, frankly I don’t see that there is &lt;em>excessive&lt;/em> pressure to publish. From what I see, for example in conversations with colleagues, the common expectation is reasonable productivity both in terms of quantity and in terms of quality. In terms of quantity, reasonable is usually a number between 1 and 10 papers per year. Publish less, and people start wondering whether you’re working consistently, and in particular whether you’ll keep working in the future. Publish much more than 10 papers per year, and people start looking at you suspiciously. I sat on a grant-review panel once where one applicant claimed his previous 3-year NSF grant had led to ~100 publications. People were very suspicious of this claim and the grant did not get good reviews, even though the science seemed to be reasonable. (I’m not saying the proposal would have been funded if the applicant had had fewer publications, but the high number certainly didn’t help; if it had any effect it was a negative one.) In most areas of Biology, I think 2-3 papers a year will be considered perfectly reasonable for anybody but a senior PI running a large lab. (This includes all papers with your name on, not just first-author papers.)&lt;/p>
&lt;p>In terms of quality, I stick to my earlier recommendation: &lt;a href="https://sevimcengiz.github.io/blog/2013/11/3/no-one-reads-your-paper-either">publish at least one paper a year that has some real substance.&lt;/a> Where exactly that paper is published is secondary, I believe. Publishing the occasional high-profile article in a luxury journal can’t hurt, but I hope that we as scientists can collectively learn to pay a little less attention to where something is published and pay more attention to the content. We shouldn’t hire somebody without having carefully read at least one or two of their papers, and I think the more diligent search committees operate like that already.&lt;/p>
&lt;p>With regards to excessive workload for editors and reviewers, I think there are several things that could be done relatively easily:&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;p>Institute a system of reviewing credits, where you receive one credit for each article you review and you have to spend a number of credits (e.g. 6) to submit an article. This would ensure that everybody who publishes carries their fair share on the reviewing side.&lt;/p>&lt;/li>
&lt;li>&lt;p>Have more graduate students and postdocs review papers. Not every paper needs to be reviewed by three members of the NAS. In fact, I often find that graduate students write better reviews than senior scientists do, because the graduate students take the job much more seriously and put way more effort into it than an established scientist normally would.&lt;/p>&lt;/li>
&lt;li>&lt;p>Have less stringent reviewing criteria, don’t judge impact. Much of the excessive reviewing load actually comes from the pressure to publish in highly selective journals. Thus, many articles make the mandatory trek from Science to Nature to PNAS to PLOS Genetics to PLOS ONE, possibly undergoing four or more separate rounds of review. It’s not uncommon for me to review the same article several times for different journals. And in the end, everything gets published anyway, somewhere. If it was the reviewers’ job to only look for major scientific flaws, then most articles could be published after 1-2 rounds of review, cutting the total review burden way down.&lt;/p>&lt;/li>
&lt;li>&lt;p>Improve tools for post-publication evaluation of articles. At present, all we have is citations and word-of-mouth. (“Have you seen the latest paper by X in PNAS? It’s really not very good.”) I’m sure we can do better than that, and over time we’ll find ways to put modern computing power and crowd-sourcing ideas to good use. &lt;a href="http://www.the-scientist.com/?articles.view/articleNo/37969/title/Post-Publication-Peer-Review-Mainstreamed/">NCBI’s PubMed Commons is a first step in this direction.&lt;/a> I’m sure over the next 10-20 years we’ll see many more innovative ideas to evaluate the quality of scientific work post publication.&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>The value of pre-publication peer review</title><link>https://sevimcengiz.github.io/blog/2013/12/21/the-value-of-pre-publication-peer-review/</link><pubDate>Sat, 21 Dec 2013 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2013/12/21/the-value-of-pre-publication-peer-review/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>I see lot of discussion these days about the value of peer review. Are journals too selective? Are acceptance decisions arbitrary? Does peer review actually catch scientific mistakes or fraudulent practices? Wouldn’t it be better to just put everything out there, say on preprint servers, and separate the wheat from the chaff in post-publication review? I’m not quite ready yet to give up on pre-publication peer review. I think it serves a useful purpose, one I wouldn’t want to do away with. In the following, I discuss four distinct services that peer review provides, and assess the value I personally assign to each of them.&lt;/p>
&lt;div id="peer-review-screens-out-nonsense-and-pseudoscience" class="section level2">
&lt;h2>Peer review screens out nonsense and pseudoscience&lt;/h2>
&lt;p>It’s important that somebody screen all potential scientific publications for actual scientific content. I don’t mind publishing null results, replication studies, or studies that present only a very minor advance. All of these works contain real science, and they may find some use at some point in the future. However, we must never mix science with pseudoscience. Someone has to assure that whatever gets published in a scientific journal is not complete nonsense. Even the preprint archive arxiv.org has &lt;a href="http://arxiv.org/help/endorsement">some sort of a screening and filtering system in place to hold back the crackpots.&lt;/a> In most cases, nonsensical papers would be caught by the editor and not even sent out to review. Nevertheless, we can consider filtering out nonsense to be an essential service of the pre-publication review process.&lt;/p>
&lt;/div>
&lt;div id="peer-review-catches-major-mistakes-andor-fraud" class="section level2">
&lt;h2>Peer review catches major mistakes and/or fraud&lt;/h2>
&lt;p>Many people seem to think that it is the reviewers’ job to catch major mistakes and/or fraud. And when they fail to do so, that is taken as evidence that peer review doesn’t work. I don’t think we can put such a high burden on the reviewers. Ultimately, the burden of producing correct and genuine results lies with the author. Peer review operates under the assumption that fundamentally the authors are honest and reasonably capable scientists. If peer review does happen to catch a major issue with a paper, that’s great, but generally I think that post-publication review is the much better venue to address major flaws or scientific misconduct.&lt;/p>
&lt;/div>
&lt;div id="peer-review-assess-novelty-potential-impact-and-fit-with-the-journal-scope" class="section level2">
&lt;h2>Peer review assess novelty, potential impact, and fit with the journal scope&lt;/h2>
&lt;p>Whether reviewers (or editors) should consider novelty and impact, and whether journals should be selective at all, is probably the most contentious issue in peer review. Traditionally, this has always been part of peer review. However, there are now several journals that explicitly state review should only assess scientific soundness (e.g. &lt;a href="http://www.plosone.org/static/information">PLOS ONE&lt;/a> or &lt;a href="https://peerj.com/about/aims-and-scope/">PeerJ&lt;/a>). I think there are valid arguments for both sides. On the one hand, it is imperative that we have publishing venues that will publish any scientifically sound study. Nobody benefits if a valid study is suppressed just because some reviewers didn’t find it interesting. If there’s no obvious scientific flaw, put it out there and let the readers (and Google) sort it out.&lt;/p>
&lt;p>On the other hand, I think that more selective journals can provide value as well. In my mind, where science has gone off-track is that the most selective journals (which are also considered to be the most prestigious ones, e.g. Nature, Science, Cell, PLOS Biology, PNAS) employ arbitrary selection criteria based primarily on the subjective goal of publishing “the best science.” As a consequence, whether I can publish in such journals depends much more on my marketing skills than on my scientific skills, and also on whether I’m working on a sexy study system.&lt;/p>
&lt;p>By contrast, the next lower tier of selective journals usually employ more objective selection criteria, and those arguably provide a useful value. For example, I’m an Associate Editor for PLOS Computational Biology, a fairly selective journal. The main requirement for publication in PLOS Computational Biology is &lt;a href="http://www.ploscompbiol.org/static/information">that you have produced high quality computational work that yields a novel biological insight.&lt;/a> In my mind, it is fairly straightforward to determine whether a paper satisfies that requirement or not. I also think that any capable computational biologist can jump over that bar. As a consequence, I feel that we’re providing useful selectivity without generating excessive artificial scarcity or making highly arbitrary decisions. If I see that somebody has on their CV a couple of PLOS Computational Biology papers, I can reasonably assume that they are doing consistent, high-quality computational work leading to novel insights into biological systems.&lt;/p>
&lt;/div>
&lt;div id="peer-review-helps-authors-improve-their-articles" class="section level2">
&lt;h2>Peer review helps authors improve their articles&lt;/h2>
&lt;p>In my mind, this last point is the most important point, and the reason why I’m not willing to give up pre-publication review in its entirety. In my experience as author, reviewer, and editor, the most common outcome of the review process other than “reject due to insufficient novelty” is “major revision.” The reviewers agree that the study has merit in principle, but they see a number of possible revisions that would improve the article. I have seen it countless times, both as author and as reviewer or editor, that a study was vastly improved after the first set of reviews. Sometimes reviewers catch an issue the authors hadn’t noticed, sometimes they have a really cool idea that brings the study to the next level, and sometimes they simply tell you that you have to work on your writing if you want to get your point across. Either way, this input is invaluable, and it improves the scientific literature tremendously. If we went to a system that operated entirely on post-publication review, we would probably still see the same kind of comments by reviewers, but there would be very little incentive for the authors to go and revise their papers accordingly.&lt;/p>
&lt;p>One downside to this aspect of peer review is that sometimes reviewers just keep insisting on changes that the authors don’t deem necessary or appropriate. This is another form of peer review gone wrong. The reviewers should make helpful suggestions, but they should not tell the authors how to write their paper. One solution to this issue is to make peer reviews public and leave with the authors the ultimate decision of whether or not they want to publish, as &lt;a href="http://www.biologydirect.com/about">Biology Direct does.&lt;/a> Another possibility is to allow authors to opt-out of re-review, as &lt;a href="http://www.biomedcentral.com/bmcbiol/about#publication">BMC Biology does.&lt;/a>&lt;/p>
&lt;/div></description></item><item><title>Excess ambition—the eternal flaw of all PhD thesis proposals</title><link>https://sevimcengiz.github.io/blog/2013/12/07/excess-ambitionthe-eternal-flaw-of-all-phd-thesis-proposals/</link><pubDate>Sat, 07 Dec 2013 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2013/12/07/excess-ambitionthe-eternal-flaw-of-all-phd-thesis-proposals/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>I cannot remember ever having seen a graduate student present a PhD thesis proposal and be criticized for lack of ambition. It never happens. Even the weakest students—especially the weakest students—present proposals that are overly ambitious and that won’t ever get done, and certainly not in the 3–4 years remaining until graduation. In fact, in my experience it is exceedingly rare that a student presents a reasonable proposal, one that is actually doable during the remainder of the time in graduate school. Usually, those only happen when students “forget” to have their qualifying exams and end up presenting their “proposal” six months before the intended graduation date. In those cases, the students know that they won’t accomplish much new between proposal day and defense day, and basically present a proposal that consists entirely of completed work.&lt;/p>
&lt;p>In Biology, most professors expect graduate students to complete about three projects, corresponding to the magical three specific aims in a typical grant proposal.&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> In my mind, a graduate student who is defending her proposal, 2–3 years into her program, should have one project completed, one well under way, and one in the early planning stages. Students doing complicated experimental work might be less advanced at that time, but at a minimum they should have one project well under way by the time they defend their thesis proposal. This gives a pretty good rule of thumb for the amount of work the proposal should encompass: Aim 1 should be the work that is in the bag, and Aims 2 and 3 together should not require more than twice the amount of work already accomplished. Instead, what I commonly see is that the completed work is only a small component of Aim 1, which alone is going to take another two years to completion. Aim 2 will need four years on top of that, and Aim 3 another ten. Basically, many graduate students propose to carry out a lifetime of research during their graduate work.&lt;/p>
&lt;p>I don’t quite know why PhD proposals tend to be overly ambitious. Maybe it’s youthful optimism or naiveté. I suspect, though, that there is a component of fear, the eternal graduate student fear of not being sufficiently productive, of not doing enough. Ironically, this fear often causes students to overlook the successes that are within reach and instead try to reach for the stars. In general, doing a successful thesis is a fine balancing act between being overly ambitious and playing it too safe, a topic for another post. However, there’s a difference between an actual PhD thesis and a thesis proposal: The thesis should contain some exciting, risky work, but for the proposal most professors want to see a plan that is doable, not one that might be doable if the stars align correctly. As a smart graduate student, you have two alternative plans, one safe and one daring, you work on both of them at the same time, and you present the safe one during the committee meeting.&lt;/p>
&lt;p>A second, related issue I frequently notice is that students display poor judgment in how much work they can realistically accomplish in the remaining time. Estimates are consistently too optimistic. If you are in year three, and you have completed 50% of your first project, it is unlikely that you’ll complete this and two entirely different projects in the remaining 2–3 years of your PhD. Further, unless you’re a paper-writing machine, it’s unlikely that you can write a paper in less than three months. (And if you are a paper-writing machine, you should have plenty of papers by the time you defend your proposal anyway.) So, if you still have three manuscripts to complete, plus a thesis, the writing time alone is going to be about a year. If you’re already halfway into year three, you’ll have about another 18 months of actual research work you can do, because the other 12 you’ll spend writing. (Of course I’d recommend that you &lt;a href="https://sevimcengiz.github.io/blog/2013/8/26/when-should-you-stop-doing-science-and-start-writing-a-paper">don’t wait all the way till the end before you start writing&lt;/a>, but the math comes out the same.) My personal rule of thumb is things take about three times as long as students estimate things will take. So if a student says a particular project needs another three months in the lab plus a month to be written up, I expect that project to be done around the same time next year.&lt;/p>
&lt;p>In conclusion, when you prepare your thesis proposal, realistically assess how much work you can complete during the remainder of your graduate years. Don’t assume that your productivity will double or triple over the next two years, because it won’t. Budget at least three months for every paper you have to write, and triple the time you think it takes to complete the remaining lab work. If you have papers in review, consider that responding to reviewer comments and revising a paper frequently takes another two to three months, during which nothing else gets done. If you end up with a plan that will require another five years of work or more, then you’ll have to change your aims. See whether your current Aim 1 can be broken down into reasonable sub-aims which can be considered the separate chapters of your thesis. It’s quite common for me to conclude a PhD proposal defense by telling the student it’d be best to scrap Aims 2 and 3 altogether and instead expand Aim 1 into the entire thesis. If you come to that realization before the committee meeting, I don’t have to tell you so during, and everybody is happier.&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>While proposals with either two or four aims can also be viable, two can appear as unimaginative (he really couldn’t think of anything else?) and four is getting dangerously close to being overly ambitious, so three it is.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>The critical need in a grant application</title><link>https://sevimcengiz.github.io/blog/2013/10/17/the-critical-need-in-a-grant-application/</link><pubDate>Thu, 17 Oct 2013 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2013/10/17/the-critical-need-in-a-grant-application/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>It’s surprising how many grant applications do not clearly spell out a critical need. A critical need is the fundamental reason why a grant should exist. Without it, there’s really not much of a point to the grant. And yet, a critical need is frequently not stated. The common mistake that people make is that they confuse a gap in knowledge with a critical need. They clearly spell out what gap in knowledge they plan to address. And mind you, that’s an important component of a grant proposal. But if you stop there, if you never explain &lt;em>why&lt;/em> there is a critical need to bridge the gap in knowledge, then your application is going to fall short. Unless the reviewers really like you for other reasons, they will probably not be impressed with your grant application.&lt;/p>
&lt;p>Let me explain the difference between a gap in knowledge and a critical need by way of an example. Assume you go out Saturday night and get drunk. In the morning, you wake up and have no recollection of how you made your way home. This is clearly a gap in knowledge. But there’s no critical need attached to that gap. I couldn’t care less whether you stumbled home, took a cab, or hitched a ride with a friend. Your grant on “The modes of transportation by which I found my way home last Saturday” is not going to be selected for funding by my agency. Now, instead, consider the following scenario. You go out Saturday night and get drunk. You wake up Sunday morning, not remembering how you got home. Upon looking into the mirror, you find that you’re battered and bruised. You’re also covered in blood. And your husband is nowhere to be found and doesn’t answer his cell phone. In this scenario, I think most people would think that there is a critical need to figure out what happened, to fill the gap in knowledge. Your grant on “Why I am innocent and didn’t kill my husband. Honestly!” would probably fare much better than the previous one.&lt;/p>
&lt;p>My point is: there are all sorts of gaps in knowledge that aren’t attached to a critical need. Grants to fill those knowledge gaps will generally not fare that well in review. Therefore, think carefully about the critical need your research will fill. If you can’t think of one right now, think harder. I’m sure you can immediately name the gap of knowledge you’re working on. The critical need should be just as obvious to you. Note: If you’re a junior scientist working on questions that your adviser has funding for, then your work almost certainly satisfies some critical need. If you’re not sure what it is, ask your adviser.&lt;/p>
&lt;p>Where in a grant application should you express the critical need? It has to come early, so your reviewers don’t waste a lot of time being bored or disinterested. Also, it needs to be in a &lt;a href="https://sevimcengiz.github.io/blog/2013/9/26/writing-paragraphs-that-make-sensethe-topic-and-the-stress-position">position of stress,&lt;/a> so your reviewers correctly perceive its importance. Consequently, there’s only a single place in a grant proposal where it fits: the last sentence of the first paragraph. The entire first paragraph should build up to the critical need, which justifies why you’re writing your grant in the first place.&lt;/p>
&lt;p>Let me illustrate this idea with the first paragraph of a grant I recently wrote:&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>&lt;/p>
&lt;blockquote>
&lt;p>Comparative sequence analysis is a cornerstone of modern biology, with applications ranging from determining the evolutionary history of species, to tracking pathogens, to identifying sites in a protein under positive or purifying selection. For protein-coding genes, comparative analysis has shown that protein structure strongly influences sequence variability: buried sites tend to be more conserved, and exposed sites—more variable. Deviations from this expectation can suggest functional importance. For example, a &lt;em>rapidly evolving buried site&lt;/em> in a viral enzyme might be near the binding pocket and contribute to the evolution of drug resistance. A &lt;em>conserved exposed site&lt;/em> might be involved in important protein–protein interactions. Yet conventional tools for comparative sequence analysis ignore protein structure and operate on sequence data alone. &lt;strong>We, therefore, see a critical need to develop comparative methods that can jointly analyze sequence and structural data.&lt;/strong>&lt;/p>
&lt;/blockquote>
&lt;p>This was the first paragraph of the Aims page, arguably the first piece of text in the grant that the reviewers read. As you can see, the entire paragraph builds up to the critical need, which is to develop comparative methods that can jointly analyze sequence and structural data. This is a critical need only because we believe—and have some preliminary data to demonstrate—that sequence analysis in a structural context will be more informative for important applications than sequence analysis in the absence of structural information can be. If there weren’t any important applications, or if the structural information made little difference to the outcome of the analysis, then the critical need would evaporate. There’d still be a gap in knowledge around sequence analysis in a structural context, but there wouldn’t be a critical need to bridge that gap.&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>For full disclosure, I should say that this grant wasn’t funded. However, it was scored in the top third of applications (26% percentile). From my reading of the reviews, I would say that the reviewers believed our critical need. We just weren’t sufficiently competitive with the actual work we were proposing. Specifically, we didn’t have sufficient preliminary results to &lt;a href="https://sevimcengiz.github.io/blog/2013/10/17/which-grants-get-funded-at-single-digit-funding-rates">give our proposal that aura of magic.&lt;/a>&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Which grants get funded at single-digit funding rates?</title><link>https://sevimcengiz.github.io/blog/2013/10/17/which-grants-get-funded-at-single-digit-funding-rates/</link><pubDate>Thu, 17 Oct 2013 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2013/10/17/which-grants-get-funded-at-single-digit-funding-rates/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>Throughout the last decade, funding rates at most US funding bodies have kept declining, and they have now reached awfully low levels. These days, single-digit success rates are pretty common. At the NSF, in some competitions I’ve seen success rates of 5% or less. As a result, most US scientists are struggling to figure out how to make the best of this abysmal situation. One could view the entire granting process as a lottery, and say that at a funding rate of 5% it takes an average of 20 submissions to get one project funded. And certainly some scientists operate this way and just write grant after grant after grant. However, I’m not convinced that that’s a viable strategy. While there is certainly an aspect of randomness to grant review, and sometimes a mediocre grant gets rated much higher than it should while an excellent grant gets triaged, I don’t think that this randomness matters much at the top end. If funding rates were around 30–40% then yes, one could probably write 3–4 grants and expect one to be funded just by chance. But I will argue that the top 5–10% of grants, the ones in the currently fundable range, are fundamentally different. If your grant isn’t like one of them, it probably has a near-zero chance of being funded. And if it is, it may well have a 50% or higher chance. The trick to being funded is hence to only write grants that can score in the top 10%. Easy. (Yes, I’m being sarcastic here.)&lt;/p>
&lt;p>The good news is that I think it’s relatively straightforward to recognize grants that can score in the top 10%. The bad news is that I don’t know how to write them. Or rather, I don’t know how make all the necessary things come together such that I can reliably write grants that will score in the top 10%. All I can do is write a grant and then evaluate whether it’ll be good enough. Usually—but not always—the answer is “no.” In those cases, I probably might just as well not even submit. For the small number of grants where the answer has been “yes,” my success rate hasn’t been all that bad in recent years.&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a>&lt;/p>
&lt;p>So how do 10th-percentile-and-up grants differ from lower-scoring grants? I like to think of them as magical. They have all the required pieces coming together in just the right way. They address an important question, use a sexy study system, have just the right combination of theory and experiment, and have extensive preliminary results demonstrating feasibility. They also are well written and easy to understand even by people outside the field.&lt;/p>
&lt;p>As you can see, some of these elements are not under your control. For example, if you’re a theoretician like me, you may not be able to add experiments to your proposal. You could gang up with an experimentalist, but then the two of you may not have any convincing joint preliminary data. More generally, you may have a great idea, but it may require three years of work to demonstrate feasibility and you won’t get it funded until you’ve put in those three years. Also, the study system you chose to work on, for whatever reason, may just not be as sexy as other systems. If you’re studying virus evolution using bacteriophages and somebody else is doing more or less the same work with some deadly human virus, chances are your proposal will be considered less competitive.&lt;/p>
&lt;p>On the other hand, some things are under your control. You definitely can improve your writing and your grantmanship. If you’re not regularly scoring in at least the top 30%, then either the science you’re doing is absolutely no good (possible, but not probable) or you just don’t know how to write a competitive grant (more likely). In the latter case, there are resources that you can take advantage of. For example, the seminars and books offered by &lt;a href="http://www.grantcentral.com/">these people&lt;/a> are pretty good.&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> The NIH has a page with &lt;a href="http://www.niaid.nih.gov/researchfunding/grant/pages/appsamples.aspx">annotated examples of high-scoring grants.&lt;/a> I will probably also write a few blog posts about grant writing in the future, so stay tuned.&lt;a href="#fn3" class="footnote-ref" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a>&lt;/p>
&lt;p>Nevertheless, as an individual investigator, in particular if you’re a junior one, it will always be difficult to jump over the bar separating the top 10% from the bottom 90%. Unless you’re literally the best in the world at doing whatever it is you are doing, your individual track record and preliminary results may not be good enough to compete at the highest level. In general, I think it’s easier to be successful as a team, competing for larger pots of money. If a funding body wants to establish a center or make a large collaborative grant on a certain topic, and you pull together the best people in the nation working on that topic, then your proposal will be hard to beat. This doesn’t mean that the single investigator grant is dead. It just means that you should evaluate carefully (and realistically!) where your work falls. And don’t waste your time on proposals that are not going to be fundable. If, however, you can see that you have all the right pieces in place, that you can write that magical proposal where everything comes together beautifully, then by all means go for it!&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>Over the last 5 years, about 2–3 grants that I thought were good enough to be funded did actually get funded. That’s good enough to run a lab on. Over that same time period, I’ve probably written only 2–3 grants that I thought &lt;em>had a realistic chance of being funded.&lt;/em> So that’s a near 100% success rate among the really good grants. I’ve of course also written many grants that didn’t get funded. But for all of those, by submission time I could have listed reasons why they likely wouldn’t make it into the top 10%, and they didn’t.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>I have no affiliation with them. I just took their training once and found it helpful.&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>Yes, I just put myself on the same level with the leading grant coaches and the NIH. I’m still trying to figure out how this modesty things works.&lt;a href="#fnref3" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>How to choose the right lab for graduate school</title><link>https://sevimcengiz.github.io/blog/2013/09/29/how-to-choose-the-right-lab-for-graduate-school/</link><pubDate>Sun, 29 Sep 2013 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2013/09/29/how-to-choose-the-right-lab-for-graduate-school/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>Choosing the right lab for graduate school can be a daunting prospect. There are so many issues to consider. So many things that could go wrong. And you have to join the most prestigious lab you can get into, don’t you? Well, let’s consider for a moment what the main point of graduate school is. Graduate school is the time when you transition from being a student to being an independent scientist. It is primarily an educational experience. While in graduate school, you should pick up some subject-matter knowledge in your field. You should become familiar with the most important experimental or computational tools of your trade. You should learn how to choose scientific questions and how to solve them. You should develop general life skills such as how to communicate, how to work with other people, and how to get stuff done on time and to spec. So how do you find the right lab in which to acquire all these skills?&lt;/p>
&lt;p>I think that the most important overall consideration should be whether you feel comfortable with the PI, the other members of the lab, and the overall lab culture. In my mind, this is even more important than the specific research area the lab works in. Graduate school will usually take about five years, and it is an important time in your personal development. The people you meet in graduate school will likely remain colleagues and friends for the rest of your life. If you’re miserable the whole time, it’s going to be an awful experience. And even if you manage to power through the misery, you won’t have performed at your best. You could have done better elsewhere.&lt;/p>
&lt;p>Further, even in the best-case scenario, you can expect that something is going to happen over these five years that will challenge you or bring you down. Maybe a close friend or relative will die. Maybe you’ll experience a prolonged period of illness. Maybe you’ll get pregnant. Maybe you’ll go through a bad relationship breakup. Maybe you’ll just be generally disenchanted with science or with your project in particular. Maybe you’ll feel that you’re not getting enough done and that everybody else is progressing so much more quickly than you are. Whatever it’s going to be in your case, you can be certain that something is going to come your way. And when it happens, being in a lab that is supportive, helpful, and pleasant can make all the difference between a successful PhD and a premature termination.&lt;/p>
&lt;p>But what about building a competitive cv? Shouldn’t you go with the most famous lab, so you’ll get great publications and will be set for your future career in academia? I’m not convinced. If you’ve read my &lt;a href="https://sevimcengiz.github.io/blog/2013/9/6/from-undergraduate-to-faculty-member-critical-decision-points-in-the-academic-career">earlier post&lt;/a>, you know that I believe all that matters career wise is that your cv is strong enough by the time you graduate that you’ll get the next job on your career path. If you’re on the academic track, that will usually mean 2-3 high-quality first-author publications, plus maybe a few more papers where you’ve made smaller contributions. In this context, “high-quality publications” means solid papers in recognized journals in your field. It does not mean Nature, Science, Cell, or PNAS. (While those won’t hurt, they’re generally not needed to get a good postdoc.) If you’re not on the academic track, the requirements aren’t that different. They aren’t stricter for sure, so for the purpose of choosing the right graduate program and lab it’s probably best to just pretend you’re on the academic track. So, if the main goal is 2-3 high-quality first-author publications, this is totally achievable in many labs all around the world. Even in labs that aren’t that well known, in universities that aren’t that highly ranked, students routinely perform at this level.&lt;/p>
&lt;p>Consequently, don’t obsess too much about the prestige of the university. Prestige is overrated at the graduate level. (It is much more important at the postdoc level.) Even the most prestigious labs in the most prestigious places frequently hire postdocs from all sorts of universities. This happens because the prestigious labs tend to employ many postdocs, often many more than they produce graduate students, and therefore they simply cannot fill all their positions with graduates from comparably prestigious labs. As long as you graduate with a competitive cv (see above), you’ll most likely be fine and get a good postdoc position. My personal opinion is that any university within the &lt;a href="http://www.shanghairanking.com/ARWU2013.html">top 200&lt;/a> of the world university rankings will probably be just fine for graduate school. I got my PhD from a university ranked somewhere past 300, and I still managed to get a good job, at a university that is consistently ranked in the top 40 worldwide and in the top 10 nationwide in my field. I’m not saying here that getting a PhD from a higher ranked institution won’t help you. I just think that it’s not as important as you may think it is.&lt;/p>
&lt;p>Related to this issue, I would like to emphasize that choosing a lab for graduate school requires very different considerations than choosing a lab for a postdoc. My advice in this post is specifically for graduate students; I may write an article for postdocs at a later date. Some labs are really good for graduate students but not that great for postdocs. Some labs are the other way round. Some labs are great for everybody, but those are much rarer and may be highly competitive.&lt;/p>
&lt;p>In particular, I would be wary of very large labs that are staffed primarily with postdocs and senior scientists. In such labs, it’s not uncommon for graduate students to be treated as second-class citizens that need to fend for themselves. If you’re in that kind of a lab, you may rarely see your PI. Your day-to-day supervision—if there is any—is likely going to come from a postdoc. At that point, you may be getting worse supervision than you would have gotten had you gone with an inexperienced, first-year faculty member.&lt;/p>
&lt;p>All else being equal, I would urge you to choose the lab that publishes more. If you’re in a lab that publishes a lot, chances are you’re going to be publishing a lot as well. By contrast, if you’re in a lab that publishes rarely, don’t expect to see your name in print that often. In fact, it’s not uncommon for a weaker student in a very productive lab to build a better track record than a stronger student might do in a lab that doesn’t like to commit words to print.&lt;/p>
&lt;p>Should you go with a junior faculty member or with a more established person? There are arguments for either route. If you go with a junior faculty member, you are more likely to get a lot of personal attention. You have the chance to build a lab from the ground up and to get your name on that lab’s important early papers. Most of the early students of scientists who became famous rose to fame with them. Of course, the early students of scientists who didn’t become famous didn’t, so take that for what it’s worth. The argument for an older, more established person is that that person is more of a known quantity. You can evaluate that person’s productivity, impact on the field, mentoring philosophy, and lab culture. The older adviser is also more likely to have connections that may be beneficial to you, and he/she is less likely to make rookie mistakes. Finally, a younger adviser might end up competing with you if you turn out to be really good. By the same token, an older, very established adviser may suck up much of the available grant money in an entire field. Once you leave the lab, you will have to change field and/or develop a clearly unique and distinct identity to remain competitive.&lt;/p>
&lt;p>Some people worry about joining a younger professor’s lab since he or she might not get tenure. I don’t think this risk is particularly high, unless you’re at a school known for never giving tenure. Of course, be careful if the writing is on the wall and there are rumors that the person whose lab you’re considering may not get tenure. In all other cases, I wouldn’t worry much about the tenure situation. Also, keep in mind that if you go with a famous and established tenured professor it’s not certain either that they will stay for five years at the same place. They might get hired away while you’re in graduate school, and that experience could be almost as stressful as your professor not getting tenure. So don’t decide against a lab out of fear, decide for the lab that overall seems to be the best fit for you. If that turns out to be the lab of an old, established professor, you’ll likely be fine. And if it is the lab of a junior person, you’ll likely be fine as well.&lt;/p>
&lt;p>Finally, you need to be aware that there are generally two types of graduate programs: those that have a rotation system and those that don’t. If there is a rotation system, you rotate with 2-4 labs in your first year, and then you decide in which lab to pursue your PhD work. If there is not, then you get accepted into the program under the assumption that you’ll join a specific lab. The advantage of the rotation system is that you can test-drive a lab before joining. The disadvantage is that if none of the rotations work out, or if you don’t get rotation spots in your preferred labs, you may end up in a lab you don’t like or in no lab at all. If there’s no rotation system, then you have to decide on a lab without really knowing much about it. In the latter types of programs, you can set up your own rotation system of sorts by asking to be co-advised by two or three faculty members. After about a year, you can then decide whether you want to stay in the co-advised situation or whether you’d rather just work with one particular faculty member.&lt;/p>
&lt;p>Ultimately, I don’t think it matters too much whether you join a program with a rotation system or not. Either way, I would encourage you to get to know the labs in the program ahead of time, and to only join a graduate program if multiple participating labs look attractive to you. Regardless of how wisely you choose your initial lab, you may reach a point where you have to switch, and at that point it’s good to have alternative options.&lt;/p></description></item><item><title>How good is good enough?</title><link>https://sevimcengiz.github.io/blog/2013/09/10/how-good-is-good-enough/</link><pubDate>Tue, 10 Sep 2013 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2013/09/10/how-good-is-good-enough/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>The other day, I wrote a blog post about &lt;a href="https://sevimcengiz.github.io/blog/2013/9/6/from-undergraduate-to-faculty-member-critical-decision-points-in-the-academic-career">critical decision points in an academic career.&lt;/a> &lt;a href="http://ivory.idyll.org/blog/">Titus Brown&lt;/a> felt that I was perpetuating the belief that being “good enough” is a necessary requirement to becoming a faculty member. My intention in writing the post was actually the exact opposite, to argue that whether somebody is or is not “good enough” is largely irrelevant to their success in academia, and not something they should spend much time thinking about. Clearly I didn’t quite succeed in getting my points across, so I’ll try again.&lt;/p>
&lt;blockquote class="twitter-tweet" lang="en">
&lt;p lang="en" dir="ltr">
&lt;a href="https://twitter.com/RELenski">&lt;span class="citation">@RELenski&lt;/span>&lt;/a> You know, I really disagree with &lt;a href="https://twitter.com/ClausWilke">&lt;span class="citation">@clauswilke&lt;/span>&lt;/a> phrasing: “Are you good enough to be a faculty member?” even in context here.
&lt;/p>
— Titus Brown (&lt;span class="citation">@ctitusbrown&lt;/span>) &lt;a href="https://twitter.com/ctitusbrown/status/377436924710907904">September 10, 2013&lt;/a>
&lt;/blockquote>
&lt;blockquote class="twitter-tweet" data-conversation="none" lang="en">
&lt;p lang="en" dir="ltr">
&lt;a href="https://twitter.com/RELenski">&lt;span class="citation">@RELenski&lt;/span>&lt;/a> &lt;a href="https://twitter.com/ClausWilke">&lt;span class="citation">@ClausWilke&lt;/span>&lt;/a> Perpetuates belief (unproven) that “being good” is even &lt;em>necessary&lt;/em> for being faculty, much less sufficient.
&lt;/p>
— Titus Brown (&lt;span class="citation">@ctitusbrown&lt;/span>) &lt;a href="https://twitter.com/ctitusbrown/status/377437139094355968">September 10, 2013&lt;/a>
&lt;/blockquote>
&lt;script async src="//platform.twitter.com/widgets.js" charset="utf-8">&lt;/script>
&lt;p>I subscribe to Malcom Gladwell’s threshold theory,&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> which argues that beyond a certain minimum required amount of innate talent, professional success is largely independent of talent and depends instead on numerous other factors, such as the amount of training you receive and the opportunities that come your way. In a nutshell, according to Gladwell, you can’t groom the village idiot into becoming a faculty member at Harvard, but any incoming graduate student in any decent university likely has the innate talent necessary to get there.&lt;a href="#fn2" class="footnote-ref" id="fnref2">&lt;sup>2&lt;/sup>&lt;/a> From there on out, it’s all just effort, proper coaching, the right connections, and some amount of luck.&lt;/p>
&lt;p>There can be no doubt that luck is important for professional success, in particular on the road to getting a tenure-track position.&lt;a href="#fn3" class="footnote-ref" id="fnref3">&lt;sup>3&lt;/sup>&lt;/a> Many pieces have to fall into place, many of which may not have anything to do with who you are and what you can do. If you’re on the job market in a recession, when there are virtually no faculty searches going on, it’s going to be tough regardless of your track record. If suddenly a new hot area opens up and you happen to &lt;em>not&lt;/em> work in that area, it may be difficult to convince departments that you’re the right candidate. My own trajectory reflects this. Without luck, I wouldn’t be a faculty member at UT Austin today. I got my job because Josh Plotkin’s wife needed to be close to a medical school, and UT Austin didn’t have one at the time. So Josh declined my department’s offer, even though it was his first choice. If Josh had been married to a different wife or not at all, or if UT Austin had been ten years ahead of their current schedule to getting a medical school, my life might be very different today.&lt;/p>
&lt;p>At the same time, I do subscribe to the idea that &lt;a href="http://www.telegraph.co.uk/technology/3304496/Be-lucky-its-an-easy-skill-to-learn.html">luck is a skill.&lt;/a> I’ve seen this countless times with colleagues, friends, and family. Some people are just consistently lucky. They always seem to make out alright. And others appear to be consistently unlucky. Something always goes wrong for them, no matter what they do. As somebody who (I believe) falls on the luckier side of the spectrum, and also as somebody who has a good sense of how actions connect to possible outcomes,&lt;a href="#fn4" class="footnote-ref" id="fnref4">&lt;sup>4&lt;/sup>&lt;/a> I can usually spot the behavioral patterns that cause people to be lucky or unlucky. Show me somebody who is &lt;em>consistently&lt;/em> unlucky, and I’ll tell you what they’re doing wrong. It would take more than a few lines in this already far-too-long blog post to explain specifics. So I’ll defer that for another time. For now, if you think you’re consistently lucky, keep doing whatever it is you’re doing. If you think you’re consistently unlucky, you probably have a tendency to use the wrong priorities in your decision making. You might make decisions out of fear, or out of a desire for pleasure, or for immediate benefit, rather than based on a rational assessment of the long-term consequences of your decisions. It might help you to discuss your decisions with a thoughtful mentor, &lt;em>and to listen to her advice.&lt;/em>&lt;/p>
&lt;p>Let’s get back to the original question. What does it take to become a faculty member? First, you need some amount of innate talent. If you’re still reading, and you’re not constantly thinking “so many complicated words,” you probably have sufficient innate talent. Second, you need some genuine luck. For example, you accidentally meet somebody at a conference who turns out to be really supportive of your work; or you make a genuinely unexpected, major discovery; or your major competitor falls while rock-climbing and is out for a year, just when you go onto the job market. Third, you need some engineered luck. You need to see opportunities when they come your way and take advantage of them. When issues arise that could cause you trouble down the road, you need to deal with them efficiently and effectively. You generally have to behave in such a way that you’re not your own worst enemy. Fourth, you need to be willing to put in the required effort. The impressiveness of a cv is strongly correlated to the amount of work expended to developing said cv, and nothing is ever going to change that. And fifth, you need to have the resilience to slog through the downturns that you will inevitably encounter on your path in academia. There will be times when nothing seems to go right, when no reviewer likes your papers or grant proposals, when you feel you’re just spinning your wheels with nothing to show for. You will have to work through these periods to be successful in academia.&lt;a href="#fn5" class="footnote-ref" id="fnref5">&lt;sup>5&lt;/sup>&lt;/a>&lt;/p>
&lt;p>Which of those five points fall under your control? The first does not. However, you’re still reading, so that point is irrelevant. The second doesn’t either. There’s nothing you can do about genuine luck or genuine misfortune. So don’t spend any time thinking about it. The other three points fall under your control, and they contribute (by my own, totally unscientific estimate) to at least 70%-80% of your success. So get cracking.&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>The threshold theory is described in Gladwell’s book “Outliers.” It’s a great book. If you haven’t read it yet, do so.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn2">&lt;p>Realistically, if you start with serious coaching only in graduate school it may be too late for star-level success. The kids that were groomed to become Harvard professors when they were three years old will have an enormous head start, one that may be difficult to catch up to. You should still try, though.&lt;a href="#fnref2" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn3">&lt;p>On this note, I find it interesting how many faculty members who are now among the most established scientists in their field were at some point close to giving up on academia. For example, Richard Lenski describes his winding path to &lt;a href="http://telliamedrevisited.wordpress.com/2013/09/09/the-good-old-days/">his first faculty appointment here.&lt;/a> I heard about this story first when I was on the job market and thought I’d never find a decent job, and I found it strangely comforting.&lt;a href="#fnref3" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn4">&lt;p>I’m an &lt;a href="http://www.16personalities.com/intj-personality">INTJ.&lt;/a> My mind is all about possibilities, and how they are connected to what’s happening right now.&lt;a href="#fnref4" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;li id="fn5">&lt;p>Of course the main issue here is to distinguish between constructively slogging through a temporary setback and delusionally keeping on going even though the situation is truly hopeless. I hope my &lt;a href="https://sevimcengiz.github.io/blog/2013/9/6/from-undergraduate-to-faculty-member-critical-decision-points-in-the-academic-career">previous post&lt;/a> can help there. As should any capable adviser or mentor.&lt;a href="#fnref5" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Should you list on your cv a paper that is in review or in preparation?</title><link>https://sevimcengiz.github.io/blog/2013/09/10/should-you-list-a-paper-in-review-or-in-preparation-on-your-cv/</link><pubDate>Tue, 10 Sep 2013 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2013/09/10/should-you-list-a-paper-in-review-or-in-preparation-on-your-cv/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>I strongly recommend that junior scientists (and even senior scientists) list submitted papers on their cv. The main reason is the inevitable delay between when a project is done and when a paper finally comes out. If I see a cv with no publications in the last year, I don’t know if that is because the person got lazy or because there are five papers in the pipeline that just haven’t made their way out of review yet. If I see a couple of papers listed as “submitted” or “in review” it gives me confidence that the person hasn’t gotten lazy yet. Also, from the titles of the papers, I can get a sense of where the person’s work is going at the moment.&lt;/p>
&lt;p>Some might be concerned that a paper that isn’t formally accepted isn’t quite a paper yet, since it doesn’t yet have the official stamp of approval. Therefore it shouldn’t be on the cv. After all, it might never see the light of day. This kind of reasoning does not really reflect reality. As far as I can tell, if a paper has been submitted it might as well have been published, because realistically most papers that get submitted will get published eventually. I have published over 100 papers, and throughout my entire career I can recall maybe 3 or 4 cases where I gave up on a paper after review. I see similar statistics as a reviewer or editor: Most papers that come my way and that I consider to be of insufficient quality to appear in print do so anyway, eventually. So I’m going to argue that maybe 5% of papers get submitted somewhere but never formally appear, while the remaining 95% are on track to becoming published works. I’m a theoretical physicist, and to me 95% is close enough to 100% that I don’t care about the difference. Once a paper has been submitted, I count it as a published paper.&lt;/p>
&lt;p>The argument becomes even stronger if a senior scientist is a coauthor on the paper. If that senior person generally publishes solid works, and if he or she agreed to submission of the article with their name on it, chances are it is a solid piece of work as it currently stands. Reviewers may still have some issues that they’re going to nitpick over. However, realistically reviewers are wrong as often as they are right, and why should I give more credence to some random, anonymous reviewer than to the senior person whose work I respect?&lt;/p>
&lt;p>There is one caveat, though: The number of papers listed on your cv as “in review” should be commensurate to your typical publication output. If you have published two papers a year for the last three years and you list 20 that are in review, I will be skeptical about the quality of those papers and will wonder whether maybe your success rate from submission to publication is not near 100%. But if you usually publish two papers a year and you list three in review, that looks reasonable and I won’t give it a second thought.&lt;/p>
&lt;p>I view papers “in preparation” differently, however. “In preparation” means nothing. A paper that is submitted must have gotten to the point where at least one, and usually several, scientists felt it could be published in principle. A paper in preparation could be nowhere near that point, and it might never get there. I certainly have had plenty of papers in my life that were “in preparation” and eventually transitioned to “nobody even remembers what the project was supposed to be about.” If I listed all of those papers on my current cv, it’d probably be twice as long and half as useful. If you have a paper in preparation that you really want to list on your cv, then hurry up, get it done, and submit it. And put it on a preprint server, too, so you and others can cite it.&lt;/p></description></item><item><title>From undergraduate to faculty member: Critical decision points in the academic career</title><link>https://sevimcengiz.github.io/blog/2013/09/06/from-undergraduate-to-faculty-member-critical-decision-points-in-the-academic-career/</link><pubDate>Fri, 06 Sep 2013 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2013/09/06/from-undergraduate-to-faculty-member-critical-decision-points-in-the-academic-career/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>If you’re an undergraduate contemplating an academic career or a graduate student considering the next steps, you may have the long-term goal of becoming a tenured professor at a major research university. At the same time, you may have serious doubts about whether this is the career for you. Are you good enough to be a faculty member? And if you’re not good enough, will you waste years of your life with little to show for it in the end? Even if you’re good enough, is that sufficient, or will you also need an extraordinary amount of luck? By embarking on an academic career, will you be making a high-stakes gamble that may have a catastrophic outcome if you lose? These are serious doubts, and they can make the prospects of pursuing an academic career seem overwhelming and pointless. As a substitute for these overwhelming, larger-than-life questions, I’d like to offer a set of critical decision points and simple rules about how to proceed. I hope that these suggestions will make the path to an academic position more navigable and less stressful.&lt;/p>
&lt;p>Let me first clarify, though, that I don’t think every graduate student has to become a tenured professor at a major university. In fact, I believe that the majority of graduate students are &lt;em>not&lt;/em> on track to become faculty members. For example, I read about a case study once where of an entering class of 20 graduate students at Yale university, only 2 had a tenure-track career 10 years later (I’m recalling this from memory, so I may have some details wrong, but the gist was approximately that.) Losing that many students to pursuits other than pure academia is Ok, as long as the majority of them finds satisfying and appropriately compensated employment. And I’m pretty sure they do. They certainly do if they picked up serious computational skills during their PhD. On the other hand, while I don’t see it as my mission to turn every student of mine into a professor, I also don’t want to see highly gifted and capable students give up on an academic career just because they perceive it as an impossible feat, one they shouldn’t even attempt.&lt;/p>
&lt;div id="from-undergraduate-to-graduate-student" class="section level2">
&lt;h2>From undergraduate to graduate student&lt;/h2>
&lt;p>If you’re currently an undergraduate, you shouldn’t even think about whether you’re on track to becoming a professor. It’s impossible to know anyway, and it doesn’t matter for the main decision you have to make: Should you go to graduate school or not? Unless you are under strong financial pressure to earn money right away (e.g. you have enormous student debt, or you have three children that you have to support on your own), this decision should not primarily be a financial one. For most students, graduate school is approximately cost-neutral: The stipend you’re paid while working as teaching assistant or graduate research assistant covers your basic living expenses. You don’t save any money while you’re in graduate school, but you also shouldn’t accumulate any debt. You could think about graduate school in terms of income lost over five years versus your future earnings potential, but frankly, if you think in these terms I don’t think a graduate program in science is right for you. Get a graduate degree in business, economics, or management, and embark on a career of serious money making.&lt;/p>
&lt;p>A graduate degree in science is for people who really care about figuring things out, or about solving problems. As an undergraduate, you have to be aware that graduate school will be very different from your undergraduate experience, unless you’ve already spent a substantial amount of time in a research lab. Graduate school is not about passing exams, getting good grades, or cramming material. In the end, it’s all about doing science and writing papers. Some people have a 4.0 undergraduate GPA and fail in graduate school, and others have a 2.9 GPA and succeed. If you really care about figuring things out, if you could see yourself spending months at a time getting to the bottom of an issue, then graduate school is for you. Don’t worry about the naysayers that say a PhD is a worthless piece of paper. I am not aware of any evidence that a PhD in science will &lt;em>hurt&lt;/em> your subsequent employability. It may not help you much, depending on how things go, but as I said already, you shouldn’t get into a PhD program for the money anyway. You should get into it because of your passion for research.&lt;/p>
&lt;/div>
&lt;div id="from-graduate-student-to-postdoc" class="section level2">
&lt;h2>From graduate student to postdoc&lt;/h2>
&lt;p>Ok, you’ve now made your way almost all the way through graduate school and the end is in sight. Should you continue and search for a postdoc position? Or should you jump ship and look for alternatives? At this point, I think it is justified to ask about earnings potential. You have obtained the most advanced degree you’ll ever get. From here on out, you’re not in it for the education, you’re in it for the experience. You have to ask yourself: Would I rather make money, or would I rather do nothing but research for a few years? For most academics, the postdoc time is a uniquely rewarding and free time. A time during which you can (mostly) freely pursue whatever research you care about, on your own schedule. You have completed your 10,000 hours of science by that time, so you can hit the ground running and do interesting stuff. For poor compensation, mind you. If your mindset is “I don’t really know what else I’d want to do anyway” then go ahead and do a postdoc. But if you can see a clear alternative path, and if that path looks attractive to you, then that alternative path may be the better choice.&lt;/p>
&lt;p>Importantly, though, it is still not time to ask yourself whether you’re on track to becoming a faculty member. Plenty of graduate students don’t do that well, only to recover spectacularly during their postdoc. And others do well as graduate students but falter as postdocs. Generally, the former group does much better than the latter on the academic job market. I’m part of the former group, and I made out alright. I like to say that if you erased from my resume every single thing I did during graduate school, nothing of consequence would change. I got a job as a faculty member anyway.&lt;/p>
&lt;p>You do have to make an honest assessment, though. Where do you stand relative to your fellow graduate students? Would you say your performance is comparable to most? Better? Worse? After five years in graduate school, you may not yet have made an earth-shattering discovery, but you should know by now whether you’re cut out for science or not. In particular, do you have one or two papers to your name for which you did the majority of the work, including the conceptual work? (I don’t care how good they are, just that they got done.) If after an honest assessment you find that you’re not really cut out for science, then don’t do a postdoc. Find a different occupation.&lt;/p>
&lt;p>One word of hope for finding a postdoc position: For as long as I can remember, the job market has been in favor of postdocs. Any capable graduate student who wants to can find a decent postdoc position. So don’t ever worry about not getting a postdoc position. If you want one, you’ll get one.&lt;/p>
&lt;/div>
&lt;div id="from-postdoc-to-faculty-member" class="section level2">
&lt;h2>From postdoc to faculty member&lt;/h2>
&lt;p>Now you’re two to three years into your postdoc. Finally it’s time to ask yourself whether you’re on track to becoming a faculty member or not. Take honest stock. Where are you, compared to other people in the field that you’d be competing with on the job market. Ask some senior scientists about an honest evaluation. Hopefully your postdoc adviser will be able to tell you where you stand. In my opinion, if you’re three years into a postdoc and you’re nowhere near ready to apply for a faculty position, then it may be time to consider alternative careers. If you’re three years in and you’re ready to apply, then go for it and see how it goes. If you’re three years in and you’re getting close but you’re not quite there yet, then it’d be reasonable to wait another year. But don’t keep saying “I’ll be ready next year.” At some point, if things don’t work out in academia, you have to cut your losses and move on. Where that point is is a somewhat arbitrary and a bit of a personal choice, but I’d place it around five years. After five years of a postdoc-level position, you should find something more permanent. And if that job is not a tenure-track faculty position, then you may have to settle for research scientist, lecturer, administrator, or whatever else you can make work for you. There are plenty of reasonable career paths for a scientist, just don’t become a career postdoc.&lt;/p>
&lt;p>Now, you can’t expect things on the job market to work out the first time round. You may not be quite ready, the big paper you wrote may not yet be that well known, or it may just be a bad year for academic hiring. If by your own and by your senior colleagues’ assessment you are ready to get a faculty position, then don’t despair if it doesn’t work out the first time round. Try at least two rounds. Also, if you changed your field after your PhD, or if you didn’t really do much of consequence as a graduate student, you may need a little more time as a postdoc. I was a postdoc for five years, and I think I needed that time to be really ready for a faculty position.&lt;/p>
&lt;/div>
&lt;div id="summary" class="section level2">
&lt;h2>Summary&lt;/h2>
&lt;p>As undergraduate, follow your passion. If you have a passion for figuring things out, get a graduate degree and see if you still like it five years down the road. Don’t worry about not being good enough.&lt;/p>
&lt;p>As graduate student, if your passion hasn’t disappeared, and if you can stomach another three to five years of being poor, go for the postdoc. Don’t worry about not being good enough.&lt;/p>
&lt;p>As postdoc, do an honest assessment of where you stand. If you are competitive on the job market, go for it. If you’re almost competitive, do what needs to be done to eliminate the “almost.” If you’re nowhere near competitive after about three years, start thinking about alternative options.&lt;/p>
&lt;/div></description></item><item><title>Why graduate students get a reasonable deal—A response to the anonymous grad student in the Guardian</title><link>https://sevimcengiz.github.io/blog/2013/08/31/atqeelrnfeyb3e03sycsdpl7p5zc83/</link><pubDate>Sat, 31 Aug 2013 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2013/08/31/atqeelrnfeyb3e03sycsdpl7p5zc83/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>This morning, an article in the Guardian is making the rounds on the academic twitter feeds. The article is written by an anonymous graduate student, and it argues &lt;a href="http://www.theguardian.com/higher-education-network/2013/aug/30/what-does-phd-stand-for">that graduate students are underpaid and that their salaries should be doubled.&lt;/a> When reading the article, I couldn’t help but feel that it lacked the careful analysis, logical reasoning, and deep thought befitting of a graduate student. The author is either not aware of or willfully ignores how graduate students are paid and why. I am willing to give the author the benefit of the doubt, though. I recently had a conversation with a senior faculty member at my institution and she also didn’t really understand how graduate students are paid. So here’s the quick summary: per hour, graduate students are compensated better than most postdocs and lecturers. After tenure-track faculty members, graduate students probably get the best deal in academia.&lt;/p>
&lt;p>A few caveats up front: I’m speaking only for natural sciences. Also, I’m speaking primarily for the US system. However, I got my PhD in Germany, and most of what I’m saying here applies to that system as well, as far as I know. I am aware that in absolute terms, graduate student salary is low. I think most professors are aware of this. In fact, our department is currently going through a strategic planning process, and the number one issue identified by our faculty was low graduate student salaries. However, I suspect that most people are thinking about a ~10% increase in graduate student salaries, not a doubling. Finally, I completely agree with &lt;a href="http://anothersb.blogspot.co.uk/2013/08/lets-pay-phd-students-more-and.html">this blogger&lt;/a> that everybody in academia is underpaid. In fact, when I meet with high-level executives from industry and tell them how much I make, they just stare at me in disbelief. So keep that in mind. Nobody is in academia for the money. With that, let’s have a look at graduate student compensation, let’s consider for what work they actually receive it, and let’s see how it stacks up compared to postdoc and lecturer compensation.&lt;/p>
&lt;p>Graduate students are enrolled in a university degree program. As part of that program, they are expected to take classes and carry out independent study. The independent study component is basically their research program, and the final demonstration that they have completed their independent study is the PhD thesis. Note that none of this effort is compensated in any way. It is a fundamental principle of university education, not just in the US but in most places, that you don’t get paid to participate in a degree program. In fact, in most places you have to pay tuition to do so. In the US, tuition is quite substantial, and ultimately the graduate students are responsible to pay it in full. Now, in most reasonable graduate programs in the natural sciences, graduate students don’t actually pay tuition, and they do receive a stipend. How does this work? One possibility is that students can receive fellowships, but I don’t want to address fellowships here. The more common scenario is that graduate students are being paid as either Teaching Assistants (TAs) or Graduate Research Assistants (GRAs) or a combination of the two. In this scenario, the stipend graduate students receive is for their TA or GRA work. Generally, TA or GRA appointments also come with funds to cover tuition. So on top of their stipend, graduate students receive substantial additional compensation, on the order of $10,000 a year at my institution, and amounting to much higher levels at other schools. Because graduate students are paid for TA or GRA work, not for their studies, TA and GRA appointments are generally half time, 20h per week. I remember, when I did my PhD in Germany, that my GRA appointment contracts always contained a clause to the effect that my supervisor was required to leave me adequate time outside my GRA duties to carry out my own, independent research.&lt;/p>
&lt;p>So how much do graduate students actually make? Typical salaries are around &lt;span>$&lt;/span>2000 per month. Lucky graduate students make a little more, maybe &lt;span>$&lt;/span>2200–&lt;span>$&lt;/span>2300, while the unlucky ones may make only around &lt;span>$&lt;/span>1900. Remember, though, that these amounts are for a 50% time position. If you extrapolate to an annual rate at 100% time, you end up somewhere in the range of &lt;span>$&lt;/span>50,000, give or take. Almost no postdoc and very few lecturers make that kind of money. (Postdoc and lecturer salaries are closer to $40,000, and often below that.) And remember, that’s without tuition remission, which goes on top of the salary.&lt;/p>
&lt;p>Thus, when graduate students are employed to do research (as GRAs), they are paid more per hour than postdocs are. And when they are employed to teach (as TAs), they are paid more than lecturers are, for a comparable workload. In particular, when a graduate student works as TA for a lecturer, the student makes more money than the lecturer does for that course, even though the lecturer has more responsibilities. (At my institution, one course pays for 33% of the time of a lecturer but for 50% of the time of a TA, &lt;em>and&lt;/em> the TA has the higher base rate!)&lt;/p>
&lt;p>Graduate students that work in well-funded labs generally get employed as GRAs rather than TAs, at least a substantial fraction of the time. Strictly speaking, the work they do as GRAs is separate from what they are working on for their degree, but most professors will try to give students work assignments that align with their own research plans. So if you’re a graduate student, are employed as GRA, and have no assignments beyond working on something that will count for your thesis, you’re getting a really good deal. You’re basically given the option to double-dip, to use the same work for both compensation and education.&lt;/p>
&lt;p>Now, as a thought experiment, what would happen if we actually paid graduate students at 100%? It’s simple. Most GRA positions would disappear. Already, if you do the math, you realize that a graduate student and a postdoc are comparable expenses. One year of graduate student salary plus tuition is comparable to one year of postdoc salary, in particular at schools where tuition is high. (As faculty member, if I want to employ a student as GRA, &lt;em>I have to pay the student’s tuition from my grant.&lt;/em>) I know many colleagues who say they’d rather hire a postdoc than a graduate student because they get a better deal for their money.&lt;a href="#fn1" class="footnote-ref" id="fnref1">&lt;sup>1&lt;/sup>&lt;/a> If you now increased the annual cost of a graduate student by another $22,000, nobody in their right mind would ever hire another graduate student. You’d have to double the salaries of everybody, graduate students, postdocs, lecturers, and professors, to keep some sort of balance among the various compensation levels, and to prevent professors from hiring only postdocs. I’m personally not opposed to doubling the salaries of everybody, but realistically the money is just not there.&lt;/p>
&lt;p>To summarize: Of all the things we can (and should) worry about in academia, high undergraduate tuition, low funding rates, poor job prospects for postdocs, tenured professors who’ve turned into dead wood, and so on, paying graduate students at 50% effort is the least of my worries.&lt;/p>
&lt;div class="footnotes">
&lt;hr />
&lt;ol>
&lt;li id="fn1">&lt;p>Incidentally, in computer science it’s the other way round. Because most PhDs in computer science can go to industry and make a lot of money, postdocs can command a much higher level of compensation in that field, and hence professors are more likely to hire graduate students than postdocs.&lt;a href="#fnref1" class="footnote-back">↩︎&lt;/a>&lt;/p>&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>A call for lightning talks at scientific conferences</title><link>https://sevimcengiz.github.io/blog/2013/08/22/a-call-for-lightning-talks-at-scientific-conferences/</link><pubDate>Thu, 22 Aug 2013 00:00:00 +0000</pubDate><guid>https://sevimcengiz.github.io/blog/2013/08/22/a-call-for-lightning-talks-at-scientific-conferences/</guid><description>
&lt;script src="https://sevimcengiz.github.io/rmarkdown-libs/header-attrs/header-attrs.js">&lt;/script>
&lt;p>At this year’s BEACON Congress, we had undergraduate lightning talks. One student, three slides, five minutes. Next. I rather enjoyed this session. In my mind, some of the most engaging talks of that conference happened in that session. (And I’m not saying this just because my student Dariya won an award for best science presented.) This got me thinking. Maybe we should institute lightning talks more commonly at conferences. And not just for undergraduates, for everybody.&lt;/p>
&lt;p>The beauty of the lighting talk is that presenters have to focus meticulously on the most relevant aspects of their work. And the good presenters absolutely manage to do that. They get their story across in three slides no problems. As expected, the bad presenters don’t. However, they wouldn’t do well with more time either, and at least a bad lightning talk is over quickly. Normally, a talk that bores you to death would continue on for twenty minutes or more, up to, God forbid, an entire hour if it’s a keynote speaker.&lt;/p>
&lt;p>So here is my proposition: We should make lightning talks a more common feature of scientific conferences. Don’t just have lightning-talk sessions for undergraduates, also have them for more senior scientists (yes, up to and including established principal investigators). This would allow more people to present their work, and at the same time it would generate more opportunities for one-on-one interactions.&lt;/p>
&lt;p>Specifically, I’d like to suggest the following. Consider a regular afternoon session at a conference, 2pm to 6pm, with two parallel tracks. Let’s assume 10 talks per track (approx. 20 minutes per talk plus one or two short coffee breaks). That’s 20 talks during the afternoon, of which any given conference attendee can see at most 10. I’d replace those two parallel tracks with a single track of lightning talks combined with associated poster sessions for the people who just presented. E.g., 2pm–2:50pm, 10 speakers give their lightning talks. 2:50pm–4pm, the same 10 speakers present their posters. 4pm–4:50pm, another 10 speakers give their lightning talks. 4:50pm–6pm, the second 10 speakers present their posters.&lt;/p>
&lt;p>Do I think that all talks at conferences should be replaced by lightning talks? Probably not. (Even though I’m tempted to say yes, my tolerance for boring or poorly presented talks is pretty low.) However, a good mix of invited keynote talks, regular 20 minute talks, and lightning talks would probably make for a very exciting and dynamic conference. I hope somebody tries this out. If you do, please invite me!&lt;/p></description></item></channel></rss>